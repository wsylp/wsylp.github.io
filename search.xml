<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[系统集成项目管理工程师必背]]></title>
    <url>%2F%E7%B3%BB%E7%BB%9F%E9%9B%86%E6%88%90%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E5%B7%A5%E7%A8%8B%E5%B8%88%E5%BF%85%E8%83%8C%2F</url>
    <content type="text"><![CDATA[本篇文章仅用于个人软考整理的背诵点，参考教材与其他书籍并在练习工程中进行整理而成。第一章 信息化知识信息概念信息的创始人信息的奠基者信息的传输模型信源—-编码—-信道(噪声)—–解码—-信宿信息的质量属性速记（精完可及经可安）精确性完整性可靠性及时性经济性可验证性安全性系统的特点目的性可嵌套性稳定性开放性脆弱性健壮性信息化层次速记（产企业国社）产品信息化企业信息化产业信息化国民经济信息化社会生活信息化社会信息的基本内涵主体：全体社会成员，包括政府、企业、事业、团体和个人手段：基于现代信息技术的先进社会生产工具途径：创建信息时代的社会生产力，推动社会生产关系及社会上层建筑的改革目标：使国家的综合实力、社会的文明素质和人民的生活质量全面提升。]]></content>
      <categories>
        <category>软考</category>
      </categories>
      <tags>
        <tag>软考</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[日常学习回顾与汇总(二)]]></title>
    <url>%2F%E6%97%A5%E5%B8%B8%E5%AD%A6%E4%B9%A0%E5%9B%9E%E9%A1%BE%E4%B8%8E%E6%B1%87%E6%80%BB-%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[进行日常中的学习与汇总进行笔记20210511mysql复核索引：复核索引查询语句中必须包含索引前面的字段才会进行进行匹配，否则则不会使用索引。如果含有查询条件中含有全部索引，则顺序不重要。12345CREATE INDEX idx_phone_name ON user(phone,name);SELECT * FROM user_innodb where name = '1';--不走索引SELECT * FROM user_innodb where phone = '2';--走索引 下同SELECT * FROM user_innodb where phone = '2' and name = '1';SELECT * FROM user_innodb where name = '1' and phone = '2';索引的数据结构：innodb默认索引数据结构是B+Tree，并且自增主键是保存到数据库中，如果重启会重新根据数据库中最大的主键进行开始。在mysql8中已经进行修改了。如果为二叉树查找树可能会导致形成一个链表平衡二叉树AVL任何节点的两个子树高度最大差别是1，也被成为高度平衡树。增加何删除可能需要一次或者多次树旋转来重新平衡这个树B-Tree多路平衡查找树每个节点包含：本结点所含关键字的个数、指向父结点的指针、关键字、指向子结点的指针聚集索引：聚集索引中键值的逻辑顺序和表中相应行的物理顺序相同。在innodb的设计中聚集索引包含整行的数据，所以innodb中索引就是数据本身，这就是大家常说的索引即数据。非聚集索引：其实就是一个普通索引，但是非聚集索引不存储全部数据，只存储聚集索引的值（一般为主键id）B+TreeB+ 树是一种树数据结构，是一个n叉树，每个节点通常有多个孩子，一颗B+树包含根节点、内部节点和叶子节点，和B-Tree几乎一样，只不过B+Tree不再包含整行的数据了。B+ 树通常用于数据库和操作系统的文件系统中。B+ 树的特点是能够保持数据稳定有序，其插入与修改拥有较稳定的对数时间复杂度。B+ 树元素自底向上插入m阶的B+树：根结点至少有两个子女每个中间节点都至少包含ceil(m / 2)个孩子，最多有m个孩子每一个叶子节点都包含k-1个元素，其中 m/2 &lt;= k &lt;= m所有的叶子结点都位于同一层每个节点中的元素从小到大排列，节点当中k-1个元素正好是k个孩子包含的元素的值域分划]]></content>
      <categories>
        <category>温故知新</category>
      </categories>
      <tags>
        <tag>温故知新</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[软件系统安全问题]]></title>
    <url>%2F%E8%BD%AF%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%89%E5%85%A8%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[软件系统安全ingXSS漏洞Xss 是 cross site scripting 的简称，指的是把JS代码存入目标服务器，然后其他客户端在访问服务器的时候，就会在客户端执行恶意JS，从而达到入侵或者盗取客户端信息的目的。XSS分为反射型、DOM型、存储型反射型：反射型一般是发送一个url给受害者，骗取用户点击，然后恶意代码就会在客户端执行。所以这也是为什么我们不能随意点击邮件里面的，或者不明目的的网站里面的链接的原因DOM型：DOM型XSS是从另一个维度对XSS进行划分，反射型，或者存储型XSS都可以是DOM型的。它的特征就是恶意代码是通过操作DOM来达到恶意目的的而已存储型XSS是在服务器的输入端，插入自己的恶意代码，然后把这些代码提交到服务器端。而后其他的客户端在访问服务器时，就会在客户端执行。因为现在很多的输入是接收富文本编辑框输入的，服务器端没有过滤的话存储型XSS更容易实现解决方案：实现Filter类继承HttpServletRequestWrapper进行处理定义转义与反转义工具类FilterConfig配置文件进行配置CrsfCsrf指的是 cross site request forgery 请求欺骗。指的是恶意代码，盗取用户的身份信息，然后利用此敏感信息发起对服务器的访问，获取有价值的信息，甚至盗取用户的银行信息。黑客通过恶意手段让用户执行恶意脚本，访问恶意服务器，恶意服务器返回恶意js，盗取用户身份并发起对原服务器的访问，恶意服务器获取到服务器有价值的数据信息。防范 CSRF 攻击可以遵循以下几种规则：Get 请求不对数据进行修改不让第三方网站访问到用户 Cookie阻止第三方网站请求接口请求时附带验证信息，比如验证码或者 Token解决方案：使用token，并对token属性进行甄别，以判断是否是真的客户。SameSite可以对 Cookie 设置 SameSite 属性。该属性表示 Cookie 不随着跨域请求发送，可以很大程度减少 CSRF 的攻击，但是该属性目前并不是所有浏览器都兼容Referer CheckHTTP Referer是header的一部分，当浏览器向web服务器发送请求时，一般会带上Referer信息告诉服务器是从哪个页面链接过来的，服务器籍此可以获得一些信息用于处理。可以通过检查请求的来源来防御CSRF攻击。正常请求的referer具有一定规律，如在提交表单的referer必定是在该页面发起的请求。所以通过检查http包头referer的值是不是这个页面，来判断是不是CSRF攻击。但在某些情况下如从https跳转到http，浏览器处于安全考虑，不会发送referer，服务器就无法进行check了。若与该网站同域的其他网站有XSS漏洞，那么攻击者可以在其他网站注入恶意脚本，受害者进入了此类同域的网址，也会遭受攻击。出于以上原因，无法完全依赖Referer Check作为防御CSRF的主要手段。但是可以通过Referer Check来监控CSRF攻击的发生。Anti CSRF Token目前比较完善的解决方案是加入Anti-CSRF-Token。即发送请求时在HTTP 请求中以参数的形式加入一个随机产生的token，并在服务器建立一个拦截器来验证这个token。服务器读取浏览器当前域cookie中这个token值，会进行校验该请求当中的token和cookie当中的token值是否都存在且相等，才认为这是合法的请求。否则认为这次请求是违法的，拒绝该次服务。这种方法相比Referer检查要安全很多，token可以在用户登陆后产生并放于session或cookie中，然后在每次请求时服务器把token从session或cookie中拿出，与本次请求中的token 进行比对。由于token的存在，攻击者无法再构造出一个完整的URL实施CSRF攻击。但在处理多个页面共存问题时，当某个页面消耗掉token后，其他页面的表单保存的还是被消耗掉的那个token，其他页面的表单提交时会出现token错误验证码应用程序和用户进行交互过程中，特别是账户交易这种核心步骤，强制用户输入验证码，才能完成最终请求。在通常情况下，验证码够很好地遏制CSRF攻击。但增加验证码降低了用户的体验，网站不能给所有的操作都加上验证码。所以只能将验证码作为一种辅助手段，在关键业务点设置验证码短信轰炸登录验证码绕过SQL注入重复提交目录遍历\穿越任意文件上传文件的上传对于服务器入侵是必须的。各种木马，webshell都要为黑客打开通道，因此，文件上传漏洞对于运维人员是致命的。要定时巡检，寻找可疑的文件。定期对服务器文件系统进行拍照，对比早先的快照以发现可疑文件。解决方案：检查文件上传路径 (避免截断、解析漏洞、目录遍历)文件扩展名检测+MIME 验证，白名单机制(避免服务器以非图片的 文件格式解析文件)不在web目录、无脚本执行权限文件内容检查或者图片的二次渲染（避免图片中插入webshell）文件重命名（如随机字符串或者时间戳等方式，防止攻击者得到webshell路径）DDOS攻击目标服务器发起高压力的访问，导致服务器无法响应正常的访问解决办法：细调防火墙参数，以及对恶意访问IP的封堵。点击劫持解决办法：X-Frame-Options 配置X-FRAME-OPTIONS是一个 HTTP 响应头，在现代浏览器有一个很好的支持。这个 HTTP 响应头 就是为了防御用 iframe 嵌套的点击劫持攻击web 容器上进行配置，添加 X-Frame-Options 响应头DENY，表示页面不允许通过 iframe 的方式展示SAMEORIGIN，表示页面可以在相同域名下通过 iframe 的方式展示ALLOW-FROM，表示页面可以在指定来源的 iframe 中展示弱口令垂直越权水平越权参考链接：web开发常见的几大安全问题 - pretty.sunshine - 博客园 (cnblogs.com)再谈web系统安全 - 知乎 (zhihu.com)]]></content>
      <categories>
        <category>security</category>
      </categories>
      <tags>
        <tag>security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP三次握手和四次挥手]]></title>
    <url>%2FTCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%92%8C%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B%2F</url>
    <content type="text"><![CDATA[三次握手与四次挥手图片理解三次握手数据传输四次挥手]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>tcp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程池攻略]]></title>
    <url>%2F%E7%BA%BF%E7%A8%8B%E6%B1%A0%E6%94%BB%E7%95%A5%2F</url>
    <content type="text"><![CDATA[我是一个小小的线程池，但是我很强大。线程池我叫线程池，我的工作就是为我的后台节省效率。简单的说就是减少线程的创建与销毁，毕竟任何指令的执行都需要资源的开销。corePoolSize我手下有corePoolSize个助手，假设corePoolSize等于5，也就是我怒呢个创建5个线程。当有任务来了，我就创建1个助手（线程）让他处理（1号助手）。此时第二条任务来了，我就再创建1个助手（2号助手），此时我还有创建3个助手能力。当第三条任务来了，不管现在我的1号，2号助手是否在空闲状态，我都会继续创建助手，知道达到corePoolSize。我的后台老大跟我说，防止后面突然的任务增多，在那时会产生创建线程的时间，让我先进行创建起来。workQueue我的助手无休止的处理任务，如果任务存在的话。某一天，我的后台老大交给了我很多任务，我的助手忙不过来了，这个时候我给他们搭建了亭子，让他们在亭子里面有序的休息等待。亭子也就是workQueue，也就是队列。可是出现了一个问题，就是亭子里面有时候没有任务等候了，助手一直频繁的查看会产生开销。于是我设置了感应器，当亭子里面来任务的时候，就会唤起我的助手。这个就是阻塞队列，当队列中为非空时，就会唤醒等待中的线程。好景不长，某一次我发现我的亭子居然一直在塞任务，我看会产生OOM,于是我给我的亭子设置了最大的容纳数目 。此时我变为了有界队列。补充：SynchronousQueueSynchronousQueue没有容量，是无缓冲等待队列，是一个不存储元素的阻塞队列，会直接将任务交给消费者，必须等队列中的添加元素被消费后才能继续添加新的元素。使用SynchronousQueue阻塞队列一般要求maximumPoolSizes为无界，避免线程拒绝执行操作。LinkedBlockingQueueLinkedBlockingQueue是一个无界（没有大小限制）缓存等待队列。当前执行的线程数量达到corePoolSize的数量时，剩余的元素会在阻塞队列里等待，在使用此阻塞队列时maximumPoolSizes就相当于无效了ArrayBlockingQueueArrayBlockingQueue是一个有界缓存等待队列，可以指定缓存队列的大小，当线程数量大于corePoolSize时，多余的任务会缓存在ArrayBlockingQueue队列中等待有空闲的线程时继续执行；当ArrayBlockingQueue满时，则又会开启新的线程去执行，直到线程数量达到maximumPoolSize；当线程数已经达到最大的maximumPoolSize时，再有新的任务到达时会执行拒绝执行策略（RejectedExecutionException）maximumPoolSize但是上面的问题还是没有彻底解决，我发现还是有源源不断的任务进来，此时我的5个助手已经忙不过来了。我的后来老大看到后，给我设置了maximumPoolSize，最大线程数目（8），也就是我还能创建3个助手。但是是有条件的，当workQueue已经满且助手数目小于8（maximumPoolSize）的情况下，依然有任务想要插入，我才可以进行创建。RejectedExecutionHandler当任务不断 的插入到workQueue中的时候，workQueue已经无法接受了，此时我会执行默认的拒绝策略，抛出异常。线程池提供了 AbortPolicy，DiscardPolicy，DiscardOldestPolicy，CallerRunsPolicy，自定义这五种拒绝策略，默认是 AbortPolicy。keepAliveTime时间荏苒，突然有一次，发现workQueue中的队列任务没有了。助手们就一直闲着。但是我的corePoolSize是5，maximumPoolSize是8 ，为了节约成本需要进行回收。此时看谁休息的时间最长就把他进行回收，设置了一个休息时间的截止时间。keepAliveTime，也就是哪个线程先达到keepAliveTime，就先干掉，直到等于5（corePoolSize）。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学习敏捷]]></title>
    <url>%2F%E5%AD%A6%E4%B9%A0%E6%95%8F%E6%8D%B7%2F</url>
    <content type="text"><![CDATA[软件开发之敏捷开发敏捷简介：目前最流行的两种敏捷方法：Scrum和极限编程(eXtreme Programming,XP）。精益方法(Lean)和看板方法(Kanban)。四种敏捷学派的最终目的就是：重视改变团队的思维模式。目标：日常工作中的种种实践；敏捷的价值观与原则；敏捷概念：敏捷是指能够让团队思考更加有效、工作更为高效，并且作出更好决策的一组方法和相关理念。敏捷也是一种思维模式，思维模式的正确与否会影响团队具体实践的高效程度。敏捷实践：每日站立会议汇报工作以及挑战。备受争议（1、开发人员抗拒，因为自己的工作计划以及工作内容被进行剖析出来，无时间工作-说辞。2、项目经理能够跟踪进度）。项目经理会认真去听每个人的汇报，但是开发人员可能仅关心自己的工作。简单的沟通与一起分析进度进行群策群力，让项目更好贯彻与执行。让整个团队保持高效。如果团队中每一位成员都觉得自己在项目规划和运行中享有同样地位，就会变得更加有意义和价值，更加高效。努力建立敏捷思维故事为什么故事容易被记忆？因为大脑容易记忆感情共鸣的事情。​ 如何做：想象自己与书中的人物遇到了同样的事情。图示视觉系能够加深记忆与理解重复重复有助于理解。由简入繁对话式的口语文风如果在对话，则更容易记忆]]></content>
      <categories>
        <category>书籍 开发</category>
      </categories>
      <tags>
        <tag>敏捷开发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[委托模式]]></title>
    <url>%2F%E5%A7%94%E6%89%98%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[设计模式之委托模式委托模式介绍非23中设计模式，面向对象设计模式中常用的一种模式。干活时你的（被委托人），功劳是我的（委托人）参与人：委托与被委托委托人与被委托人在权力上平等（实现同一个接口）委托人持有被委托人的引用不关心过程只关心结果生活举例：开发小程序：现该公司需要开发一个”设计模式”的小程序,归小强（小强小强我最强）项目组开发。此时项目经理将该任务委托给小小强去开发。接口：DevCode.java123456789101112package org.springframework.tests.patterns;/** * 接口 * @author Administrator */public interface DevCode &#123; //开发小程序 void devMiniApps();&#125;项目经理小强1234567891011121314151617package org.springframework.tests.patterns;/** * 项目经理小强 * @author Administrator */public class XiaoQiang implements DevCode &#123; private final XiaoXiaoQiang qiang = new XiaoXiaoQiang(); @Override public void devMiniApps() &#123; //开发小程序 this.qiang.devMiniApps(); &#125;&#125;小强项目组开发人员12345678910111213141516171819202122package org.springframework.tests.patterns;/** * 小小强开发人员 * @author Administrator */public class XiaoXiaoQiang implements DevCode &#123; @Override public void devMiniApps() &#123; System.out.println("我是苦逼的小小强............."); System.out.println("分析需求............."); System.out.println("搭建框架............."); System.out.println("加班加班我最强............."); System.out.println("测试万岁............."); System.out.println("业务验收............."); System.out.println("与产品经理打了一架，继续加班............."); System.out.println("聪明如我开发完成............."); &#125;&#125;测试：12345678910111213141516171819202122package org.springframework.tests.patterns;/** * * @author Administrator */public class TestDev &#123; public static void main(String[] args) &#123; new XiaoQiang().devMiniApps(); &#125;&#125;===结果我是苦逼的小小强.............分析需求.............搭建框架.............加班加班我最强.............测试万岁.............业务验收.............与产品经理打了一架，继续加班.............聪明如我开发完成.............为什么使用委托模式解耦,委托解耦简单说就是把产生事件的代码和处理事件的代码通过委托者给隔离开来。“委托变量（方法答名）可以作为函数参数的形式传入到一个函数中”，只要增加一个新的处理方法就可。委托带来的程序扩展性的提升。在spring中用委托模式进行解耦，来进行达到了灵活的使用。应用场景实现了松耦]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>委托模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[类装载器]]></title>
    <url>%2F%E7%B1%BB%E8%A3%85%E8%BD%BD%E5%99%A8%2F</url>
    <content type="text"><![CDATA[类装载器类装载器将类装在到JVM需要以下步骤：装载：查找和导入Class文件链接：执行校验、准备和解析步骤，其中解析步骤是可以选择的。校验：检查载入的class文件数据的正确性 准备：给类的静态变量分配存储空间。 解析：将符号引用转换为直接引用。 初始化：对类的静态变量、静态代码块执行初始化工作。分为三个类装载器：根装载器、ExtClassLoader（扩展类装载器）和AppClassLoader(应用类装载器)ExtClassLoader：进行装载JRE扩展目录ext中的JAR包AppClassLoader：进行装载Classpath路径下的类包。三者关系：根加载器是扩展类装载器的父类，扩展类装载器是应用装载器的父类。在装载时采用的时“全盘负责委托机制”，全盘负责：就是当一个ClassLoader装载一个类时，除非显式的使用另一个ClassLoader,该类所依赖及引用的类也有这个ClassLoader载入；委托机制：至先委托父类装载器寻找目标，只有找不到的情况下才从自己的类路径中查找并装载目标类。java的反射机制]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>类装载器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[模板方法模式]]></title>
    <url>%2F%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[模板方法模式模板方法模式使用当我们要完成在某一细节层次一致的一个过程或一系列步骤，但其个别步骤在更详细的层次上的实现可能不同时，我们通常考虑模板方法模式来处理。模板方法模式：定义一个操作中的算法的骨架，而将一些步骤延迟到自雷中。模板方法使得自雷可以不改变一个算法的结构即可重新定义该算法的某些特定的步骤。当不变的与可变的额行为在方法的子类实现中进行混合，可以将不变的行为搬到单一的地方帮住子类拜托重复的不变的行为的纠缠。简单的说：就是执行固定的流程，中间步骤有差别，可以实现批量生产。优势提供了一个很好的代码复用平台。简单说下:在spring中的模板方法有JDBC连接。定义骨架 1.进行获取连接对象 、2.获取PreparedStatement 、3.参数封装、4.执行、5.返回结果不变的为1 3 4 5改变的为2，需要传入参数我们模仿下一个考试答题的案例12345678910111213141516171819202122public abstract class TestEnglish &#123; //不变的行为 public void questuion1() &#123; System.out.println("选择题1: 1+1 = () ; A:1 B:2 C:3 D:4"); &#125; public void questuion2() &#123; System.out.println("选择题2: 1+2 = () ; A:1 B:2 C:3 D:4"); &#125; public void questuion3() &#123; System.out.println("选择题3: 1+3 = () ; A:1 B:2 C:3 D:4"); &#125; //改变的行为 public String answer1() &#123; return ""; &#125;&#125;123456789public class StudentA extends TestEnglish &#123; @Override public String answer1()&#123; questuion1(); return "a"; &#125;&#125;12345678public class TestMain &#123; public static void main(String[] args) &#123; TestEnglish studentA = new StudentA(); String answer1 = studentA.answer1(); System.out.println(answer1); &#125;&#125;]]></content>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[日常学习回顾与汇总]]></title>
    <url>%2F%E6%97%A5%E5%B8%B8%E5%AD%A6%E4%B9%A0%E5%9B%9E%E9%A1%BE%E4%B8%8E%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[日常学习回顾与汇总日常学习回顾与汇总20200321 星期六mysql123456789group_concat()与group by一起使用，支持排序group_concat( columnA order by columnA desc/asc)distinct columnA,columnBcast(columnA as decimal(20,4))case when 表达式 then 结果 when 表达式2 then 结果 else 结果 endEnglish1234567891011121314151617I love dog. 我爱吃狗肉dog eat dog 残酷的竞争Love me , love my dog. 爱屋及乌Every dog has its day. 凡人皆有出头之日fish out of water 尴尬，不自在的人She is blackwashed. 有人黑你Come out in the wash. 真相大白Come on be reasonable. 理智一点reputation 声誉声望play my foot in my mouth 说错话a slip of the tongue 口误 说漏嘴my foot 我不信，得了吧foot the bill 买单keep a foot in both camps 脚踏两只船javaif…else的优化提前return ，去除不必else123456789101112131415161718private static void one() &#123; int a = 10; int b = 100; // 优化前 if (a &lt; b) &#123; System.out.println(b - a); &#125; else &#123; return; &#125; //优化后 if (b &lt;= a) &#123; return; &#125; System.out.println(b - a); &#125;三目运算符使用枚举123456789101112131415161718192021private static void three() &#123; int status = 5; String statusName = ""; //优化前 if (status == 0) &#123; statusName = "临时保存"; &#125; else if (status == 1) &#123; statusName = "提交"; &#125; else if (status == 2) &#123; statusName = "审批"; &#125; else if (status == 3) &#123; statusName = "拒绝"; &#125; else if (status == 4) &#123; statusName = "回收"; &#125; else if (status == 5) &#123; statusName = "删除"; &#125; //优化后 statusName = Status.getStatusName(status);123456789101112131415161718192021222324252627282930313233343536373839package base;public enum Status &#123; temp(0,"临时保存"),save(1,"提交"),sp(2,"审批"),hs(3,"回收"),jj(4,"拒绝"),delete(5,"删除"); public static String getStatusName(int value)&#123; for(Status o: Status.values() )&#123; if(o.getValue() == value)&#123; return o.getDesc(); &#125; &#125; return ""; &#125; private int value; private String desc; public int getValue() &#123; return value; &#125; public void setValue(int value) &#123; this.value = value; &#125; public String getDesc() &#123; return desc; &#125; public void setDesc(String desc) &#123; this.desc = desc; &#125; Status(int value, String desc) &#123; this.value = value; this.desc = desc; &#125;&#125;合并条件表达式多个表达式，可以进行判断的进行何在一个条件里面进行判断使用optional123456789101112String name = "张三";//优化前if(name != null)&#123; System.out.println(name);&#125; else &#123; System.out.println("NULL");&#125;//优化后Optional&lt;String&gt; nameOP = Optional.of(name);// JAVA9nameOP.ifPresentOrElse(System.out::println, () -&gt; System.out.println("Null"));表驱动法表驱动法，又称之为表驱动、表驱动方法。表驱动方法是一种使你可以在表中查找信息，而不必用很多的逻辑语句（if或case）来把它们找出来的方法。以下的demo，把map抽象成表，在map中查找信息，而省去不必要的逻辑语句。12345678910111213141516// 优化前if (param.equals(value1)) &#123; doAction1(someParams);&#125; else if (param.equals(value2)) &#123; doAction2(someParams);&#125; else if (param.equals(value3)) &#123; doAction3(someParams);&#125;//优化后Map&lt;?, Function&lt;?&gt; action&gt; actionMappings = new HashMap&lt;&gt;(); // 这里泛型 ? 是为方便演示，实际可替换为你需要的类型// 初始化actionMappings.put(value1, (someParams) -&gt; &#123; doAction1(someParams)&#125;);actionMappings.put(value2, (someParams) -&gt; &#123; doAction2(someParams)&#125;);actionMappings.put(value3, (someParams) -&gt; &#123; doAction3(someParams)&#125;);// 省略多余逻辑语句actionMappings.get(param).apply(someParams)优化逻辑结构，正常流程走主干1234567891011121314151617181920//优化前public double getAdjustedCapital()&#123; if(_capital &lt;= 0.0 )&#123; return 0.0; &#125; if(_intRate &gt; 0 &amp;&amp; _duration &gt;0)&#123; return (_income / _duration) *ADJ_FACTOR; &#125; return 0.0;&#125;//优化后public double getAdjustedCapital()&#123; if(_capital &lt;= 0.0 )&#123; return 0.0; &#125; if(_intRate &lt;= 0 || _duration &lt;= 0)&#123; return 0.0; &#125; return (_income / _duration) *ADJ_FACTOR;策略模式+工厂方法1234567891011121314 String medalType = "guest"; if ("guest".equals(medalType)) &#123; System.out.println("嘉宾勋章"); &#125; else if ("vip".equals(medalType)) &#123; System.out.println("会员勋章"); &#125; else if ("guard".equals(medalType)) &#123; System.out.println("展示守护勋章"); &#125; //勋章接口public interface IMedalService &#123; void showMedal(); String getMedalType();&#125;123456789101112131415161718192021222324252627282930313233//守护勋章策略实现类public class GuardMedalServiceImpl implements IMedalService &#123; @Override public void showMedal() &#123; System.out.println("展示守护勋章"); &#125; @Override public String getMedalType() &#123; return "guard"; &#125;&#125;//嘉宾勋章策略实现类public class GuestMedalServiceImpl implements IMedalService &#123; @Override public void showMedal() &#123; System.out.println("嘉宾勋章"); &#125; @Override public String getMedalType() &#123; return "guest"; &#125;&#125;//VIP勋章策略实现类public class VipMedalServiceImpl implements IMedalService &#123; @Override public void showMedal() &#123; System.out.println("会员勋章"); &#125; @Override public String getMedalType() &#123; return "vip"; &#125;&#125;123456789101112//勋章服务工产类public class MedalServicesFactory &#123; private static final Map&lt;String, IMedalService&gt; map = new HashMap&lt;&gt;(); static &#123; map.put("guard", new GuardMedalServiceImpl()); map.put("vip", new VipMedalServiceImpl()); map.put("guest", new GuestMedalServiceImpl()); &#125; public static IMedalService getMedalService(String medalType) &#123; return map.get(medalType); &#125;&#125;123String medalType = "guest";IMedalService medalService = MedalServicesFactory.getMedalService(medalType);medalService.showMedal();JVM1234567891011121314151617-XX:MetaspaceSize=128m 元空间默认大小-XX:MaxMetaspaceSize=128m 元空间最大大小-Xms1024m 堆最大大小-Xmx1024m 堆最小大小-Xmn256m 新生代大小-Xss256k 栈最大深度-XX:SurvivorRatio=8 新生代分区比例（8:2）-XX:+userConcMarkSweepGC 指定CMS收集器-XX:+printGCDetails 打印详细的GC日志20200325 星期三English123456789101112131415161718192021222324252627282930313233343536373839404142434445Eat one&apos;s words 收回前言 承认错误Break one&apos;s word 食言keep one&apos;s word 守信用 履行诺言cut it out 省省吧 闭嘴level off 稳定下来go to your room 你完蛋了(来源于美国把孩子关小黑屋)sleep late 睡到很晚才起来It&apos;s sick 狂拽炫霸I feel you 我懂你You are a chicken 胆小鬼 胆怯的人prise 赞扬 钦佩compliment 赞美称赞flatter 奉承 讨好Good for you 干的漂亮fire something off 匆忙寄发（邮件等） Don&apos;t go around something the world owes you a living.The world owes you nothing.别到处跟别人抱怨这个世界欠你什么，这个世界什么都不欠你的。bad apple 坏家伙a cool fish 冷漠的人，态度冰冷的人drawn-out 冗长的You have a phone call 你来电话了It is your call 这是你的电话Your phone is ringing.hang up 挂断answer the phone 回电话screen your calls 不方便接电话/骚扰电话I have got the wrong number 打错电话It didn&apos;t get through 电话打不通I&apos;m broke. 我没钱了。make heavy weather of sth 小题大做replacement 代替 替补take out the rubbish. 扔垃圾mysql12345678910111213141516count(column) 查询不为null的数目count(*) sql标准用法，查询所有数据mysql执行引擎：InnonDB MyISAMMyISAM:表级锁，可以把表的总行数记录下来，会直接把行数返回，前提是没有where 条件MyISAM做了一个简单的优化，那就是它可以把表的总行数单独记录下来，如果从一张表中使用COUNT(*)进行查询的时候，可以直接返回这个记录下来的数值即可。InnonDB:支持事务，行级锁InnoDB中索引分为：聚簇索引(主键索引)-&gt;查询的是整行记录非聚簇索引(非主键索引)-&gt;该行记录的逐渐值非聚簇索引比聚簇索引小很多，mysql优先选择最小的非聚簇索引来扫表，故在建表时，创建一个非主键索引很有必要。InnonDB: count(1)和count(*) 查询速率是一样的Mysql索引扫盲总结其他模因：英文 meme基因使得各种物种生物把自己的生理特征遗传给下一代。模因使得人类把思想、行为传播给其他人。两者有区别：遗传性（童话，诗歌）、变异性（改编童话）、选择性（适者生存）传播方式、表理行事、自主选择权20200330mysql尽量使用select 具体字段节省资源，减少网络开销select * 可能不会使用到覆盖索引如果知道只有一条结果，建议使用limit 1如果存在limit 1 找到第一条就会返回不会继续扫描如果查询条件为唯一索引的话没有必要加上limit 1 ,因为唯一索引也是在查找到第一个记过后进行返回0尽量避免在where语句众使用or进行连接条件使用or可能会使索引失效，从而扫描全表，使用union all1select * from t_user where id= 1 union all select * from t_user where name = &apos;张三&apos;如果name没有索引，操作为：索引扫描+全表扫描+合并优化limit分页当偏移量很大时，limit就会很低下1234select * from t_user limit 100000,10-- 改造后select * form t_user where id &gt;100000 limit 10-- 或者20210506mysqloffset 与 limit在常规的使用中科院满足，在大数量的情况下会导致不足。因每次进行分页时数据库都会进行低效的全盘扫描。全盘扫描：又称为顺序扫描，在数据库中进行逐行扫描，顺序读取每一行的数据，然后检查是否符合查询条件。这种扫描最慢，因为需要大量的磁盘I/O,从磁盘到内存的开销很大。OFFSET 越高，查询时间就越长。替代方案1select * from table_name id &gt; 10 limit 20基于指针的分页，本地上保存上次分页的接受的主键和limit。因为通过显示的告诉数据库最新行，数据库可知道从哪里开始搜索（基于有效的索引），而无需考虑范围之外的记录。建议：尽量使用自增主键，即使为了分页。其他Drone自动化部署获取key用keyset(),若获取value则使用entryset()Collection.isEmpty()的复杂度为O(1),size()的时间复杂度为O(n)初始化集合尽量指定大小频繁调用Collection.contains使用set,复杂度为O(1)工具类中屏蔽构造函数（private)字符串用String.valueOf()比“”+value更有效返回空数组或者集合而非NULL枚举属性字段为私有并不可修改布隆过滤器布隆过滤器（Bloom Filter）是1970年由布隆提出的。它实际上是一个很长的二进制向量和一系列随机映射函数。布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都比一般的算法要好的多，缺点是有一定的误识别率和删除困难使用场景：1、黑名单 2、URL去重 3、单词拼写检查 4、Key-Value缓存系统的Key校验 5、ID校验，比如订单系统查询某个订单ID是否存在，如果不存在就直接返回20210507springboot启动原理注解：123@SpringBootApplication=@SpringBootConfiguration(实际上是@Configuration)+@EnableAutoConfiguration+@ComponentScan启动时候的执行流程创建SpringApplication实例，然后调用该对象的实例方法。12345678910/** * Static helper that can be used to run a &#123;@link SpringApplication&#125; from the * specified sources using default settings and user supplied arguments. * @param primarySources the primary sources to load * @param args the application arguments (usually passed from a Java main method) * @return the running &#123;@link ApplicationContext&#125; */public static ConfigurableApplicationContext run(Class&lt;?&gt;[] primarySources, String[] args) &#123; return new SpringApplication(primarySources).run(args);&#125;在初始化的时候会进行一下操作判断是否创建一个为web使用的ApplicationContext类型。加载可用的ApplicationContextInitializer加载可用的ApplicationListener推断并设置main方法定义类1234567891011121314151617181920/** * Create a new &#123;@link SpringApplication&#125; instance. The application context will load * beans from the specified primary sources (see &#123;@link SpringApplication class-level&#125; * documentation for details. The instance can be customized before calling * &#123;@link #run(String...)&#125;. * @param resourceLoader the resource loader to use * @param primarySources the primary bean sources * @see #run(Class, String[]) * @see #setSources(Set) */@SuppressWarnings(&#123; "unchecked", "rawtypes" &#125;)public SpringApplication(ResourceLoader resourceLoader, Class&lt;?&gt;... primarySources) &#123; this.resourceLoader = resourceLoader; Assert.notNull(primarySources, "PrimarySources must not be null"); this.primarySources = new LinkedHashSet&lt;&gt;(Arrays.asList(primarySources)); this.webApplicationType = WebApplicationType.deduceFromClasspath(); setInitializers((Collection) getSpringFactoriesInstances(ApplicationContextInitializer.class)); setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); this.mainApplicationClass = deduceMainApplicationClass();&#125;初始化完成后执行，执行main方法。遍历执行所有通过SpringFactoriesLoader可以查找到并加载的SpringApplicationRunListener.调用他们的starting()方法，通知他们SpringBoot要启动了。创建并配置当前springboot将要使用的Environment(包括配置要使用的PropertySource以及Profile)遍历所有的SpringApplicationRunListener的environmentPrepared(),通知SpringBoot，环境准备好了。123456789101112131415private ConfigurableEnvironment prepareEnvironment(SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments) &#123; // Create and configure the environment ConfigurableEnvironment environment = getOrCreateEnvironment(); configureEnvironment(environment, applicationArguments.getSourceArgs()); ConfigurationPropertySources.attach(environment); listeners.environmentPrepared(environment); bindToSpringApplication(environment); if (!this.isCustomEnvironment) &#123; environment = new EnvironmentConverter(getClassLoader()).convertEnvironmentIfNecessary(environment, deduceEnvironmentClass()); &#125; ConfigurationPropertySources.attach(environment); return environment; &#125;如果SpringBoot的showBanner属性为TRUE，则进行打印Banner123456789101112private Banner printBanner(ConfigurableEnvironment environment) &#123; if (this.bannerMode == Banner.Mode.OFF) &#123; return null; &#125; ResourceLoader resourceLoader = (this.resourceLoader != null) ? this.resourceLoader : new DefaultResourceLoader(null); SpringApplicationBannerPrinter bannerPrinter = new SpringApplicationBannerPrinter(resourceLoader, this.banner); if (this.bannerMode == Mode.LOG) &#123; return bannerPrinter.print(environment, this.mainApplicationClass, logger); &#125; return bannerPrinter.print(environment, this.mainApplicationClass, System.out); &#125;根据用户是否明确设置了applicationContextClass类型以及初始化阶段的推断结果，决定该为当前SpringBoot应用创建什么类型的ApplicationContext并创建完成，然后根据条件决定是否添加ShutdownHook，决定是否使用自定义的BeanNameGenerator，决定是否使用自定义的ResourceLoader，当然，最重要的，将之前准备好的Environment设置给创建好的ApplicationContext使用1234567891011121314151617181920212223242526272829/** * Strategy method used to create the &#123;@link ApplicationContext&#125;. By default this * method will respect any explicitly set application context or application context * class before falling back to a suitable default. * @return the application context (not yet refreshed) * @see #setApplicationContextClass(Class) */ protected ConfigurableApplicationContext createApplicationContext() &#123; Class&lt;?&gt; contextClass = this.applicationContextClass; if (contextClass == null) &#123; try &#123; switch (this.webApplicationType) &#123; case SERVLET: contextClass = Class.forName(DEFAULT_SERVLET_WEB_CONTEXT_CLASS); break; case REACTIVE: contextClass = Class.forName(DEFAULT_REACTIVE_WEB_CONTEXT_CLASS); break; default: contextClass = Class.forName(DEFAULT_CONTEXT_CLASS); &#125; &#125; catch (ClassNotFoundException ex) &#123; throw new IllegalStateException( "Unable create a default ApplicationContext, please specify an ApplicationContextClass", ex); &#125; &#125; return (ConfigurableApplicationContext) BeanUtils.instantiateClass(contextClass); &#125;ApplicationContext创建好之后，SpringApplication会再次借助Spring-FactoriesLoader，查找并加载classpath中所有可用的ApplicationContext-Initializer，然后遍历调用这些ApplicationContextInitializer的initialize（applicationContext）方法来对已经创建好的ApplicationContext进行进一步的处理。遍历调用所有SpringApplicationRunListener的contextPrepared()方法。1234567891011121314151617181920212223242526272829private void prepareContext(ConfigurableApplicationContext context, ConfigurableEnvironment environment, SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments, Banner printedBanner) &#123; context.setEnvironment(environment); postProcessApplicationContext(context); applyInitializers(context); listeners.contextPrepared(context); if (this.logStartupInfo) &#123; logStartupInfo(context.getParent() == null); logStartupProfileInfo(context); &#125; // Add boot specific singleton beans ConfigurableListableBeanFactory beanFactory = context.getBeanFactory(); beanFactory.registerSingleton("springApplicationArguments", applicationArguments); if (printedBanner != null) &#123; beanFactory.registerSingleton("springBootBanner", printedBanner); &#125; if (beanFactory instanceof DefaultListableBeanFactory) &#123; ((DefaultListableBeanFactory) beanFactory) .setAllowBeanDefinitionOverriding(this.allowBeanDefinitionOverriding); &#125; if (this.lazyInitialization) &#123; context.addBeanFactoryPostProcessor(new LazyInitializationBeanFactoryPostProcessor()); &#125; // Load the sources Set&lt;Object&gt; sources = getAllSources(); Assert.notEmpty(sources, "Sources must not be empty"); load(context, sources.toArray(new Object[0])); listeners.contextLoaded(context); &#125;最核心的一步，将之前通过@EnableAutoConfiguration获取的所有配置以及其他形式的IoC容器配置加载到已经准备完毕的ApplicationContext。遍历调用所有SpringApplicationRunListener的contextLoaded()方法。调用ApplicationContext的refresh()方法，完成IoC容器可用的最后一道工序。查找当前ApplicationContext中是否注册有CommandLineRunner，如果有，则遍历执行它们。正常情况下，遍历执行SpringApplicationRunListener的finished()方法、（如果整个过程出现异常，则依然调用所有SpringApplicationRunListener的finished()方法，只不过这种情况下会将异常信息一并传入处理）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * Run the Spring application, creating and refreshing a new * &#123;@link ApplicationContext&#125;. * @param args the application arguments (usually passed from a Java main method) * @return a running &#123;@link ApplicationContext&#125; */ public ConfigurableApplicationContext run(String... args) &#123; StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; Collection&lt;SpringBootExceptionReporter&gt; exceptionReporters = new ArrayList&lt;&gt;(); configureHeadlessProperty(); //获取SpringApplicationRunListeners,并进行执行staring() SpringApplicationRunListeners listeners = getRunListeners(args); listeners.starting(); try &#123; //获取配置环境 ApplicationArguments applicationArguments = new DefaultApplicationArguments(args); //准备环境 ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); configureIgnoreBeanInfo(environment); //打印Banner Banner printedBanner = printBanner(environment); //创建ApplicationContext context = createApplicationContext(); exceptionReporters = getSpringFactoriesInstances(SpringBootExceptionReporter.class, new Class[] &#123; ConfigurableApplicationContext.class &#125;, context); //初始化initializer，遍历listeners的context方法 prepareContext(context, environment, listeners, applicationArguments, printedBanner); refreshContext(context); afterRefresh(context, applicationArguments); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass).logStarted(getApplicationLog(), stopWatch); &#125; listeners.started(context); callRunners(context, applicationArguments); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, listeners); throw new IllegalStateException(ex); &#125; try &#123; listeners.running(context); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, null); throw new IllegalStateException(ex); &#125; return context; &#125; 参考：面试官：能说下 SpringBoot 启动原理吗？ (qq.com)]]></content>
      <categories>
        <category>温故知新</category>
      </categories>
      <tags>
        <tag>温故知新</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[deepin安装mysql]]></title>
    <url>%2Fdeepin%E5%AE%89%E8%A3%85mysql%2F</url>
    <content type="text"><![CDATA[deepin安装mysqldeepin在线安装mysql123456-- 这种方式安装的是最新的，当时安装后是MariDB，就重新卸载了。sudo apt-get install mysql-server mysql-client-- 删除sudo apt-get remove mysql-*dpkg -l |grep ^rc|awk '&#123;print $2&#125;' |sudo xargs dpkg -Pdeepin 离线安装官网安装教程123456-- 官网下载 下载MySQL APT存储库https://dev.mysql.com/downloads/repo/apt/ 选择操作系统时 jessie 代表debain8版本-- 我的命令：sudo dpkg -i mysql-apt-config_0.8.13-1_all.deb sudo dpkg -i mysql-apt-×××.debsudo apt-get updatesudo apt-get install mysql-server]]></content>
      <categories>
        <category>deepin</category>
      </categories>
      <tags>
        <tag>deepin linux mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[catalina.out日志切割]]></title>
    <url>%2Fcatalina-out%E6%97%A5%E5%BF%97%E5%88%87%E5%89%B2%2F</url>
    <content type="text"><![CDATA[对于生产日志切割背景最近发现生产上tomcat下的日志catalina.out文件太大，影响排查问题以及写入写出性能。百度了下发现有好多方法，但是我角色还是自己写个脚本就可以了，无需引用第三方的东西。思路找到文件所造路径，将之拷贝一份到新文件中删除十天前的文件将catalina.out内容清空脚本12345678910111213141516171819202122232425262728293031323334353637# !/bin/base# catalina.out目录log_path=/usr/java/apache-tomcat-7.0.70/logsfile_name=catalina.out#文件绝对路径file_pa=$&#123;log_path&#125;/$&#123;file_name&#125;today=`date +%y%m%d`# 判断文件是否存在if [ ! -d $&#123;log_path&#125;/his ];then mkdir $&#123;log_path&#125;/hisfi# 十天前day_ten_before=`date -d '10 days ago' +%y%m%d`#十天前的文件名file_be=$&#123;log_path&#125;/his/$&#123;file_name&#125;_$&#123;day_ten_before&#125;#当天的文件名file_to=$&#123;log_path&#125;/his/$&#123;file_name&#125;_$&#123;today&#125;#cp文件cp $&#123;file_pa&#125; $&#123;file_to&#125;#清除catalina.out文件内容echo &gt; $&#123;file_pa&#125;#删除十天前切割的日志文件if [ -f $&#123;file_be&#125; ];then rm -rf $&#123;file_be&#125;fi运行结果运行前运行后]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>catalina.out 日志 切割</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx系列(三)配置文件]]></title>
    <url>%2Fnginx%E7%B3%BB%E5%88%97-%E4%B8%89-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[配置文件基本配置worker_processes工作进程是单线程进程。 如果Nginx正在进行CPU密集型工作（如SSL或gzipping），并且您有2个或更多CPU /核心，则可以将worker_processes设置为等于CPU或核心数。 如果您提供大量静态文件并且文件的总大小大于可用内存，那么您可以增加worker_processes以充分利用磁盘带宽。在未配置该内容时，我可以查看我们的进程1234[root@localhost conf]# ps -ef | grep nginxroot 2180 1 0 05:54 ? 00:00:00 nginx: master process /usr/local/nginx/sbin/nginxnobody 2181 2180 0 05:54 ? 00:00:00 nginx: worker processroot 3123 2794 0 06:51 pts/1 00:00:00 grep --color=auto nginx此时可以看到nginx一个为主进程和一个工作进程。nginx有一个主进程和几个工作进程。主进程的主要目的是读取和评估配置，并维护工作进程。工作进程会对请求进行实际处理。nginx使用基于事件的模型和依赖于操作系统的机制来有效地在工作进程之间分发请求。工作进程数在配置文件中定义，可以针对给定配置进行修复，也可以自动调整为可用CPU内核数将1改为2，重新加载然后进行查看进程1234567[root@localhost conf]# vim nginx.conf[root@localhost conf]# ../sbin/nginx -s reload[root@localhost conf]# ps -ef | grep nginxroot 2180 1 0 05:54 ? 00:00:00 nginx: master process /usr/local/nginx/sbin/nginxnobody 3275 2180 0 07:01 ? 00:00:00 nginx: worker processnobody 3276 2180 0 07:01 ? 00:00:00 nginx: worker processroot 3278 2794 0 07:01 pts/1 00:00:00 grep --color=auto nginx默认值为1，官网上说正常情况下1足够了可以设置为CPU核心数，2或者4或者8,再多没有意义(top命令后按1可以查看CPU的核数)如果省事的话设置为autoworker_connetionsmain部分中的worker_connections和worker_processes允许您计算可以处理的最大客户端： max clients = worker_processes * worker_connections也就是说如果worker_processes为2，worker_connetions 为100，那么最大客户端连接数为2*100 = 200。该数值不能超过 worker_rlimite_nofileworker_cpu_affinitynginx默认是没有开启利用多核cpu的配置的。需要通过增加worker_cpu_affinity配置参数来充分利用多核cpu，cpu是任务处理，当计算最费时的资源的时候，cpu核使用上的越多，性能就越好。2核cpu，开启2个进程12worker_processes 2;worker_cpu_affinity 01 10;解释：01表示启用第一个CPU内核，10表示启用第二个CPU内核worker_cpu_affinity 01 10;表示开启两个进程，第一个进程对应着第一个CPU内核，第二个进程对应着第二个CPU内核。2核cpu，开启4个进程12worker_processes 4;worker_cpu_affinity 01 10 01 10;开启了四个进程，它们分别对应着开启2个CPU内核4个cpu，开启4个进程12worker_processes 4;worker_cpu_affinity 0001 0010 0100 1000;0001表示启用第一个CPU内核，0010表示启用第二个CPU内核，依此类推4核cpu，开启2个进程12worker_processes 2;worker_cpu_affinity 0101 1010;0101表示开启第一个和第三个内核，1010表示开启第二个和第四个内核；2个进程对应着四个内核；worker_cpu_affinity配置是写在/etc/nginx/nginx.conf里面的；2核是 01，四核是0001，8核是00000001，有多少个核，就有几位数，1表示该内核开启，0表示该内核关闭。8核cpu，开启8个进程12worker_processes 8;worker_cpu_affinity 00000001 00000010 00000100 00001000 00010000 00100000 01000000 10000000;0001表示启用第一个CPU内核，0010表示启用第二个CPU内核，依此类推；worker_processes最多开启8个，8个以上性能提升不会再提升了，而且稳定性变得更低，所以8个进程够用了说明：配置完之后可以重启nginx，用ab工具或者wrk工具，可以进行性能测试，在服务器上执行top，然后按1，就可以看到cpu工作情况，如果多个cpu内核的利用率差不多，就证明nginx已经成功利用了多核cpu，测试结束后，cpu内核的负载都同时降低。worker_rlimit_nofile语法：1worker_rlimit_nofile 204800;为nginx工作进程改变打开最多文件描述符数目的限制。用来在不重启主进程的情况下增加限制理论上这个值是最多打开文件数（ulimit -n）与nginx工作进程相除。日志配置日志格式nginx日志文件在logs下面access.log 记录请求日志error.log 记录错误日志在配置文件中有配置日志格式话的地方12345log_format main '$remote_addr - $remote_user [$time_local] "$request" ' '$status $body_bytes_sent "$http_referer" ' '"$http_user_agent" "$http_x_forwarded_for"';access_log logs/access.log main;将log_format与access_log前面的注释放开，我们来进行查看日志：1192.168.2.118 - - [27/Jul/2019:07:22:02 -0700] "GET /gms/index2.html HTTP/1.1" 200 429 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36" "-"请求头参数说明示例$remote_addr客户端地址192.168.2.118$remote_user客户端用户名称–$time_local访问时间与时间[27/Jul/2019:07:22:02 -0700]$request请url和http协议“GET /gms/index2.html HTTP/1.1”$status请求状态200$body_bytes_sent发给客户端文件内容大小429$http_refererurl跳转来源-$http_user_agent用户终端浏览器信息Mozilla/5.0 (Windows NT 10.0; Win64; x64)AppleWebKit/537.36 (KHTML, like Gecko)Chrome/74.0.3729.131 Safari/537.36$http_x_forwarded_for被转发的请求的原始IP-$http_host请求地址，即浏览器中你输入的地址$upstream_statusupstream状态$ssl_protocolSSL协议版本$ssl_cipher交换数据中的算法$upstream_addr后台upstream的地址，即真正提供服务的主机地址$request_time整个请求的总时间$upstream_response_time请求过程中，upstream响应时间请求头配置：proxy_set_header X-real-ip $remote_addr其中这个X-real-ip是一个自定义的变量名，名字可以随意取，这样做完之后，用户的真实ip就被放在X-real-ip这个变量里了 ,web端进行获取：request.getHeader(“X-real-ip”)proxy_set_header X-Forwarded-For $remote_addr真实的显示出客户端原始ipproxy_set_header Host $http_host如果想获取客户端访问的头部，可以这样来设置。但是，如果客户端请求头中没有携带这个头部，那么传递到后端服务器的请求也不含这个头部proxy_set_header Host $host个配置相当于上面配置的增强。它的值在请求包含”Host”请求头时为”Host”字段的值，在请求未携带”Host”请求头时为虚拟主机的主域名。proxy_set_header Host $host:$proxy_port服务器名和后端服务器的端口（访问端口）一起传送proxy_set_header &lt;&lt;&lt;*&gt;&gt;&gt; “”请求头的值为空，请求头将不会传送给后端服务器proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for在默认情况下经过proxy转发的请求，在后端看来远程地址都是proxy端的ip 。添加这条配置之后：意思是增加一个$proxy_add_x_forwarded_for到X-Forwarded-For里去，注意是增加，而不是覆盖，当然由于默认的X-Forwarded-For值是空的，所以我们总感觉X-Forwarded-For的值就等于$proxy_add_x_forwarded_for的值，实际上当你搭建两台nginx在不同的ip上，并且都使用了这段配置，那你会发现在web服务器端通过request.getHeader(“X-Forwarded-For”)获得的将会是客户端***ip和第一台*nginx的ip。在第一台nginx中,使用proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;现在的$proxy_add_x_forwarded_for变量的”X-Forwarded-For”部分是空的，所以只有$remote_addr，而$remote_addr的值是用户的ip，于是赋值以后，X-Forwarded-For变量的值就是用户的真实的ip地址了。到了第二台nginx，也使用proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;现在的$proxy_add_x_forwarded_for变量，X-Forwarded-For部分包含的是用户的真实ip，$remote_addr部分的值是上一台nginx的ip地址，于是通过这个赋值以后现在的X-Forwarded-For的值就变成了”用户的真实**ip，第一台nginx的ip**”。日志切割由于日志文件在运行中过大，会导致写入写出以及排查问题的困难，会进行sh脚本进行日志切割，每天进行定时命令进行切割123456789101112#!/bin/bash#设置日志文件存放目录LOG_HOME="/usr/local/nginx/logs/"#备分文件名称LOG_PATH_BAK="$(date -d yesterday +%Y%m%d%H%M)"access.log#重命名日志文件mv $&#123;LOG_HOME&#125;access.log $&#123;LOG_HOME&#125;/$&#123;LOG_PATH_BAK&#125;#向nginx主进程发信号重新打开日志 kill -USR1 `cat /usr/local/nginx/logs/nginx.pid`location配置精准匹配1location =/uri&#123;&#125;优先级最高的匹配，=表示必须与指定的模式精确匹配一般匹配1location /uri&#123;&#125;优先级高于正则匹配，如果存在多个相同的前缀的一般匹配，那么最终会按照最大长度来做匹配正则匹配~ 表示：指定的正则表达式要区分大小写~* 表示：指定的正则表达式不区分大小写^~ 类似于无修饰符的行为，也是以指定模式开始，不同的是，如果模式匹配，那么就停止搜索其他模式了@ ：定义命名location区段，这些区段客户段不能访问，只可以由内部产生的请求来访问，如try_files或error_page等123456789101112131415161718192021222324Location区段匹配示例location = / &#123; # 只匹配 / 的查询. [ configuration A ]&#125;location / &#123; # 匹配任何以 / 开始的查询，但是正则表达式与一些较长的字符串将被首先匹配。 [ configuration B ]&#125;location ^~ /images/ &#123; # 匹配任何以 /images/ 开始的查询并且停止搜索，不检查正则表达式。 [ configuration C ]&#125;location ~* \.(gif|jpg|jpeg)$ &#123; # 匹配任何以gif, jpg, or jpeg结尾的文件，但是所有 /images/ 目录的请求将在Configuration C中处 理。 [ configuration D ]&#125; 各请求的处理如下例：/ → configuration A/documents/document.html → configuration B/images/1.gif → configuration C/documents/1.jpg → configuration Droot 、alias指令区别123location /img/ &#123; alias /var/www/image/;&#125;12&gt; 若按照上述配置的话，则访问/img/目录里面的文件时，ningx会自动去/var/www/image/目录找文件&gt;123location /img/ &#123; root /var/www/image;&#125;12&gt; 若按照这种配置的话，则访问/img/目录下的文件时，nginx会去/var/www/image/img/目录下找文件。&gt;alias是一个目录别名的定义，root则是最上层目录的定义。还有一个重要的区别是alias后面必须要用“/”结束，否则会找不到文件的。。。而root则可有可无~~event配置accept_mutex语法：1accept_mutex on | off ;设置网络连接的序列化 (默认为开启状态)当某一个时刻只有一个网络连接到来时，多个睡眠进程会被同时叫醒，，但只有一个进程可获得连接。如果每次唤醒的进程数太多，会影响一部分系统性能。为解决这样的问题，Nginx配置中包含了一条指令 accept_mutex,当其设置为开启的时候，就会对多个Nginx进程接收连接进行序列化，防止多个进程对连接争抢。multi_accept语法：1multi_accept on | off;设置是否允许同时接收多个网络连接此指令默认为关闭（off）状态，即每个worker process 一次只能接收一个新到达的网络连接。每个Nginx 服务器 的worker process 都有能力同时接收多个新到达的网络连接，但是这需要在配置之文件中进行设置，其指令为multi_acceptuse语法为：1use method;事件驱动模型的选择 -&gt; method可选择的内容有：select , poll、kqueue、cpoll、rtsig、/dev/poll以及wcentport，其中几种模型是比较常用的Nginx 服务器提供了多种事件驱动模型来处理网络消息。配置文件中为我们提供了相关指令来强制 Nginx 服务器选择那种事件驱动模型进行消息处理，其指令为use可以在编译时使用–with-select_module 和 –without-select_module 设置是否强制编译select 模块到 Nginx 内核；使用–with-poll_module 和 –without-poll_module 设置是否强制编译poll模块到 Nginx 内核；worker_connections语法:1worker_connections number;配置最大的连接数指令worker_connections 主要用来社会允许每一个worker process 同时开启的的最大连接数这里的number 不仅仅包括和前端用户建立的连接数，而是包括所有可能的连接数。另外，number 值 不能大于操作系统支持打开的最大文件句柄数量。keepalived介绍Keepalived软件起初是专为LVS负载均衡软件设计的，用来管理并监控LVS集群系统中各个服务节点的状态，后来又加入了可以实现高可用的VRRP (Virtual Router Redundancy Protocol ,虚拟路由器冗余协议）功能。因此，Keepalived除了能够管理LVS软件外，还可以作为其他服务（例如：Nginx、Haproxy、MySQL等）的高可用解决方案软件如何实现故障转移Keepalived高可用服务对之间的故障切换转移，是通过 VRRP 来实现的。在 Keepalived服务正常工作时，主 Master节点会不断地向备节点发送（多播的方式）心跳消息，用以告诉备Backup节点自己还活着，当主 Master节点发生故障时，就无法发送心跳消息，备节点也就因此无法继续检测到来自主 Master节点的心跳了，于是调用自身的接管程序，接管主Master节点的 IP资源及服务。而当主 Master节点恢复时，备Backup节点又会释放主节点故障时自身接管的IP资源及服务，恢复到原来的备用角色。GZIP在进行安装nginx时，依赖中有Gzip，此时我们来进行使用gzip on|off开启或者关闭gzip功能gzip_buffers 4 4k/8k设置系统获取几个单位的缓存用于存储gzip的压缩结果数据流。 例如 4 8k 代表以8k为单位的4倍申请内存gzip_comp_level默认值：1(建议选择为4) gzip压缩比/压缩级别，压缩级别 1-9，级别越高压缩率越大，当然压缩时间也就越长（比较消耗cpu）gzip_types mime-type默认值: gzip_types text/html (默认不对js/css文件进行压缩)一般情况下，在压缩常规文件时可以设置为：gzip_types text/plain application/x-javascript text/css application/xml text/javascript;注意: 图片/mp3这样的二进制文件,不必压缩。因为压缩率比较小, 比如100-&gt;80字节,而且压缩也是耗费CPU资源的。gzip_min_length默认值: 0 ，不管页面多大都压缩 ,设置允许压缩的页面最小字节数，页面字节数从header头中的Content-Length中进行获取。建议设置成大于1k的字节数，小于1k可能会越压越大gzip_http_version 1.0|1.1默认值: gzip_http_version 1.1(就是说对HTTP/1.1协议的请求才会进行gzip压缩)注：99.99%的浏览器基本上都支持gzip解压了。但是假设我们使用的是默认值1.1，如果我们使用了proxy_pass进行反向代理，那么nginx和后端的upstream server之间是用HTTP/1.0协议通信的，如果我们使用nginx通过反向代理做Cache Server，而且前端的nginx没有开启gzip，同时，我们后端的nginx上没有设置gzip_http_version为1.0，那么Cache的url将不会进行gzip压缩gzip_proxied [off|expired|no-cache|no-store|private|no_last_modified|no_etag|auth|any] gzip_proxied [off|expired|no-cache|no-store|private|no_last_modified|no_etag|auth|any]默认值：off，Nginx作为反向代理的时候启用，开启或者关闭后端服务器返回的结果，匹配的前提是后端服务器必须要返回包含”Via”的 header头。off - 关闭所有的代理结果数据的压缩expired - 启用压缩，如果header头中包含 “Expires” 头信息no-cache - 启用压缩，如果header头中包含 “Cache-Control:no-cache” 头信息no-store - 启用压缩，如果header头中包含 “Cache-Control:no-store” 头信息private - 启用压缩，如果header头中包含 “Cache-Control:private” 头信息no_last_modified - 启用压缩,如果header头中不包含 “Last-Modified” 头信息no_etag - 启用压缩 ,如果header头中不包含 “ETag” 头信息auth - 启用压缩 , 如果header头中包含 “Authorization” 头信息any - 无条件启用压缩gzip_vary on | off开启时，将带着 ‘Vary: Accept-Encoding’头域的响应头部，主要功能是告诉浏览器发送的数据经过了压缩处理。开启后的效果是在响应头部添加了Accept-Encoding: gzip，这对于本身不支持Gzip压缩的浏览器是有用的。gzip_disable “MSIE [1-6].”禁用IE6的gzip压缩针对不同类型的浏览器发起的请求，选择性地开启或关闭Gzip功能，支持使用正则表达式。gzip_static on|offnginx对于静态文件的处理模块该模块可以读取预先压缩的gz文件，这样可以减少每次请求进行gzip压缩的CPU资源消耗。该模块启用后，nginx首先检查是否存在请求静态文件的gz结尾的文件，如果有则直接返回该gz文件内容。为了要兼容不支持gzip的浏览器，启用gzip_static模块就必须同时保留原始静态文件和gz文件。这样的话，在有大量静态文件的情况下，将会大大增加磁盘空间。我们可以利用nginx的反向代理功能实现只保留gz文件12345678gzip on; #开启gzip功能gzip_min_length 1024; #响应页面数据上限gzip_buffers 4 16k; #缓存空间大小gzip_http_version 1.1; #http协议版本gzip_comp_level 4; #压缩级别4gzip_types text/plain application/x-javascript text/css application/xml text/javascript;gzip_vary on; #启用压缩标识gzip_static on; #开启文件预压缩文件服务器一些静态资源一般会进行放在文件服务器中123456789101112131415161718192021222324# 文件服务器server &#123; listen 90 default_server; listen [::]:90 default_server; server_name _; #root /usr/share/nginx/html; root /usr/local/nginx/html/upload/; autoindex on;# 显示目录 autoindex_exact_size on;# 显示文件大小 autoindex_localtime on;# 显示文件时间 location / &#123; &#125; error_page 404 /404.html; location = /40x.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125;&#125;参考内容：Nginx系列5：nginx服务器的Gzip压缩nginx+keepalive实现高可用负载均衡详解]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx 负载均衡 配置文件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx系列(一)安装与配置]]></title>
    <url>%2Fnginx%E7%B3%BB%E5%88%97-%E4%B8%80%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[安装与配置安装nginx本博主是在centos7的基础上进行搭建nginx的，可能由于之前搭建的有一些工具，故在安装nginx的时候为安装任何依赖。正常情况我们需要判断下面是否进行安装。gcc g++ 用来编译nginxPCRE库zlib库openssl(某些vps默认没有安装ssl)下载nginx下载地址 nginx下载其中Stable version为稳定版，Legacy versions为历史版本，Mainline version为最新版本。我下载的为Stable version中的nginx-1.16.0查看nginx版本如果不清楚是否安装过nginx，可以进行命令查看版本nginx -v123nginx -v# 结果nginx version: nginx/1.16.0解压与编译将下载好的nginx版本放到虚拟机中，目录自己定义，我选择目录为/usr/java,进行解压 ，并进入解压后文件夹，编译进行启动123456789# 解压文件tar -zxvf nginx-1.16.0# 进入解压文件夹cd nginx-1.16.0/./configure# 编译makemake install由于未进行配置，故在安装的时候安装目录为默认路径 “/usr/local/nginx”nginx启动nginx的启动地址为：/usr/local/nginx/sbin ，下面有nginx命令，进行执行即可启动。查看是否启动成功:12345ps -ef | grep nginx# 结果显示root 52807 1 0 Jul05 ? 00:00:00 nginx: master process ./nginxnobody 52808 52807 0 Jul05 ? 00:00:00 nginx: worker processroot 67376 53051 0 06:16 pts/2 00:00:00 grep --color=auto nginx也可以使用其他命令查看是否启动成功1234567netstat -ntpl# 结果为，本博主仅选取了前几行，可以看到下面最后一行最后显示的有nginxActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 192.168.2.163:6379 0.0.0.0:* LISTEN 18048/./bin/redis-s tcp 0 0 0.0.0.0:111 0.0.0.0:* LISTEN 1/systemd tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 52807/nginx: mnginx停止命令停止12345# 停止[root@localhost sbin]# ./nginx -s stop# 查看进程[root@localhost sbin]# ps -ef | grep nginxroot 67495 53051 0 06:26 pts/2 00:00:00 grep --color=auto nginxkill 进程​ kill 掉master进程12345678[root@localhost sbin]# ps -ef | grep nginxroot 67545 1 0 06:30 ? 00:00:00 nginx: master process ./nginxnobody 67546 67545 0 06:30 ? 00:00:00 nginx: worker processroot 67548 53051 0 06:30 pts/2 00:00:00 grep --color=auto nginx[root@localhost sbin]# kill -9 67545[root@localhost sbin]# ps -ef | grep nginxnobody 67546 1 0 06:30 ? 00:00:00 nginx: worker processroot 67550 53051 0 06:30 pts/2 00:00:00 grep --color=auto nginxnginx配置此时我们的搭载的是两台虚拟机，其中一台装有nginx,两台都有tomcat,此时我们进行配置nginx由于博主版本安装为1.16版的，不同的版本可能配置文件不一样。1/usr/local/nginx/conf在上main目录下，进行修改配置文件nginx.conf，在server上面增加下面内容1234upstream myTomcatServer &#123; server 192.168.2.163:8080; server 192.168.2.228:8080;&#125;在location中增加代理设置123456location / &#123; root html; index index.html index.htm; # 下面一句为增加内容 proxy_pass http://myTomcatServer; &#125;修改后的文件内容为：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167#user nobody;worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; #log_format main '$remote_addr - $remote_user [$time_local] "$request" ' # '$status $body_bytes_sent "$http_referer" ' # '"$http_user_agent" "$http_x_forwarded_for"'; #access_log logs/access.log main; sendfile on; #tcp_nopush on;#user nobody;worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; #log_format main '$remote_addr - $remote_user [$time_local] "$request" ' # '$status $body_bytes_sent "$http_referer" ' # '"$http_user_agent" "$http_x_forwarded_for"'; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; upstream myTomcatServer &#123; server 192.168.2.163:8080; server 192.168.2.228:8080; &#125; server &#123; listen 80; server 192.168.2.163:8080; server 192.168.2.228:8080; &#125; keepalive_timeout 65; #gzip on; upstream myTomcatServer &#123; server 192.168.2.163:8080; server 192.168.2.228:8080; &#125; server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; root html; index index.html index.htm; proxy_pass http://myTomcatServer; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # deny access to .htaccess files, if Apache's document root # concurs with nginx's one # #location ~ /\.ht &#123; # deny all; #&#125; &#125; # another virtual host using mix of IP-, name-, and port-based configuration # #server &#123; # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125; # HTTPS server # #server &#123; # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125;&#125;校验配置文件的正确性命令为：nginx -t123[root@localhost conf]# ../sbin/nginx -tnginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is oknginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful重新加载配置文件命令为：nginx -s reload1[root@localhost conf]# ../sbin/nginx -s reload负载均衡集群校验启动两个环境中的tomcat，进行访问一开始显示无法访问，tomcat启动日常，进行考虑可能由于虚拟机防火墙导致，故将防火墙关闭后发现可以正常访问。防火墙centos7采用的是firewalled查看防火墙状态：123firewall-cmd --state# 结果running关闭并禁止开机启动1234# 关闭防火墙systemctl stop firewalld.service# 禁止开机启动systemctl disable firewalld.service校验输入niginx地址，并加入请求路径，并多次刷新查看结果（默认端口80或者省略不写）1http://192.168.2.163/gms/index.html # nginx地址为163 nginx负载均衡策略上述采用的是默认策略。轮询 -&gt; 默认方式weight -&gt; 权重方式ip_hash -&gt; 依据ip分配方式least_conn -&gt; 最少连接方式fair (第三方) -&gt; 响应时间方式url_hash(第三方) -&gt; 依据url方式轮询最基本的配置方法，上面的例子就是轮询的方式，它是upstream模块默认的负载均衡默认策略。每个请求会按时间顺序逐一分配到不同的后端服务器。参数如下参数参数名称fail_timeout与max_fails结合使用max_fails设置在fail_timeout参数设置的时间内最大失败次数，在这个时间内，所有针对该服务器的请求都失败了，那么认为该服务器会被认为是停机了fail_time服务器会被认为停机的时间长度,默认为10sbackup标记该服务器为备用服务器。当主服务器停止时，请求会被发送到它这里。down标记服务器永久停机了注意：在轮询中，如果服务器down掉了，会自动剔除该服务器缺省配置就是轮询策略此策略适合服务器配置相当，无状态且短平快的服务使用weight权重方式，在轮询策略的基础上指定轮询的几率如下所示：1234upstream myTomcatServer &#123; server 192.168.2.163:8080 weight=2; server 192.168.2.228:8080 max_fails=3 fail_timeout=20s; &#125;weight参数用于指定轮询的几率，weight默认为1，weight的数值与访问比例成正比，比如weight为2 的访问几率是默认为1的2倍。注意:权重越高分配到需要处理的请求越多此策略可以与least_conn和ip_hash结合使用此策略比较适合服务器的硬件配置差别比较大的情况ip_hash指定负载均衡器按照基于客户端IP的分配方式，这个方法确保了相同的客户端的请求一直发送到相同的服务器，以保证session会话。这样每个访客都固定访问一个后端服务器，可以解决session不能跨服务器的问题12345upstream myTomcatServer &#123; ip_hash; server 192.168.2.163:8080 weight=2; server 192.168.2.228:8080 max_fails=3 fail_timeout=20s; &#125;注意：在nginx版本1.3.1之前，不能在ip_hash中使用权重（weight）ip_hash不能与backup同时使用此策略适合有状态服务，比如session当有服务器需要剔除，必须手动down掉least_conn把请求转发给连接数较少的后端服务器。轮询算法是把请求平均的转发给各个后端，使它们的负载大致相同；但是，有些请求占用的时间很长，会导致其所在的后端负载较高。这种情况下，least_conn这种方式就可以达到更好的负载均衡效果。123456upstream myTomcatServer &#123; # ip_hash; least_conn; server 192.168.2.163:8080 weight=2; server 192.168.2.228:8080 max_fails=3 fail_timeout=20s; &#125;注意：此负载均衡策略适合请求处理时间长短不一造成服务器过载的情况第三方策略第三方的负载均衡策略的实现需要安装第三方插件fair在server的下一行增加12345678upstream myTomcatServer &#123; hash $request_url ; #实现每个url定向到同一个后端服务器 # ip_hash; #least_conn; server 192.168.2.163:8080 weight=2; server 192.168.2.228:8080 max_fails=3 fail_timeout=20s; # fair; #实现响应时间短的优先分配 &#125;url_hash按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，要配合缓存命中来使用。同一个资源多次请求，可能会到达不同的服务器上，导致不必要的多次下载，缓存命中率不高，以及一些资源时间的浪费。而使用url_hash，可以使得同一个url（也就是同一个资源请求）会到达同一台服务器，一旦缓存住了资源，再此收到请求，就可以从缓存中读取。12345678upstream myTomcatServer &#123; hash $request_url ; #实现每个url定向到同一个后端服务器 # ip_hash; #least_conn; server 192.168.2.163:8080 weight=2; server 192.168.2.228:8080 max_fails=3 fail_timeout=20s; # fair; #实现响应时间短的优先分配 &#125;]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx 负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx系列(二)session共享]]></title>
    <url>%2Fnginx%E7%B3%BB%E5%88%97-%E4%BA%8C-session%E5%85%B1%E4%BA%AB%2F</url>
    <content type="text"><![CDATA[session共享session共享之redis介绍nginx在解决session的时候有好几种方案ip_hash存放redissession换coolie单独设置一个session服务器tomcat自带的cluster方式考虑到目前自己所工作的项目中，有以下特性经常停服务需要多台服务器分担压力项目从统一用户（SSO）进行单点登录redis可以进行推上去单点登录中的token是实时的，仅仅用来登录时候双方校验，校验过后就不在使用，也没有提供接口进行二次校验token的正确性。测试环境中由于redis已经搭建，但是由于种种原因为上线，正好借此机会进行推上去。根据上述情况，决定采用redis进行存储session,保证session共享。在写博客之前，博主在开发的测试环境进行试验，最后实现了该功能。使用redis的话现在需要 tomcat-redis-session-manager.jar包，目前该链接仅仅支持到tomcat7，点击链接进行下载 tomcat-redis-session-manager编译通过上面下载的内容，但是上面没有jar包，此时需要我们进行编辑为jar包。编译工具使用的为gradle，类似于maven的一样就行配置环境变量。首先解压后，修改其中的build.gradle文件，修改后内容如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102apply plugin: 'java'apply plugin: 'maven'apply plugin: 'signing'group = 'com.orangefunction'version = '2.0.0'repositories &#123; mavenCentral()&#125;compileJava &#123; // 指定jdk版本 sourceCompatibility = 1.8 targetCompatibility = 1.8&#125;dependencies &#123; compile group: 'org.apache.tomcat', name: 'tomcat-catalina', version: '7.0.70' compile group: 'redis.clients', name: 'jedis', version: '2.8.1' compile group: 'org.apache.commons', name: 'commons-pool2', version: '2.2' //compile group: 'commons-codec', name: 'commons-codec', version: '1.9' testCompile group: 'junit', name: 'junit', version: '4.+' testCompile 'org.hamcrest:hamcrest-core:1.3' testCompile 'org.hamcrest:hamcrest-library:1.3' testCompile 'org.mockito:mockito-all:1.9.5' testCompile group: 'org.apache.tomcat', name: 'tomcat-coyote', version: '7.0.70'&#125;task javadocJar(type: Jar, dependsOn: javadoc) &#123; classifier = 'javadoc' from 'build/docs/javadoc'&#125;task sourcesJar(type: Jar) &#123; from sourceSets.main.allSource classifier = 'sources'&#125;artifacts &#123; archives jar archives javadocJar archives sourcesJar&#125;// 要进行注释掉//signing &#123; //sign configurations.archives//&#125;uploadArchives &#123; repositories &#123; mavenDeployer &#123; beforeDeployment &#123; MavenDeployment deployment -&gt; signing.signPom(deployment) &#125; // 注释掉 // repository(url: "https://oss.sonatype.org/service/local/staging/deploy/maven2/") &#123; // authentication(userName: sonatypeUsername, password: sonatypePassword) //&#125; //repository(url: "https://oss.sonatype.org/content/repositories/snapshots") &#123; // authentication(userName: sonatypeUsername, password: sonatypePassword) //&#125; pom.project &#123; name 'tomcat-redis-session-manager' packaging 'jar' description 'Tomcat Redis Session Manager is a Tomcat extension to store sessions in Redis' url 'https://github.com/jcoleman/tomcat-redis-session-manager' issueManagement &#123; url 'https://github.com:jcoleman/tomcat-redis-session-manager/issues' system 'GitHub Issues' &#125; scm &#123; url 'https://github.com:jcoleman/tomcat-redis-session-manager' connection 'scm:git:git://github.com/jcoleman/tomcat-redis-session-manager.git' developerConnection 'scm:git:git@github.com:jcoleman/tomcat-redis-session-manager.git' &#125; licenses &#123; license &#123; name 'MIT' url 'http://opensource.org/licenses/MIT' distribution 'repo' &#125; &#125; developers &#123; developer &#123; id 'jcoleman' name 'James Coleman' email 'jtc331@gmail.com' url 'https://github.com/jcoleman' &#125; &#125; &#125; &#125; &#125;&#125;然后我们可以更改java与依赖包的版本，上述为本人编译成功后的文件，大家可以直接进行复制替换。在tomcat-redis-session-manager-1.2-tomcat-7下进行编译，命令为1gradle build编译后在build /lib 下会生成jar包 tomcat-redis-session-manager-master-2.0.0.jar注意：上述依赖的包一定要与我们实际的tomcat版本一直，jdk版本一直，而且上面用到的包的版本，会在下面配置中进行使用。配置首先说明需要的包：tomcat-redis-session-manager-master-2.0.0.jarjedis-2.8.1.jarcommons-pool2-2.2.jar操作步骤（每台服务器都要进行操作）将上述的包放在tomcat目录下的lib中保证上述包与编译包的版本一致修改context配置文件（tomcat下conf目录中的context.xml)123456&lt;Valve className=&quot;com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve&quot; /&gt;&lt;Manager className=&quot;com.orangefunction.tomcat.redissessions.RedisSessionManager&quot; host=&quot;192.168.2.163&quot; port=&quot;6379&quot; database=&quot;0&quot; maxInactiveInterval=&quot;60&quot; /&gt;其中要保证value与manager标签中的className保持一致（可以解压jar包，得到路径）分别启动tomcat博主是在两台服务器上进行搭建的，此时要进行启动，并正常访问（此时nginx为启动）开启nginx并访问启动nginx，可以参考上篇博客，结果如下图 tomcat中session同步在有些时候我们需要进行用tomcat自带的session同步，比较简答以及不需要redis；介绍 Clustertomcat自带的session同步是根据组播的形式的，大家加入一个组来进行实现session同步。当时由于是内网环境进行搭建，在上述为成功的刺激下尝试使用这种方式，很遗憾，家里在tomcat8的基础上进行搭建起来了，但是tomcat7未成功。下面讲的是在tomct8的基础上进行的。配置 Cluster此时与上述redis实现redis共享不一致，此时修改的conf下的server.xml，直接上代码,在下面增加，也就是在Engine 标签中1234567891011121314151617181920212223242526272829303132333435363738394041&lt;Cluster className="org.apache.catalina.ha.tcp.SimpleTcpCluster" channelSendOptions="8"&gt; &lt;Manager className="org.apache.catalina.ha.session.DeltaManager" expireSessionsOnShutdown="false" notifyListenersOnReplication="true"/&gt; &lt;Channel className="org.apache.catalina.tribes.group.GroupChannel"&gt; &lt;Membership className="org.apache.catalina.tribes.membership.McastService" &lt;!-- 该地址不能修改，用于组播，当配置相同的address 与 端口时候就会组成一下组，session在组内进行传播 --&gt; address="228.0.0.4" port="45564" frequency="500" dropTime="3000"/&gt; &lt;Receiver className="org.apache.catalina.tribes.transport.nio.NioReceiver" &lt;!-- 该地址可以修改为aotu,如果报错的话也可以修改为ip地址，但是注意的是如果是同一个服务器上的两个tomcat，需要修改端口号保证端口号不能重复 --&gt; address="auto" port="4000" autoBind="100" selectorTimeout="5000" maxThreads="6"/&gt; &lt;Sender className="org.apache.catalina.tribes.transport.ReplicationTransmitter"&gt; &lt;Transport className="org.apache.catalina.tribes.transport.nio.PooledParallelSender"/&gt; &lt;/Sender&gt; &lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.TcpFailureDetector"/&gt; &lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.MessageDispatchInterceptor"/&gt; &lt;/Channel&gt; &lt;Valve className="org.apache.catalina.ha.tcp.ReplicationValve" filter=""/&gt; &lt;Valve className="org.apache.catalina.ha.session.JvmRouteBinderValve"/&gt; &lt;Deployer className="org.apache.catalina.ha.deploy.FarmWarDeployer" tempDir="/tmp/war-temp/" deployDir="/tmp/war-deploy/" watchDir="/tmp/war-listen/" watchEnabled="false"/&gt; &lt;ClusterListener className="org.apache.catalina.ha.session.ClusterSessionListener"/&gt; &lt;/Cluster&gt;上面的代码要在两个tomcat上进行添加此时在项目中的web.xml上增加标签1&lt;distributable/&gt;启动中看到部分日志：1234567810-Jul-2019 08:16:01.090 INFO [main] org.apache.catalina.ha.tcp.SimpleTcpCluster.startInternal Cluster is about to start10-Jul-2019 08:16:01.108 INFO [main] org.apache.catalina.tribes.transport.ReceiverBase.bind Receiver Server Socket bound to:[/192.168.2.163:4000]10-Jul-2019 08:16:01.125 INFO [main] org.apache.catalina.tribes.membership.McastServiceImpl.setupSocket Setting cluster mcast soTimeout to [500]10-Jul-2019 08:16:01.132 INFO [main] org.apache.catalina.tribes.membership.McastServiceImpl.waitForMembers Sleeping for [1000] milliseconds to establish cluster membership, start level:[4]10-Jul-2019 08:16:02.133 INFO [main] org.apache.catalina.tribes.membership.McastServiceImpl.waitForMembers Done sleeping, membership established, start level:[4]10-Jul-2019 08:16:02.139 INFO [main] org.apache.catalina.tribes.membership.McastServiceImpl.waitForMembers Sleeping for [1000] milliseconds to establish cluster membership, start level:[8]10-Jul-2019 08:16:03.140 INFO [main] org.apache.catalina.tribes.membership.McastServiceImpl.waitForMembers Done sleeping, membership established, start level:[8]10-Jul-2019 08:16:03.144 SEVERE [main] org.apache.catalina.ha.deploy.FarmWarDeployer.start FarmWarDeployer can only work as host cluster subelement!另外一台启动日志1234567891010-Jul-2019 08:19:32.360 INFO [main] org.apache.catalina.ha.tcp.SimpleTcpCluster.startInternal Cluster is about to start10-Jul-2019 08:19:32.374 INFO [main] org.apache.catalina.tribes.transport.ReceiverBase.bind Receiver Server Socket bound to:[/192.168.2.228:4000]10-Jul-2019 08:19:32.398 INFO [main] org.apache.catalina.tribes.membership.McastServiceImpl.setupSocket Setting cluster mcast soTimeout to [500]10-Jul-2019 08:19:32.426 INFO [main] org.apache.catalina.tribes.membership.McastServiceImpl.waitForMembers Sleeping for [1000] milliseconds to establish cluster membership, start level:[4]10-Jul-2019 08:19:32.460 INFO [Membership-MemberAdded.] org.apache.catalina.ha.tcp.SimpleTcpCluster.memberAdded Replication member added:[org.apache.catalina.tribes.membership.MemberImpl[tcp://&#123;192, 168, 2, 163&#125;:4000,&#123;192, 168, 2, 163&#125;,4000, alive=211314, securePort=-1, UDP Port=-1, id=&#123;80 -3 -97 73 -77 -63 65 -56 -69 32 -65 -51 -106 61 -81 79 &#125;, payload=&#123;&#125;, command=&#123;&#125;, domain=&#123;&#125;, ]]10-Jul-2019 08:19:33.428 INFO [main] org.apache.catalina.tribes.membership.McastServiceImpl.waitForMembers Done sleeping, membership established, start level:[4]10-Jul-2019 08:19:33.461 INFO [main] org.apache.catalina.tribes.membership.McastServiceImpl.waitForMembers Sleeping for [1000] milliseconds to establish cluster membership, start level:[8]10-Jul-2019 08:19:33.628 INFO [Tribes-Task-Receiver[Catalina-Channel]-1] org.apache.catalina.tribes.io.BufferPool.getBufferPool Created a buffer pool with max size:[104857600] bytes of type: [org.apache.catalina.tribes.io.BufferPool15Impl]10-Jul-2019 08:19:34.462 INFO [main] org.apache.catalina.tribes.membership.McastServiceImpl.waitForMembers Done sleeping, membership established, start level:[8]10-Jul-2019 08:19:34.467 SEVERE [main] org.apache.catalina.ha.deploy.FarmWarDeployer.start FarmWarDeployer can only work as host cluster subelement! 上述用到的页面代码如下:1234567891011121314151617181920212223242526272829303132333435&lt;%@ page contentType="text/html; charset=UTF-8" %&gt; &lt;%@ page import="java.util.*" %&gt; &lt;html&gt;&lt;head&gt;&lt;title&gt;Tomcat Cluster Demo&lt;/title&gt;&lt;/head&gt; &lt;body&gt; Server Info: &lt;% out.println(request.getLocalAddr() + " : " + request.getLocalPort()+"&lt;br&gt;");%&gt; &lt;% out.println("&lt;br&gt; ID " + session.getId()+"&lt;br&gt;"); String dataName = request.getParameter("dataName"); if (dataName != null &amp;&amp; dataName.length() &gt; 0) &#123; String dataValue = request.getParameter("dataValue"); session.setAttribute(dataName, dataValue); System.out.println("application:" + application.getAttribute(dataName)); application.setAttribute(dataName, dataValue); &#125; out.print("&lt;b&gt;Session List&lt;/b&gt;"); Enumeration&lt;String&gt; e = session.getAttributeNames(); while (e.hasMoreElements()) &#123; String name = e.nextElement(); String value = session.getAttribute(name).toString(); out.println( name + " = " + value+"&lt;br&gt;"); System.out.println( name + " = " + value); &#125; %&gt; &lt;form action="test.jsp" method="POST"&gt; Name:&lt;input type=text size=20 name="dataName"&gt; &lt;br&gt; Value:&lt;input type=text size=20 name="dataValue"&gt; &lt;br&gt; &lt;input type=submit&gt; &lt;/form&gt; &lt;/body&gt; &lt;/html&gt;]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx 负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo 百度收录]]></title>
    <url>%2Fhexo-%E7%99%BE%E5%BA%A6%E6%94%B6%E5%BD%95%2F</url>
    <content type="text"><![CDATA[hexo 收录百度收录域名申请搭建博客，但是如何让更多的人能够看到自己的博客呢？当然是让搜索引擎找到我们的博客了，那么就需要让搜索引擎找到我们的博客。在国内百度进行搜索的概率很大，网络长城基本上让我们离谷歌的世界有点远。搜索我们的网址，因写博客时网址已经被收录，此时我们输入一个未收录的域名。此时点击提交网址，将链接地址进行提交。或者选择 用户中心 ==&gt; 站点管理==&gt;添加网站==&gt;输入网址==&gt;网址校验本博主域名为wsylp.top 因此网址为wsylp.top。域名校验：我们选择的为CNAME校验。将给出的信息在域名解析中进行配置即可，建议不要删除。本博主与2018年11月份申请域名博客进行搭建博客，折腾多次终于在百度站长上看到提交记录了。中间的心酸真是**。sitemap提交最简单的方式使用sitemap提交，不过效果很差百度收录很慢，不过对于谷歌来说sitemap还是很紧简单的。安装插件12npm install hexo-generator-sitemap --save npm install hexo-generator-baidu-sitemap --save修改站点下配置文件_config.yml中url内容：123456#URL## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'url: http://wsylp.toproot: /permalink: :year/:month/:day/:title/permalink_defaults:我们可以在public的目录下看到 baidusitemap.xml、sitemap.xmlbaidusitemap.xml 用于百度sitemap.xml 用于谷歌等其他搜索引擎在百度站长==&gt;链接提交==&gt;自动提交==&gt;sitemap==&gt;输入数据文件地址（http://wsylp.top/baidusitemap.xml）将域名换掉即可。 主动推送现阶段hexo已经集成了主动提交的功能，只需要安装插件即可。安装插件我们需要在hexo根目录安装插件1npm install hexo-baidu-url-submit --save修改跟目录下配置文件_config.yml发布选择配置1234567deploy:- type: git repo: coding: git@git.dev.tencent.com:wsylp/wsylp.coding.me.git github: git@github.com:wsylp/wsylp.github.io.git branch: master- type: baidu_url_submitter提交信息配置12345baidu_url_submit: count: 3 # 提交最新的三个链接 host: wsylp.top # 在百度站长平台中注册的域名 token: ***** # 请注意这是您的秘钥， 所以请不要把博客源代码发布在公众仓库里! path: baidu_urls.txt # 文本文档的地址， 新链接会保存在此文本文档里将上述host换为自己的域名，token为百度站长提供的密钥新链接的产生： hexo g 会产生一个文本文件，里面包含最新的链接新链接的提交： hexo d 会从上述文件中读取链接，提交至百度搜索引擎。成功信息1234567INFO Deploying: baidu_url_submitterINFO Submitting urlshttp://wsylp.top/2019/06/03/hexo-百度收录/http://wsylp.top/2019/06/03/hexo-主题配置/http://wsylp.top/2019/06/01/Spring-Boot初体验（二）配置文件/&#123;"remain":4999997,"success":3&#125;INFO Deploy done: baidu_url_submitter{“remain”:4999997,”success”:3} 这个为百度返回的成功的信息。一般提交成功后，一天之后就可以在百度站长上看到提交的数目（如果之前提交过是不进行计算的）]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo 主题配置]]></title>
    <url>%2Fhexo-%E4%B8%BB%E9%A2%98%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[hexo 主题配置首页概览搭建好hexo后，我们发现正常的情况下首页显示的为一片博客的全部内容，这样就会导致我们一直下拉才可以找到下一篇博客，很繁琐，我们想要看到该博客的概览即可。打开theme主题下的_config.yml，找到auto_excerpt，将enable改为true。12345# Automatically Excerpt. Not recommend.# Please use &lt;!-- more --&gt; in the post to control excerpt accurately.auto_excerpt: enable: true length: 150下面有两个对比图，一个为改之前的，一个为改之后的。 自定义样式在使用的过程中发现hexo 6 默认的为水平实线为虚线，看起来好丑。故才进行改动。在进行改动的过程中发现使用F12快捷键。首先打开我们的F12，选择选择器，查看信息。将hr的标签内容复制下，然后改为我们想要的结果。自定义样式放在theme==&gt;next==&gt;source==&gt;css==&gt;_custom==&gt;custom.style文件中。123456789101112131415161718192021// Custom styles.// 主页文章添加阴影效果 .post &#123; margin-top: 60px; margin-bottom: 60px; padding: 25px; -webkit-box-shadow: 0 0 5px rgba(202, 203, 203, .5); -moz-box-shadow: 0 0 5px rgba(202, 203, 204, .5); &#125; //将hr改为实线 hr &#123; margin: 40px 0; height: 3px; border: none; background-color: #ddd; background-image: none;&#125;//将h2、h3、h4、h5、h6标签的颜色进行改变h2,h3,h4,h5,h6 &#123; color: #92b10b;&#125;上述为我的修改内容，上面注释也很清楚看板娘也就是下面的小姑娘了。安装 hexo-helper-live2d1npm install --save hexo-helper-live2d安装模板1npm install live2d-widget-model-z16配置在主题配置文件中增加：12345678910111213141516live2d: enable: true scriptFrom: local pluginRootPath: live2dw/ pluginJsPath: lib/ pluginModelPath: assets/ tagMode: false debug: false model: use: live2d-widget-model-z16 display: position: right width: 280 height: 700 mobile: show: true模板预览地址：https://huaji8.top/post/live2d-plugin-2.0/12345678910111213141516171819202122live2d-widget-model-chitoselive2d-widget-model-epsilon2_1live2d-widget-model-gflive2d-widget-model-haru/01 (use npm install --save live2d-widget-model-haru)live2d-widget-model-haru/02 (use npm install --save live2d-widget-model-haru)live2d-widget-model-harutolive2d-widget-model-hibikilive2d-widget-model-hijikilive2d-widget-model-izumilive2d-widget-model-koharulive2d-widget-model-mikulive2d-widget-model-ni-jlive2d-widget-model-nicolive2d-widget-model-nietzschelive2d-widget-model-nipsilonlive2d-widget-model-nitolive2d-widget-model-shizukulive2d-widget-model-tororolive2d-widget-model-tsumikilive2d-widget-model-unitychanlive2d-widget-model-wankolive2d-widget-model-z16加载速度hexo的加载速度太慢，每次进行打开时会经过相对来说较长的时间。采用压缩js、css、html的方式来提高速度。安装gulp1npm install -g gulp安装依赖：12345gulp-htmlclean // 清理htmlgulp-htmlmin // 压缩htmlgulp-minify-css // 压缩cssgulp-uglify // 混淆jsgulp-imagemin // 压缩图片执行命令：1npm install gulp-htmlclean gulp-htmlmin gulp-minify-css gulp-uglify gulp-imagemin --save在博客根目录下创建文件gulpfile.js123456789101112131415161718192021222324252627282930313233343536373839404142434445464748var gulp = require('gulp');var minifycss = require('gulp-minify-css');var uglify = require('gulp-uglify');var htmlmin = require('gulp-htmlmin');var htmlclean = require('gulp-htmlclean');var imagemin = require('gulp-imagemin');// 压缩htmlgulp.task('minify-html', function() &#123; return gulp.src('./public/**/*.html') .pipe(htmlclean()) .pipe(htmlmin(&#123; removeComments: true, minifyJS: true, minifyCSS: true, minifyURLs: true, &#125;)) .pipe(gulp.dest('./public'))&#125;);// 压缩cssgulp.task('minify-css', function() &#123; return gulp.src('./public/**/*.css') .pipe(minifycss(&#123; compatibility: 'ie8' &#125;)) .pipe(gulp.dest('./public'));&#125;);// 压缩jsgulp.task('minify-js', function() &#123; return gulp.src('./public/js/**/*.js') .pipe(uglify()) .pipe(gulp.dest('./public'));&#125;);// 压缩图片gulp.task('minify-images', function() &#123; return gulp.src('./public/images/**/*.*') .pipe(imagemin( [imagemin.gifsicle(&#123;'optimizationLevel': 3&#125;), imagemin.jpegtran(&#123;'progressive': true&#125;), imagemin.optipng(&#123;'optimizationLevel': 7&#125;), imagemin.svgo()], &#123;'verbose': true&#125;)) .pipe(gulp.dest('./public/images'))&#125;);// 默认任务gulp.task('default', gulp.parallel( 'minify-html','minify-css','minify-js','minify-images'));第一次先运行hexo clean ==&gt; hexo g ==&gt; gulp1234567891011121314151617181920212223242526272829303132333435$ gulp[07:41:28] Using gulpfile F:\github\hexo\gulpfile.js[07:41:28] Starting &apos;default&apos;...[07:41:28] Starting &apos;minify-html&apos;...[07:41:28] Starting &apos;minify-css&apos;...[07:41:28] Starting &apos;minify-js&apos;...[07:41:28] Starting &apos;minify-images&apos;...[07:41:29] gulp-imagemin: ✔ algolia_logo.svg (saved 36 B - 0.8%)[07:41:30] Finished &apos;minify-css&apos; after 1.83 s[07:41:30] gulp-imagemin: ✔ cc-by-nc-nd.svg (saved 7.46 kB - 67.5%)[07:41:30] gulp-imagemin: ✔ cc-by-nc-sa.svg (saved 7.86 kB - 66.7%)[07:41:30] gulp-imagemin: ✔ avatar.gif (saved 1.14 kB - 39%)[07:41:30] gulp-imagemin: ✔ cc-by-nc.svg (saved 6.69 kB - 68.3%)[07:41:30] gulp-imagemin: ✔ alipay.jpg (saved 25.9 kB - 21.7%)[07:41:30] gulp-imagemin: ✔ cc-by-nd.svg (saved 6.45 kB - 67.9%)[07:41:30] gulp-imagemin: ✔ apple-touch-icon-next.png (saved 190 B - 12.3%)[07:41:30] gulp-imagemin: ✔ cc-by-sa.svg (saved 7 kB - 67.5%)[07:41:30] gulp-imagemin: ✔ cc-by.svg (saved 5.83 kB - 69.4%)[07:41:30] gulp-imagemin: ✔ cc-zero.svg (saved 2.15 kB - 34.3%)[07:41:30] Finished &apos;minify-js&apos; after 2.38 s[07:41:30] gulp-imagemin: ✔ logo.svg (saved 780 B - 73.7%)[07:41:30] gulp-imagemin: ✔ quote-l.svg (saved 414 B - 46.4%)[07:41:30] gulp-imagemin: ✔ quote-r.svg (saved 410 B - 46.6%)[07:41:31] gulp-imagemin: ✔ loading.gif (already optimized)[07:41:31] gulp-imagemin: ✔ favicon-16x16-next.png (saved 150 B - 34.5%)[07:41:31] gulp-imagemin: ✔ favicon-32x32-next.png (saved 152 B - 23.8%)[07:41:31] gulp-imagemin: ✔ placeholder.gif (already optimized)[07:41:31] gulp-imagemin: ✔ searchicon.png (saved 37 B - 4.8%)[07:41:31] gulp-imagemin: ✔ wechatpay.jpg (saved 17.7 kB - 17.9%)[07:41:31] gulp-imagemin: ✔ wsylp.jpg (saved 21.5 kB - 31.5%)[07:41:31] gulp-imagemin: ✔ wsylp1.jpg (saved 21.1 kB - 33.9%)[07:41:31] gulp-imagemin: Minified 20 images (saved 133 kB - 31%)[07:41:31] Finished &apos;minify-images&apos; after 3 s[07:41:33] Finished &apos;minify-html&apos; after 4.76 s[07:41:33] Finished &apos;default&apos; after 4.77 s进行发布 hexo d]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM之运行时数据区（二）方法区与堆]]></title>
    <url>%2FJVM%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA%EF%BC%88%E4%BA%8C%EF%BC%89%E6%96%B9%E6%B3%95%E5%8C%BA%E4%B8%8E%E5%A0%86%2F</url>
    <content type="text"><![CDATA[方法区与堆上篇博客讲到程序计数器与虚拟机栈，这次我们来聊一聊方法区与堆（Heap），还有本地方法栈。本地方法栈简单的说本地方法栈我们没有必要了解太多，本地方法栈（Native Method Stack）的作用域虚拟机栈所发挥的作用类似，不过通过名字我们也能推测出，本地方法栈是用来执行Native方法的。它也会抛出stackOverflowerror和OutOfMemoryError。堆Heap我们先来看下这幅图先来了解下:java中的堆是java虚拟机中所管理的内存中最大的一块。从上面的图片中我们可以按到。java Heap是被线程共享的。在java虚拟机规范中说明：所有对象实例以及数组都要在堆上进行分配，但是随着JIT编译器的发展与逃逸分析技术的逐渐成熟，栈上分配、标量替换技术将会导致一些微妙的变化发生，所有对象都分配在堆上也不在那么绝对了，也就是说堆是用来存放对象的空间，几乎所有的对象都存储在堆中。我们也通过我所画的图形颜色可以看出java中的堆分为新生代与老年代，而新生代有分为Eden空间，From Survivor空间、To Survivor空间，也就是上图中的Eden、s0、s1。我们在这里先简单介绍下几个概念，至于新生代，老年代以及Eden 与survivor之间的比例如何划分，还有对象如何存放的，我们会在后面的垃圾回收器中会讲到内存的分配策略。新生代：英文为Young Generation也叫年轻代，通过字面意思，在根据新生代是在堆中我们可以理解为新创建的对象存放的内存空间，但是注意的是由于新生代也有空间的，并不能保证最有的对象会分配到新生代中，一些大对象（需要大量连续内存空间的java对象，例如很长的字符串以及数组：new Byte[100*1024*1024]）。老年代：除了上面所说的大对象放在老年代里，还有一部分是“年龄大”的对象，由于对象的生命周期不一致，有的很早就夭折了，有的比较坚强存活时间长，虚拟机就把这些”老货“安置到老年代中，具体如何进行区分是“老年”与“新生”，我们在后面再进行介绍。Eden：是新生代的一部分，其实在进行划分细的话，新创建的对象时放在新生代中的Eden空间的。Survivor：翻译中文为“幸存”的意思，java虚拟机在开始的时候会将From Survivor 与Eden进行存放对象，在空间满的时候会进行GC(回收)，虚拟机会把存活的对象放在To Survivor空间中（如果存放的下的话），然后清空From Survivor+Eden,然后使用To Survivor 与Eden ,当下次进行GC时，虚拟机将Eden+To Survivor中存活的对象放入From Survivor，以此类推。永久代： 指内存的永久保存区域，主要存放Class和Meta（元数据）的信息,Class在被加载的时候被放入永久区域. 它和和存放实例的区域不同,GC不会在主程序运行期对永久区域进行清理。所以这也导致了永久代的区域会随着加载的Class的增多而胀满，最终抛出OOM异常。不过在jdk1.8之后被移除。Metaspace（ 元空间）：从JDK 8开始，Java开始使用元空间取代永久代，元空间并不在虚拟机中，而是直接使用本地内存。方法区方法区（Method Area）用来存储已经被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。从之前的图中我们也可以看到它与java 对一样也是线程共享的，也可以叫做非堆（Non_Heap）。有点需要说明的是部分人将方法区成为“永久代”，实际上两者本质上不同，在HotSpot虚拟机上，把GC分代收集扩展至方法区，这样就可以使用java虚拟机来进行管理这部分内存。到了这个地方我们需要进行分析下，在jdk8中将“永久代”给移除了，那么我们犯迷糊“永久代”，“方法区”到底是什么概念以及jdk中的元数据又是什么？这里我们先来一个个分析jdk7之前：方法区位于永久代（PermGen）, 永久代和堆相互隔离，永久代的大小在启动JVM虚拟机的时可以设定一个固定值，不可变。jdk7中：存储在永久代的部分数据就已经转移到Java Heap或者Native Memory（本地内存，也称为C-Heap，是JVM自身进程使用的，空间不足时不会触发GC），但是永久代依然存在，没有完全移除。 JDK 7的HotSpot VM是把Symbol的存储从PermGen移动到了native memory，并且把静态变量从instanceKlass末尾（位于PermGen内）移动到了java.lang.Class对象的末尾（位于普通Java heap内）。“常量池”如果说的是SymbolTable（符号引用） / StringTable（字符串常量），这俩table自身原本就一直在native memory里，是它们所引用的东西在哪里更有意义。JDK7是把SymbolTable引用的Symbol移动到了native memory，而StringTable引用的java.lang.String实例则从PermGen移动到了普通Java heap（譬如符号引用(Symbols)转移到了native memory；字符串常量池(interned strings)转移到了Java heap；类的静态变量(class statics)转移到了Java heap）。jdk8中：取消永久代，方法存放于元空间（Metaspace），元空间仍然与堆不相连，但是与堆共享物理内存，逻辑上可认为在堆中。为什么要移除永久代？字符串存在永久代中，容易出现性能问题和内存溢出；永久代大小不容易确定，PermSize指定太小容易造成永久代OOM；永久代会为GC带来不必要的复杂度，并且回收率偏低；oracle将HotSpot与JRockit合二为一；我们这里简单测试下：12345678910111213141516package jvm;import java.util.ArrayList;import java.util.List;public class StringOomMock &#123; static String base = "string"; public static void main(String[] args) &#123; List&lt;String&gt; list = new ArrayList&lt;String&gt;(); for (int i=0;i&lt; Integer.MAX_VALUE;i++)&#123; String str = base + base; base = str; list.add(str.intern()); &#125; &#125;&#125;运行的结果如下，抛出的为Java heap溢出，我们可以判断出字符串在1.8中不是存在永久代而是java堆中。123456Exception in thread "main" java.lang.OutOfMemoryError: Java heap space at java.util.Arrays.copyOf(Arrays.java:3332) at java.lang.AbstractStringBuilder.ensureCapacityInternal(AbstractStringBuilder.java:124) at java.lang.AbstractStringBuilder.append(AbstractStringBuilder.java:448) at java.lang.StringBuilder.append(StringBuilder.java:136) at jvm.StringOomMock.main(StringOomMock.java:11)下面我们进行测试Metaspace溢出，记得设置参数“-XX:MetaspaceSize=10M -XX:MaxMetaspaceSize=20M”123456789101112131415161718192021222324252627282930313233package jvm;import java.io.File;import java.net.URL;import java.net.URLClassLoader;import java.util.ArrayList;import java.util.List;/** * Metaspace溢出 * @author wsylp * */public class MetaspaceOOMTest &#123; public static void main(String[] args) &#123; try &#123; //准备url URL url = new File("C:\\Users\\wsylp\\Desktop\\study\\性能优化\\code").toURI().toURL(); URL[] urls = &#123;url&#125;; //获取有关类型加载的JMX接口 //用于缓存类加载器 List&lt;ClassLoader&gt; classLoaders = new ArrayList&lt;ClassLoader&gt;(); while (true) &#123; //加载类型并缓存类加载器实例 ClassLoader classLoader = new URLClassLoader(urls); classLoaders.add(classLoader); classLoader.loadClass("HelloWorld2"); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;运行结果如下12345678910111213Exception in thread "main" java.lang.OutOfMemoryError: Metaspace at java.lang.ClassLoader.defineClass1(Native Method) at java.lang.ClassLoader.defineClass(ClassLoader.java:763) at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142) at java.net.URLClassLoader.defineClass(URLClassLoader.java:467) at java.net.URLClassLoader.access$100(URLClassLoader.java:73) at java.net.URLClassLoader$1.run(URLClassLoader.java:368) at java.net.URLClassLoader$1.run(URLClassLoader.java:362) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:361) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) at jvm.MetaspaceOOMTest.main(MetaspaceOOMTest.java:24)我们可以看出JDK8中永久代已经被移除了，换成了元空间（Metaspace）。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>运行时数据区</tag>
        <tag>Java Heap</tag>
        <tag>方法区</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM之运行时数据区（一）程序计数器与虚拟机栈]]></title>
    <url>%2FJVM%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA%EF%BC%88%E4%B8%80%EF%BC%89%E7%A8%8B%E5%BA%8F%E8%AE%A1%E6%95%B0%E5%99%A8%E4%B8%8E%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88%2F</url>
    <content type="text"><![CDATA[程序计数器与虚拟机栈什么是JVM我们首先通过一张图来了解下虚拟机在上图中我们能够清晰的看出，我们锁写的代码“HellloWorld.java”编译为class文件，class文件达到的目的就是“WORE”,一次编译导出运行（”Write Once Run Everywhere”）, 单数如何达到在linux，windows，Mac等各类计算机中达到运行的呢？常规机器仅仅识别“010101”，也就是识别数字”1“和“0”，这就需要依赖我们的JVM虚拟机了。我们的代码运行在虚拟机上，虚拟机帮助我们将class文件转化为机器所能识别运行的语言。功能：负责翻译功能，让机器能够识别我们写的代码管理内存，可以帮我们来管理内存。为什么学习虚拟机呢？正常情况下我们不需要关心虚拟机的内存情况，由虚拟机进行帮我们进行管理内存，但是如果一旦出现内存泄漏或者溢出，我们就很难排查错误。运行时数据区java虚拟机在执行java程序的执行过程中会把他所管理的内存划分为若干个不同的数据区域。这些区域有着各自的用途，以及创建和销毁时间，有的区域随着虚拟机进程的启动而存在，有的区域则依赖用户线程的启动和结束而建立和销毁。在虚拟机规范里面，java虚拟机将包括一下的运行时数据区。程序计数器程序计数器（program Counter Register）：指向当前线程正在执行的字节码指令的地址 行号简单的说就是当前的线程走到哪一步，进行记录下来，因为CPU在整个执行的过程中可能会发生抢占式，也就是这个线程没有执行结束而去执行其他的线程，不那么当前的信息需要保存下来。在虚拟机的概念模型里，字节码解释器工作时就是通过改变计数器的值来去下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都要依赖这个计数器。在执行Java方法时记录的是正在执行的虚拟机字节码指令的地址，Native方法，则计数器为空。我们来看一下面方法的指令，其中冒号左边的数字就是代表着程序计数器的值，也就是指令偏移地址，程序计数器通过这个地址来进行执行，当CPU进行执行其他线程时，程序计数器就会将当前的偏移地址进行保存起来，这样在下次执行时就知道执行到哪一步了，因此程序计数器是私有的（如果只有一个的话，执行其他线程时存放的偏移地址可能会重复，这样程序计数器就不知道执行到哪一步了）。12345678910111213public static int methodOne(int); descriptor: (I)I flags: ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=3, args_size=1 0: bipush 8 2: istore_1 3: iload_0 4: iload_1 5: iadd 6: istore_2 7: iload_2 8: ireturn虚拟机栈虚拟机栈（JAVA VIrtual Machine Statcks）：存储当前线程运行方法所需要的数据、指令、返回地址；既然是虚拟机栈，那么也就是栈(后进先出)，想到了栈就会有压栈和出栈，但是我们呀栈栈是什么呢？这里将压栈出栈的最小单位定位栈帧。栈帧里存放的又是什么呢？在Java虚拟机中，栈帧用来存储局部变量表、操作数栈、动态链接、方法出口等信息；每个方法在执行的时候都会创建一个栈帧。局部变量表局部变量表（Local Variable Table）是一组变量值存储空间，用于存放方法参数和方法内部定义的局部变量表。上面代码中“locals=3,args_size=1”代表该方法局部局部变量表数量为3，方法参数数目为1。那么局部变量表的单位是什么呢？大家可能见到过一个单词”Slot”,也就是Variable Slot，中文的意思也就是变量槽，变量槽为局部变量的基本单位，方法中的局部变量信息也就存放在变量槽中。我们这里取32为的虚拟机，在32位的虚拟机中，一个Slot可以存放一个32位以内的数据类型，存放8种数据类型，byte、short 、int 、float 、boolean、char、reference(引用类型，表示对一个对象的引用，在虚拟机中规范中没有说明它的长度，也没有明确指出这种引用应该有怎样的结构，一般来说，虚拟机实现至少都应当能通过这个引用做到两点，一是从此引用中直接或间接地查找到对象在 Java 堆中的数据存放的起始地址索引，二是此引用中直接或间接地查找到对象所属数据类型在方法区中的存储的类型信息，否则无法实现 Java 语言规范中定义的语法约束约束)、returnAddress （返回地址，已经很少见到了，它是为字节码指令 jsr、jsr_w 和 ret 服务的，指向了一条字节码指令的地址，很古老的 Java 虚拟机曾经使用这几条指令来实现异常处理，现在已经由异常表代替）。针对64位的数据类型，虚拟机会以高对齐的方式分配两个连续的Slot，数据类型为long,double。还需要注意的是Slot是可以重用的。复用的目的当然是为了节省栈帧空间。那么我们就需要考虑如何进行复用的了。简单的说就是方法中定义的变量，其作用域并不一定会覆盖整个方法，如果当前自己码PC计数器的值已经超过了某个变量的作用域，那这个变量对应的Slot就可以交给其他变量使用，但是会有一些副作用，会影响到JVM的垃圾回收行为。首先我们先运行下面代码: 运行之前我们需要配置环境变量，这样我们就能看到回收信息，在debug中进行配置123456789public class SlotTest &#123; public static void main(String[] args) &#123; byte[] placeholder = new byte[32*1024*1024]; System.gc(); &#125;&#125;打印信息为12[GC (System.gc()) 35389K-&gt;33664K(251392K), 0.0168623 secs][Full GC (System.gc()) 33664K-&gt;33421K(251392K), 0.0081896 secs]上面并没有进行回收32M的数据，我们将它进行改造为下面的代码123456789public class SlotTest &#123; public static void main(String[] args) &#123; &#123; byte[] placeholder = new byte[32 * 1024 * 1024]; &#125; System.gc(); &#125;&#125;我们再次观察运行后的信息12[GC (System.gc()) 35389K-&gt;33600K(251392K), 0.0178175 secs][Full GC (System.gc()) 33600K-&gt;33421K(251392K), 0.0081758 secs]从上面的信息中，我们发现虚拟机并没有进行回收32M的数据。我们再次进行修改代码12345678910public class SlotTest &#123; public static void main(String[] args) &#123; &#123; byte[] placeholder = new byte[32 * 1024 * 1024]; &#125; int b = 0; System.gc(); &#125;&#125;运行后的记过如下12[GC (System.gc()) 35389K-&gt;832K(251392K), 0.0009699 secs][Full GC (System.gc()) 832K-&gt;653K(251392K), 0.0038388 secs]从上面的三个代码我们进行分析，首先创建的32M的数据，虽然没有被引用，但是在方法内部，JVM并没有进行回收，第二个代码，虽然已经没有代码的引用，但是变量槽Slot并没有被覆盖，所以第二块代码仍然没有回收，第三处代码我们创建新的变量，这个时候32M的变量槽被复用，导致垃圾回收器进行回收。操作数栈操作数栈（Operand Stack）也常被称操作栈，它是一个后入先出栈。操作数栈和局部变量表在访问方式上存在着较大差异，操作数栈并非采用访问索引的方式来进行数据访问的，而是通过标准的入栈和出栈操作来完成一次数据访问我们从简单的一个代码为例123456789101112131415public class HelloWorld &#123; public static void main(String[] args) &#123; int a = 10; methodOne(a); &#125; public static int methodOne(int i) &#123; int b = 8; int c= i+b; return c; &#125;&#125;我们进行查看生成的字节码，将class文件进行反汇编javap是 Java class文件分解器，可以反编译（即对javac编译的文件进行反编译），也可以查看java编译器生成的字节码1javap -c -v HelloWorld.class &gt; HelloWorld.txt将指令输出到HelloWorld.txt中1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374Classfile /C:/Users/wsylp/Desktop/study/性能优化/code/HelloWorld.class Last modified 2019-1-9; size 365 bytes MD5 checksum b16686878d8381f6497431a1e9932515 Compiled from "HelloWorld.java"public class HelloWorld minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPERConstant pool: #1 = Methodref #4.#15 // java/lang/Object."&lt;init&gt;":()V #2 = Methodref #3.#16 // HelloWorld.methodOne:(I)I #3 = Class #17 // HelloWorld #4 = Class #18 // java/lang/Object #5 = Utf8 &lt;init&gt; #6 = Utf8 ()V #7 = Utf8 Code #8 = Utf8 LineNumberTable #9 = Utf8 main #10 = Utf8 ([Ljava/lang/String;)V #11 = Utf8 methodOne #12 = Utf8 (I)I #13 = Utf8 SourceFile #14 = Utf8 HelloWorld.java #15 = NameAndType #5:#6 // "&lt;init&gt;":()V #16 = NameAndType #11:#12 // methodOne:(I)I #17 = Utf8 HelloWorld #18 = Utf8 java/lang/Object&#123; public HelloWorld(); descriptor: ()V flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object."&lt;init&gt;":()V 4: return LineNumberTable: line 1: 0 public static void main(java.lang.String[]); descriptor: ([Ljava/lang/String;)V flags: ACC_PUBLIC, ACC_STATIC Code: stack=1, locals=2, args_size=1 0: bipush 10 2: istore_1 3: iload_1 4: invokestatic #2 // Method methodOne:(I)I 7: pop 8: return LineNumberTable: line 4: 0 line 5: 3 line 6: 8 public static int methodOne(int); descriptor: (I)I flags: ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=3, args_size=1 0: bipush 8 2: istore_1 3: iload_0 4: iload_1 5: iadd 6: istore_2 7: iload_2 8: ireturn LineNumberTable: line 9: 0 line 10: 3 line 12: 7&#125;SourceFile: "HelloWorld.java"上面为输出的结果，我们来看mian方法的指令12345678910111213public static int methodOne(int); descriptor: (I)I flags: ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=3, args_size=1 0: bipush 8 2: istore_1 3: iload_0 4: iload_1 5: iadd 6: istore_2 7: iload_2 8: ireturn在上述字节码指令示例中首先将由 “bipush” 指令将byte类型的10转换为int类型后压入操作数栈（对于byte、short、char类型的值在入栈前，会被转换为int类型）成功入栈后，”istore_1”指令便会将栈顶元素出栈并存储到环境变量表中索引为1的Slot上。“iload_0” 和 “iload_1” 指令会负责将局部变量表中索引为”0”和”1”的slot上的数值10和8重新压入操作数栈的栈顶“iadd” 指令会将两个数值出栈执行家法运算后再将运算结果重新压入栈顶“istore_2” 指令会将运算结果出栈并存放在局部变量表中索引为2的slot上。“iload_2” 指令将局部变量中的索引为2的数值进行压入栈中“ireturn” 指令时将方法也就是操作数栈中的数据进行返回操作。在操作栈中，一项运算通常由多个子运算嵌套进行，一个子运算的结果可以被其他外围运算所使用。注意的时，操作数栈中的数据必须正确的操作，不能压入两个int的数值，却把他当作long类型的数值去操作。命令意义iconst_1将一个byte型常量值推送至栈顶bipush将一个byte型常量值推送至栈顶iload_1第二个int型局部变量进栈，从0开始计数istore_1将栈顶int型数值存入第二个局部变量，从0开始计数iadd栈顶两int型数值相加，并且结果进栈return当前方法返回voidgetstatic获取指定类的静态域，并将其值压入栈顶putstatic为指定的类的静态域赋值invokevirtual调用实例方法invokespecial调用超类构造方法、实例初始化方法、私有方法invokestatic调用静态方法invokeinterface调用接口方法new创建一个对象，并且其引用进栈newarray创建一个基本类型数组，并且其引用进栈此时我这边产生了一个疑问？它存在的意义是什么呢？虚拟机把操作数栈作为它的工作区——大多数指令都要从这里弹出数据，执行运算，然后把结果压回操作数栈动态链接每个栈帧都包含一个指向运行时常量池中该栈帧所属方法的引用，持有这个引用是为了支持方法调用过程中的动态链接。常量池中存在的大量引用，在运行期间转化为直接引用，这部分就是动态链接。方法返回地址当一个方法在执行过程中有两种方式退出该方法，一种是遇到返回的字节码指令，这种叫做正常完成出口，另外一种是执行中出现异常，称为异常完成出口。代码在执行的过程中，执行结束方法后我们需要进行继续往下执行，所以我们需要记录方法开始被调用的地方。方法退出的过程等于把当前栈帧出栈，因此在退出的时候可能执行的操作有：恢复上层方法的局部变量表和操作数栈，把返回值（非void）压入点用着栈帧的操作数栈中，调整PC计数器的值以指向方法调用指令后的一条指令等。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>运行时数据区</tag>
        <tag>程序计数器</tag>
        <tag>虚拟机栈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lambda表达式与Stream]]></title>
    <url>%2FLambda%E8%A1%A8%E8%BE%BE%E5%BC%8F%E4%B8%8EStream%2F</url>
    <content type="text"><![CDATA[Lambda表达式与StreamLambda表达式背景java 8中增加了许多特性，到现在才来总结写一下Lamdba表达式，让我们来遛一遛吧，毕竟简化了我们的代码量。简化了匿名委托的使用，让代码更加简洁，但是如果你不懂，那么久一路懵吧，为了高大上的代码我们必须学并用之实践。简介来看下百度百科如何进行解释的：“Lambda 表达式”(lambda expression)是一个匿名函数，Lambda表达式基于数学中的λ演算得名，直接对应于其中的lambda抽象(lambda abstraction)，是一个匿名函数，即没有函数名的函数。Lambda表达式可以表示闭包（注意和数学传统意义上的不同）。函数式接口的重要属性是：我们能够使用 Lambda 实例化它们，Lambda 表达式让你能够将函数作为方法参数，或者将代码作为数据对待。Lambda 表达式的引入给开发者带来了不少优点：在 Java 8 之前，匿名内部类，监听器和事件处理器的使用都显得很冗长，代码可读性很差，Lambda 表达式的应用则使代码变得更加紧凑，可读性增强；Lambda 表达式使并行操作大集合变得很方便，可以充分发挥多核 CPU 的优势，更易于为多核处理器编写代码。语法特性可选类型生命：不用声明参数类型，编译器可以从参数值来进行推断它是什么类型可选参数周围括号：单个参数无需括号，但是多个参数括号是必需的可选大括号：如果表达式只一个语句，那么不必用大括号括起来如果表达式体只有单个表达式用于值的返回，那么编译器会自动完成这一步。若要指示表达式来返回某个值，则需要使用大括号。一般语法（Type1 param1,Type2 param2,…,TypeN paramN ) -&gt; {statment1;statment2;…return statmentM;}方法引用lambda表达式还有两种简化代码的手段，它们是方法引用、构造引用。方法引用是什么呢？如果我们要实现接口的方法与另一个方法A类似，（这里的类似是指参数类型与返回值部分相同），我们直接声明A方法即可。也就是，不再使用lambda表达式的标准形式，改用高级形式。无论是标准形式还是高级形式，都是lambda表达式的一种表现形式。举例：12Function function1 = (x) -&gt; x;Function function2 = String::valueOf;对比Function接口的抽象方法与String的value方法，可以看到它们是类似的。12345R apply(T t);public static String valueOf(Object obj) &#123;return (obj == null) ? "null" : obj.toString();&#125;方法引用的语法：123对象::实例方法类::静态方法类::实例方法前两个很容易理解，相当于对象调用实例方法，类调用静态方法一样。只是第三个需要特殊说明。当出现如下这种情况时：1Compare&lt;Boolean&gt; c = (a, b) -&gt; a.equals(b);用lambda表达式实现Compare接口的抽象方法，并且方法体只有一行，且该行代码为参数1调用方法传入参数2。此时，就可以简化为下面这种形式：1Compare&lt;Boolean&gt; c = String::equals;也就是“类::实例方法”的形式。值得一提的是，当参数b不存在时，该方式依旧适用。例如：123Function function1 = (x) -&gt; x.toString();Function function1 = Object::toString;构造引用先来创建一个供给型接口对象：1Supplier&lt;String&gt; supplier = () -&gt; new String();在这个lammbda表达式中只做了一件事，就是返回一个新的Test对象，而这种形式可以更简化：1Supplier&lt;String&gt; supplier = String::new;提炼一下构造引用的语法：1类名::new当通过含参构造方法创建对象，并且参数列表与抽象方法的参数列表一致，也就是下面的这种形式：1Function1 function = (x) -&gt; new String(x);也可以简化为：1Function1 function = String::new;特殊点的数组类型：1Function&lt;Integer,String[]&gt; function = (x) -&gt; new String[x];可以简化为：1Function&lt;Integer,String[]&gt; function = String[]::new;示例迭代列表123456789101112131415161718192021//迭代列表 private static void iteratorList() &#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(); list.add("one"); list.add("two"); list.add("three"); //传统遍历 System.out.println("传统方式："); for (String s : list) &#123; System.out.println(s); &#125; //Lambda表达式 System.out.println("Lambda表达式："); list.forEach(n-&gt; System.out.println(n)); // 使用Java 8的方法引用更方便，方法引用由::双冒号操作符标示， list.forEach(System.out::println); &#125;运行结果如下：1234567891011传统方式：onetwothreeLambda表达式：onetwothreeonetwothree实现Runnablelambda可以替换匿名内部类，在实现runnable的时候，我们能够明显看出来，代码的简洁性的差异。123456789101112//多线程 private static void threads() &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println("传统的代码"); &#125; &#125;).start(); new Thread( ()-&gt; System.out.println("我是lambda表达式")).start(); &#125;结果：12传统的代码我是lambda表达式集合排序比较传统的排序代码笼统繁琐，看起来虽然易懂，但是代码量较多，使用起来不方便。如果使用Lambda简单明了，至于Comparator.comparing相关内容会在其他章节进行介绍。1234567891011121314151617181920212223242526272829303132333435363738//排序 private static void sort() &#123; List&lt;User&gt; users = new ArrayList&lt;User&gt;() &#123; &#123; add(new User("0004", "四")); add(new User("0001", "一")); add(new User("0002", "二")); add(new User("0003", "三")); &#125; &#125;; System.out.println("传统方式"); Collections.sort(users, new Comparator&lt;User&gt;() &#123; @Override public int compare(User user1, User user2) &#123; return user1.getDah().compareTo(user2.getDah()); &#125; &#125;); users.forEach(user -&gt; System.out.println(user.getDah() + ":" + user.getName())); //lambda表达式 System.out.println("使用lambda表达式"); Collections.sort(users, (s1, s2) -&gt; (s1.getDah().compareTo(s2.getDah()))); users.forEach(user -&gt; System.out.println(user.getDah() + ":" + user.getName())); System.out.println("使用Comparator.comparing 与lambda表达式"); users.sort(Comparator.comparing(e -&gt; e.getDah())); users.forEach(user -&gt; System.out.println(user.getDah() + ":" + user.getName())); // 该方法引用 user::getDah 可以代替 lambda表达式 System.out.println("使用Comparator.comparing 与 ::"); users.sort(Comparator.comparing(User::getDah)); users.forEach(user -&gt; System.out.println(user.getDah() + ":" + user.getName())); &#125;结果如下：1234567891011121314151617181920传统方式0001:一0002:二0003:三0004:四使用lambda表达式0001:一0002:二0003:三0004:四使用Comparator.comparing 与lambda表达式0001:一0002:二0003:三0004:四使用Comparator.comparing 与 ::0001:一0002:二0003:三0004:四使用lambda表达式和函数式接口Predicate除了在语言层面支持函数式编程风格，java8也增加了一个java.util.function包，它包含了很多类，用来支持java的函数式编程，其中一个为Predicate，使用 java.util.function.Predicate 函数式接口以及lambda表达式，可以向API方法添加逻辑，用更少的代码支持更多的动态行为。下面是Java 8 Predicate 的例子，展示了过滤集合数据的多种常用方法。Predicate接口非常适用于做过滤。1234567891011121314151617181920212223242526private static void predicateTry() &#123; List&lt;String&gt; languages = Arrays.asList("Java", "Scala", "C++", "Haskell", "Lisp"); System.out.println("Languages 用J开头 :"); filter(languages, (str)-&gt;str.startsWith("J")); System.out.println("Languages 用a结尾"); filter(languages, (str)-&gt;str.endsWith("a")); System.out.println("languages所有数据 :"); filter(languages, (str)-&gt;true); System.out.println("不打印 : "); filter(languages, (str)-&gt;false); System.out.println(" language 长度大于 4:"); filter(languages, (str)-&gt;str.length() &gt; 4); &#125; public static void filter(List&lt;String&gt; names, Predicate&lt;String&gt; condition) &#123; for(String name: names) &#123; if(condition.test(name)) &#123; System.out.println(name + " "); &#125; &#125; &#125;结果如下:123456789101112131415Languages 用J开头 :Java Languages 用a结尾Java Scala languages所有数据 :Java Scala C++ Haskell Lisp 不打印 : language 长度大于 4:Scala Haskell还有一种更加简洁的办法，与上面的结果是一致的。我们可以看到，Stream API过滤方法也是支持Predicate，这个意味着我们可以定制filter()方法替换里面的内联代码，还有Predicate接口也允许进行多重条件的测试。1names.stream().filter(name-&gt;(condition.test(name))).forEach(name-&gt; System.out.println(name));如何在lambda表达式中增加Predicatejava.util.function.Predicate 允许将两个或更多的 Predicate 合成一个。它提供类似于逻辑操作符AND和OR的方法，名字叫做and()、or()和xor()，用于将传入 filter() 方法的条件合并起来。例如，要得到所有以J开始，长度为四个字母的语言，可以定义两个独立的 Predicate 示例分别表示每一个条件，然后用 Predicate.and() 方法将它们合并起来，如下所示：1234567891011121314private static void predicateTry2() &#123; // 甚至可以用and()、or()和xor()逻辑函数来合并Predicate， // 例如要找到所有以J开始，长度为四个字母的名字，你可以合并两个Predicate并传入 List&lt;String&gt; languages = Arrays.asList("Java", "Scala", "C++", "Haskell", "Lisp"); Predicate&lt;String&gt; startWithJ = n-&gt;n.startsWith("J"); Predicate&lt;String&gt; length4 = n-&gt;n.length() == 4; languages.stream().filter(language-&gt;startWithJ.and(length4).test(language)).forEach(language-&gt; System.out.println(language));&#125;结果如下：1Java类似地，也可以使用 or() 和 xor() 方法。本例着重介绍了如下要点：可按需要将 Predicate 作为单独条件然后将其合并起来使用。简而言之，你可以以传统Java命令方式使用 Predicate 接口，也可以充分利用lambda表达式达到事半功倍的效果。Map和Reduce可以看到map将集合类（例如列表）元素进行转换的。还有一个 reduce() 函数可以将所有值合并成一个。Map和Reduce操作是函数式编程的核心操作，因为其功能，reduce 又被称为折叠操作。另外，reduce 并不是一个新的操作，你有可能已经在使用它。SQL中类似 sum()、avg() 或者 count() 的聚集函数，实际上就是 reduce 操作，因为它们接收多个值并返回一个值。流API定义的 reduceh() 函数可以接受lambda表达式，并对所有值进行合并。IntStream这样的类有类似 average()、count()、sum() 的内建方法来做 reduce 操作，也有mapToLong()、mapToDouble() 方法来做转换。这并不会限制你，你可以用内建方法，也可以自己定义。在这个Java 8的Map Reduce示例里，我们首先对所有价格应用 12% 的VAT，然后用 reduce() 方法计算总和。12345678910111213141516private static void mapAndReduce() &#123; //每个订单增加12%的关税 List&lt;Integer&gt; costBeforeTax = Arrays.asList(100, 200, 300, 400, 500); double total = 0; for(Integer cost : costBeforeTax)&#123; total = total+(cost+cost*0.12); &#125; System.out.println("总价为：" + total); //使用新方法 double bill = costBeforeTax.stream().map(cost-&gt;(cost+cost*0.12)).reduce((sum,cost)-&gt;sum+cost).get(); System.out.println(bill); &#125;结果为：12总价为：1680.01680.0通过过滤创建String列表过滤是Java开发者在大规模集合上的一个常用操作，而现在使用lambda表达式和流API过滤大规模数据集合是惊人的简单。流提供了一个 filter() 方法，接受一个 Predicate 对象，即可以传入一个lambda表达式作为过滤逻辑。下面的例子是用lambda表达式过滤Java集合，将帮助理解。12345678private static void stringFilter() &#123; List&lt;String&gt; languages = Arrays.asList("Java", "Scala", "C++", "Haskell", "Lisp"); List&lt;String&gt; stringList = languages.stream().filter(x -&gt; x.length() &gt; 4).collect(Collectors.toList()); stringList.forEach(language-&gt; System.out.println(language)); &#125;结果如下:12ScalaHaskell另外，关于 filter() 方法有个常见误解。在现实生活中，做过滤的时候，通常会丢弃部分，但使用filter()方法则是获得一个新的列表，且其每个元素符合过滤原则。列表的每个元素应用函数我们通常需要对列表的每个元素使用某个函数，例如逐一乘以某个数、除以某个数或者做其它操作。这些操作都很适合用 map() 方法，可以将转换逻辑以lambda表达式的形式放在 map() 方法里，就可以对集合的各个元素进行转换了，如下所示。1234567private static void stringToUpperCase() &#123; List&lt;String&gt; languages = Arrays.asList("Java", "Scala", "C++", "Haskell", "Lisp"); String collect = languages.stream().map(x -&gt; x.toUpperCase()).collect(Collectors.joining(",")); System.out.println(collect);&#125;结果如下：1JAVA,SCALA,C++,HASKELL,LISP复制不同的值，创建一个子列表本例展示了如何利用流的 distinct() 方法来对集合进行去重。123456789private static void listDistinct() &#123; List&lt;String&gt; languages = Arrays.asList("Java", "Scala", "C++", "Haskell", "Java","Lisp"); List&lt;String&gt; stringList = languages.stream().distinct().collect(Collectors.toList()); stringList.forEach(n -&gt; System.out.println(n));&#125;结果如下：12345JavaScalaC++HaskellLisp计算集合元素的最大值、最小值、总和以及平均值IntStream、LongStream 和 DoubleStream 等流的类中，有个非常有用的方法叫做 summaryStatistics() 。可以返回 IntSummaryStatistics、LongSummaryStatistics 或者 DoubleSummaryStatistic s，描述流中元素的各种摘要数据。在本例中，我们用这个方法来计算列表的最大值和最小值。它也有 getSum() 和 getAverage() 方法来获得列表的所有元素的总和及平均值。1234567891011private static void listDeal() &#123; //获取数字的个数、最小值、最大值、总和以及平均值 List&lt;Integer&gt; primes = Arrays.asList(2, 3, 5, 7, 11, 13, 17, 19, 23, 29); IntSummaryStatistics intSummaryStatistics = primes.stream().mapToInt(x -&gt; x).summaryStatistics(); System.out.println("最大数："+intSummaryStatistics.getMax()); System.out.println("平均数："+intSummaryStatistics.getAverage()); System.out.println("最小数："+intSummaryStatistics.getMin()); System.out.println("和："+intSummaryStatistics.getSum());&#125;结果:1234最大数：29平均数：12.9最小数：2和：129Lambda表达式 vs 匿名类既然lambda表达式即将正式取代Java代码中的匿名内部类，那么有必要对二者做一个比较分析。一个关键的不同点就是关键字 this。匿名类的 this 关键字指向匿名类，而lambda表达式的 this 关键字指向包围lambda表达式的类。另一个不同点是二者的编译方式。Java编译器将lambda表达式编译成类的私有方法。使用了Java 7的 invokedynamic 字节码指令来动态绑定这个方法。Lambda总结上面举了很多lambda实例，也侧重讲了如何去理解lambda表达式。到这里，不要懵。要记住lambda的本质：为函数型接口的匿名实现进行简化与更简化。所谓的简化就是lambda的标准形式，所谓的更简化是在标准形式的基础上进行方法引用和构造引用。方法引用是拿已有的方法去实现此刻的接口。构造引用是对方法体只有一句new Object()的进一步简化StreamStream是什么Stream不是集合元素，也不是数据结构并不保存数据，它是有关算法与计算的，它更像一个高版本的Iterator。简单来说，它的作用就是通过一系列操作将数据源（集合、数组）转换为想要的结果。Stream特点Stream是不会存储元素的。Stream不会改变原对象，相反，他们会返回一个持有结果的新Stream。Strream是延迟执行的，意味着他们会等到需要结果时候才执行。生成Stream的方式123456789101112131415161718192021222324private static void createStream() &#123; //Collection系的 stream() 和 parallelStream(); List&lt;String&gt; list = new ArrayList&lt;&gt;(); Stream&lt;String&gt; stream = list.stream(); Stream&lt;String&gt; stringStream = list.parallelStream(); //通过Arrays Stream&lt;String&gt; stream1 = Arrays.stream(new String[10]); //通过Stream Stream&lt;Integer&gt; stream2 = Stream.of(1, 2, 3); //无限流 //迭代 Stream&lt;Integer&gt; iterate = Stream.iterate(0, (x) -&gt; x + 2); iterate.limit(10).forEach(System.out::println); //生成 Stream&lt;Double&gt; generate = Stream.generate(() -&gt; Math.random()); generate.forEach(System.out::println); &#125;Stream的中间操作多个中间操作连接而成为流水线，流水线不遇到终止操作是不触发任何处理的，所以有称为“惰性求值”。123456789list.stream() .map(s -&gt; s+1)//映射 .flatMap(s-&gt;Stream.of(s))//和map差不多，但返回类型为Stream，类似list.add()和list.addAll()的区别 .filter(s-&gt;s.length()&lt;10)////过滤 .limit(5) //限制 .skip(1) //跳过 .distinct() //去重 .sorted() //自然排序 .sorted(String::compareTo); //自定义排序关于map方法，参数为一个Function函数型接口的对象，也就是传入一个参数返回一个对象。这个参数就是集合中的每一项。类似Iterator遍历。其它的几个操作思想都差不多。Stream的终止操作1234567891011list.stream().allMatch((x) -&gt; x.length()&lt;5); // 检查是否匹配所有元素list.stream().anyMatch(((x) -&gt; x.length()&gt;6)); // 检查是否至少匹配一个元素list.stream().noneMatch((x) -&gt;x.length()&gt;5); //检查是否没有匹配所有元素list.stream().findFirst(); // 返回第一个元素list.stream().findAny(); // 返回当前流中的任意一个元素list.stream().count(); // 返回流中元素的总个数list.stream().forEach(System.out::println); //内部迭代list.stream().max(String::compareTo); // 返回流中最大值Optional&lt;String&gt; min = list.stream().min(String::compareTo);//返回流中最小值System.out.println("min "+min.get());reduce （归约）将流中元素反复结合起来得到一个值123456789Integer reduce = list.stream() .map(s -&gt; (s + 1)) .reduce(0, (x, y) -&gt; x + y); //归约：0为第一个参数x的默认值，x是计算后的返回值，y为每一项的值。System.out.println(reduce);Optional&lt;Integer&gt; reduce1 = list.stream() .map(s -&gt; (s + 1)) .reduce((x, y) -&gt; x + y); // x是计算后的返回值，默认为第一项的值，y为其后每一项的值。System.out.println(reduce);collect（收集）将流转换为其他形式。需要Collectors类的一些方法。1234567891011121314151617181920212223242526272829303132333435363738394041//转集合 Set&lt;Integer&gt; collect = list.stream() .collect(Collectors.toSet()); List&lt;Integer&gt; collect2 = list.stream() .collect(Collectors.toList()); HashSet&lt;Integer&gt; collect1 = list.stream() .collect(Collectors.toCollection(HashSet::new)); //分组 &#123;group=[444, 555, 666, 777, 555]&#125; Map&lt;String, List&lt;Integer&gt;&gt; collect3 = list.stream() .collect(Collectors.groupingBy((x) -&gt; "group"));//将返回值相同的进行分组 System.out.println(collect3); //多级分组 &#123;group=&#123;777=[777], 666=[666], 555=[555, 555], 444=[444]&#125;&#125; Map&lt;String, Map&lt;Integer, List&lt;Integer&gt;&gt;&gt; collect4 = list.stream() .collect(Collectors.groupingBy((x) -&gt; "group", Collectors.groupingBy((x) -&gt; x))); System.out.println(collect4); //分区 &#123;false=[444], true=[555, 666, 777, 555]&#125; Map&lt;Boolean, List&lt;Integer&gt;&gt; collect5 = list.stream() .collect(Collectors.partitioningBy((x) -&gt; x &gt; 500)); System.out.println(collect5); //汇总 DoubleSummaryStatistics collect6 = list.stream() .collect(Collectors.summarizingDouble((x) -&gt; x)); System.out.println(collect6.getMax()); System.out.println(collect6.getCount()); //拼接 444,555,666,777,555 String collect7 = list.stream() .map(s -&gt; s.toString()) .collect(Collectors.joining(",")); System.out.println(collect7); //最大值 Optional&lt;Integer&gt; integer = list.stream() .collect(Collectors.maxBy(Integer::compare)); System.out.println(integer.get());参考内容：Java8 lambda表达式10个示例lambda表达式和Stream API]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java Lambda Stream</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[软技能:代码之外的生存指南（一）职业]]></title>
    <url>%2F%E8%BD%AF%E6%8A%80%E8%83%BD-%E4%BB%A3%E7%A0%81%E4%B9%8B%E5%A4%96%E7%9A%84%E7%94%9F%E5%AD%98%E6%8C%87%E5%8D%97%EF%BC%88%E4%B8%80%EF%BC%89%E8%81%8C%E4%B8%9A%2F</url>
    <content type="text"><![CDATA[代码之外的生存指南（一）职业软技能–代码之外的生存指南（一）职业在意外之中看到这本书，自己尝试着读了几篇，发现很实用，就将这本书读完，在这进行对本书的收获进行分享，也方便自己在以后进行很好的回顾。首先这本书没有进行描述我们如何写出优美的代码以及新技术，但是这本书讲的确实是我们身为程序员应该考虑或者面临的问题。现在我们进行走进这本书。转换思想–我是企业首先不管我们现在在哪里工作，我们需明白一个观点，就是我们为谁工作？可能大家都会说为了自己工作（心里偷偷的想，如果公司是我自己的那就是为我自己，否则就是为公司工作），实际上我们心里究竟如何进行思考的呢？是的，实际工作中认为我们是公司工作的！但是我们为何不转换思想呢？我们可以把我们的工作看作是自己的公司，然后我们提供产品（把想法进行实现的产品）。只有你开始把自己当作一个企业去思考时，你才能开始做出良好的商业决策。我们要像企业的思想去思考。首先我们的合同就相当于乙方合同，我们与甲方（公司）进行签合同，那么我们就是为自己的公司工作，必然我们会没有薪水（甲方将与我们解除合同）。但我们用着了这种思想之后，我们就会明白一个简单的道理：我们能为乙方提供什么？程序员千千万万，我的公司又如何发展？首先我们的拥有其他公司无法替代的产品，而且在某个领域是第一的，我的公司才会拥有生存下去的能力，否则我们会慢慢的”年老色衰“。企业的未来–发展目标如果我没有梦想，那么与咸鱼有什么区别！现在在工作之外你在做什么？回到家里玩游戏?看电视？看小说？还是在发呆？成功人的一天是充实的，那个经常在上班时悠哉游哉的人，下班后却以各种理由进行放弃企业发展的人？你觉得你的企业会倒闭吗？如果没有航海图我们就无法把握方向，我们要有一个发展目标，例如，每天都一本书的几页，锻炼身体多久，学习新技术等等，设立一个大的目标，从年目标到月目标，周目标，日目标，然后每天去看完成进度。这就是年度计划，你可不想到年底时回想这一年，你的企业服务没有任何进步。没有进步就是在退步，因为别人在前进，终有一天你会发现你破产了。软件开发工程师 &lt;&gt; 零沟通别烦我，我要静静当一个码农！很多人认为是自己的工作环境限制了自己的沟通能力，表达能力。 回顾我们一天的上班情况，遇见同事要打招呼，要看邮件，看消息，进行会议，写文档，分析需求等，实际上我们只是把沟通后的结果进行实现，我们作为软件开发人员实际上就是在沟通！那么我们简单提下沟通中事情：永远不要批评，如果是你被批评了你心里也会不舒服，所以不要批评。避免争吵，我们首先冷静下来，用自己的想法去说服别人会产生分歧，这个时候我们不要固执，应该冷静，然后去谈论问题。换位思考，我们是开发人员，提供服务人员，我们的目的是提供服务，我们应该站在客户的角度上进行思考，在沟通中也是站在对方的角度去思考。专业专业化专业化是任何行业所需要的，只要专业化才可以很好的发展，这就是树叶有专攻，在一个精力，时间有限控制下，专业是一个快速发展以及生存的指南。专人做专事，专业化的规则是：专业化程度越深，潜在的机会就越少，但获得这些机会的可能性越大，也请你记住，一个人只能做一份工作。这里简单说下软件开发的几个专业领域：Web开发栈嵌入式系统特定的操作系统移动开发框架软件系统如何选择专业：现在自己或者之前公司哪些痛点现在那种缺少人去做，或者缺少经验丰富的人你喜欢什么或者擅长什么注意：但是要注意我们在专业化的基础上进行拓展分支。成为专业人士在《The War Of Art》 中有段话是这样说的成为专业人士是一种心态。如果我们总是与恐惧、自毁、拖延和自我怀疑作斗争，那么问题就是：我们正在像外行那样思考问题。外行毫不起眼，外行人废话连篇，外行屈从于逆境。专业人士可不这么想。不管怎样，他引人注目，他恪尽职守，他始终如一。养成良好习惯德行兼备提高完善自我肯定自己做一个有思想的芦苇晋升不想当将军的士兵不是好士兵，在公司里我们想升职，我们不想当一个默默无闻的码农。想想自己工作多久了，上一次升职是什么时候？世界上没有无缘无故的爱，也没有无缘无故的升职加薪。如何晋升承担责任能力越大责任越大，责任伴随着机遇，成为问题的解决者。责任代表着价值，尝试着在解决自己工作的同时，进行研究目前项目中的现状，难题，然后尝试解决。引人注目领导不会把升职的机会给一个默默无闻的人，尝试着分享，提出有利于公司或者项目建议并提供实现方法。学习无法承受或者接受新事物，也就无法完成任务挑战，而且没办法证明你比昨天强。狂热书中讲到我们不能陷入对技术的狂热之中，也就是说我们不应该有着鄙视链的思想，然后去任意的贬低其他技术。我们须知“存在即合理”，任何技术既然生存下来，那么必有他的优点，或者它是为解决某一问题而应运而生，我们没有必要去认为自己是做好的。我们保存对技术要冷静，也就是说可以狂热但不失理智，钟爱但不唯一。参考文献：［1］著John Z. Sonmez 译 王小刚.软技能：代码之外的生存指南[Ｍ].北京：人民邮电出版社．]]></content>
      <categories>
        <category>软技能：代码之外的生存指南</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>发展</tag>
        <tag>职业</tag>
        <tag>书籍</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络安全之RSA]]></title>
    <url>%2F%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E4%B9%8BRSA%2F</url>
    <content type="text"><![CDATA[代码之外的生存指南（一）职业简介RSA是一种非对称加密算法，在公开密钥加密和电子商业中RSA被广泛使用。RSA是1977年由罗纳德·李维斯特（Ron Rivest）、阿迪·萨莫尔（Adi Shamir）和伦纳德·阿德曼（Leonard Adleman）一起提出的。当时他们三人都在麻省理工学院工作。RSA就是他们三人姓氏开头字母拼在一起组成的。1973年，在英国政府通讯总部工作的数学家克利福德·柯克斯（Clifford Cocks）在一个内部文件中提出了一个相同的算法，但他的发现被列入机密，一直到1997年才被发表。对极大整数做因数分解的难度决定了RSA算法的可靠性。换言之，对一极大整数做因数分解愈困难，RSA算法愈可靠。假如有人找到一种快速因数分解的算法的话，那么用RSA加密的信息的可靠性就肯定会极度下降。但找到这样的算法的可能性是非常小的。今天只有短的RSA钥匙才可能被强力方式解破。到目前为止，世界上还没有任何可靠的攻击RSA算法的方式。只要其钥匙的长度足够长，用RSA加密的信息实际上是不能被解破的。加密解密过程RSA虽然是非对称加密，但是确实有公钥私钥的，一般都是公钥公开，每个人都可以用公钥，但是只有持有私钥的人才可以进行解密，从而保证了加密的安全性。我们可看出实际应用中的加密与解密的过程。用公钥加密的数据用私钥解密用私钥加密的数据用公钥解密123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103package encrpt;import org.apache.tomcat.util.codec.binary.Base64;import javax.crypto.BadPaddingException;import javax.crypto.Cipher;import javax.crypto.IllegalBlockSizeException;import javax.crypto.NoSuchPaddingException;import java.io.UnsupportedEncodingException;import java.security.*;import java.security.interfaces.RSAPrivateKey;import java.security.interfaces.RSAPublicKey;import java.security.spec.InvalidKeySpecException;import java.security.spec.PKCS8EncodedKeySpec;import java.security.spec.X509EncodedKeySpec;import java.util.HashMap;import java.util.Map;/** * @Description: * @Author: wsylp * @Date: 2019/7/1 22:30 */public class RSAEncrpt &#123; private static Map&lt;Integer, String&gt; keymap = new HashMap&lt;Integer, String&gt;(); public static void main(String[] args) throws Exception &#123; //获取公钥私钥 genKeyPair(); //加密与解密 String msg = "wsylp.top"; String digest = encrypt(msg,keymap.get(0)); //解密 String decrptyStr= decrpty(digest,keymap.get(1)); &#125; public static String decrpty(String str, String privateKey) throws Exception&#123; //64位解码加密后的字符串 byte[] inputByte = Base64.decodeBase64(str.getBytes("UTF-8")); //base64编码的私钥 byte[] decoded = Base64.decodeBase64(privateKey); RSAPrivateKey priKey = (RSAPrivateKey) KeyFactory.getInstance("RSA").generatePrivate(new PKCS8EncodedKeySpec(decoded)); //RSA解密 Cipher cipher = Cipher.getInstance("RSA"); cipher.init(Cipher.DECRYPT_MODE, priKey); String outStr = new String(cipher.doFinal(inputByte)); return outStr; &#125; private static String encrypt(String msg,String publicKey) throws NoSuchAlgorithmException, InvalidKeySpecException, NoSuchPaddingException, InvalidKeyException, UnsupportedEncodingException, BadPaddingException, IllegalBlockSizeException &#123; byte[] decodes = Base64.decodeBase64(publicKey); RSAPublicKey rsa = (RSAPublicKey) KeyFactory.getInstance("RSA").generatePublic(new X509EncodedKeySpec(decodes)); //RSA加密 Cipher cipher = Cipher.getInstance("RSA"); cipher.init(Cipher.ENCRYPT_MODE,rsa); String outStr = Base64.encodeBase64String(cipher.doFinal(msg.getBytes("UTF-8"))); return outStr; &#125; /** * 随机生成密钥对 */ private static void genKeyPair() throws NoSuchAlgorithmException &#123; // KeyPairGenerator类用于生成公钥和私钥对，基于RSA算法生成对象 KeyPairGenerator keyPairGen = KeyPairGenerator.getInstance("RSA"); // 初始化密钥对生成器，密钥大小为96-1024位 keyPairGen.initialize(1024, new SecureRandom()); // 生成一个密钥对，保存在keyPair中 KeyPair keyPair = keyPairGen.generateKeyPair(); RSAPrivateKey privateKey = (RSAPrivateKey) keyPair.getPrivate(); // 得到私钥 RSAPublicKey publicKey = (RSAPublicKey) keyPair.getPublic(); // 得到公钥 String publicKeyString = new String(Base64.encodeBase64(publicKey.getEncoded())); // 得到私钥字符串 String privateKeyString = new String(Base64.encodeBase64((privateKey.getEncoded()))); // 将公钥和私钥保存到Map keymap.put(0, publicKeyString); //0表示公钥 keymap.put(1, privateKeyString); //1表示私钥 &#125;&#125;数字签名数字签名，就是只有信息的发送者才能产生的别人无法伪造的一段数字串，这段数字串同时也是对信息的发送者发送信息真实性的一个有效证明。数字签名是非对称密钥加密技术与数字摘要技术的应用。简单地说,所谓数字签名就是附加在数据单元上的一些数据,或是对数据单元所作的密码变换。这种数据或变换允许数据单元的接收者用以确认数据单元的来源和数据单元的完整性并保护数据,防止被人(例如接收者)进行伪造。对消息字符串的散列值（Message digest，用 MD5、SHA256 等算法求得的长度较短且固定的字符串）使用RSA的私钥进行签名（实际上仍然是加密消息）后，得到一个签名摘要，将其放在消息的合适位置后，一并发送。接收对方公钥并获取签名摘要，并对消息进行计算散列值，将结果与签名摘要进行比较，如果相等就是消息没有被篡改。特点保证信息传输的完整性、发送者的身份认证、防止交易中的抵赖发生。数字签名技术是将摘要信息用发送者的私钥加密，与原文一起传送给接收者。接收者只有用发送者的公钥才能解密被加密的摘要信息，然后用对收到的原文产生一个摘要信息，与解密的摘要信息对比。如果相同，则说明收到的信息是完整的，在传输过程中没有被修改，否则说明信息被修改过，因此数字签名能够验证信息的完整性。数字签名是个加密的过程，数字签名验证是个解密的过程。数字签名算法依靠公钥加密技术来实现的。在公钥加密技术里，每一个使用者有一对密钥：一把公钥和一把私钥。公钥可以自由发布，但私钥则秘密保存；还有一个要求就是要让通过公钥推算出私钥的做法不可能实现。普通的数字签名算法包括三种算法：密码生成算法；标记算法；验证算法。​ 通过RSA加密解密算法，我们可以实现数字签名的功能。我们可以用私钥对信息生成数字签名，再用公钥来校验数字签名，当然也可以反过来公钥签名，私钥校验。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172package encrpt;import org.apache.tomcat.util.codec.binary.Base64;import javax.crypto.BadPaddingException;import javax.crypto.Cipher;import javax.crypto.IllegalBlockSizeException;import javax.crypto.NoSuchPaddingException;import java.io.UnsupportedEncodingException;import java.security.*;import java.security.interfaces.RSAPrivateKey;import java.security.interfaces.RSAPublicKey;import java.security.spec.InvalidKeySpecException;import java.security.spec.PKCS8EncodedKeySpec;import java.security.spec.X509EncodedKeySpec;import java.util.HashMap;import java.util.Map;/** * @Description: * @Author: wsylp * @Date: 2019/7/1 22:30 */public class RSAUtil &#123; private static Map&lt;Integer, String&gt; keymap = new HashMap&lt;Integer, String&gt;(); public static void main(String[] args) throws Exception &#123; //1.初始化密钥，产生公钥私钥对 genKeyPair(); //2.执行签名 byte[] digest = executeSignature("wsylp.top",keymap.get(1)); //3.验证签名 boolean flag = verifySignature("wsylp.top",digest,keymap.get(0) ); System.out.println(flag); &#125; /** * 私钥解密 * @param str 解密内容 * @param privateKey 私钥 * @return * @throws Exception */ public static String decrpty(String str, String privateKey) throws Exception&#123; //64位解码加密后的字符串 byte[] inputByte = Base64.decodeBase64(str.getBytes("UTF-8")); //base64编码的私钥 byte[] decoded = Base64.decodeBase64(privateKey); RSAPrivateKey priKey = (RSAPrivateKey) KeyFactory.getInstance("RSA").generatePrivate(new PKCS8EncodedKeySpec(decoded)); //RSA解密 Cipher cipher = Cipher.getInstance("RSA"); cipher.init(Cipher.DECRYPT_MODE, priKey); String outStr = new String(cipher.doFinal(inputByte)); return outStr; &#125; /** * * @param msg 加密内容 * @param publicKey 公钥 * @return * @throws NoSuchAlgorithmException * @throws InvalidKeySpecException * @throws NoSuchPaddingException * @throws InvalidKeyException * @throws UnsupportedEncodingException * @throws BadPaddingException * @throws IllegalBlockSizeException */ public static String encrypt(String msg,String publicKey) throws NoSuchAlgorithmException, InvalidKeySpecException, NoSuchPaddingException, InvalidKeyException, UnsupportedEncodingException, BadPaddingException, IllegalBlockSizeException &#123; byte[] decodes = Base64.decodeBase64(publicKey); RSAPublicKey rsa = (RSAPublicKey) KeyFactory.getInstance("RSA").generatePublic(new X509EncodedKeySpec(decodes)); //RSA加密 Cipher cipher = Cipher.getInstance("RSA"); cipher.init(Cipher.ENCRYPT_MODE,rsa); String outStr = Base64.encodeBase64String(cipher.doFinal(msg.getBytes("UTF-8"))); return outStr; &#125; /** * 随机生成密钥对 * @throws NoSuchAlgorithmException */ public static void genKeyPair() throws NoSuchAlgorithmException &#123; // KeyPairGenerator类用于生成公钥和私钥对，基于RSA算法生成对象 KeyPairGenerator keyPairGen = KeyPairGenerator.getInstance("RSA"); // 初始化密钥对生成器，密钥大小为96-1024位 keyPairGen.initialize(1024, new SecureRandom()); // 生成一个密钥对，保存在keyPair中 KeyPair keyPair = keyPairGen.generateKeyPair(); RSAPrivateKey privateKey = (RSAPrivateKey) keyPair.getPrivate(); // 得到私钥 RSAPublicKey publicKey = (RSAPublicKey) keyPair.getPublic(); // 得到公钥 String publicKeyString = new String(Base64.encodeBase64(publicKey.getEncoded())); // 得到私钥字符串 String privateKeyString = new String(Base64.encodeBase64((privateKey.getEncoded()))); // 将公钥和私钥保存到Map keymap.put(0, publicKeyString); //0表示公钥 keymap.put(1, privateKeyString); //1表示私钥 &#125; /** * * 签名 * @param privateKeyStr 私钥 * @return * @throws InvalidKeyException * @throws NoSuchAlgorithmException * @throws InvalidKeySpecException * @throws SignatureException */ public static byte[] executeSignature(String msg,String privateKeyStr) throws InvalidKeyException, NoSuchAlgorithmException, InvalidKeySpecException, SignatureException &#123; //base64编码的私钥 byte[] decodes = Base64.decodeBase64(privateKeyStr); PrivateKey privateKey = KeyFactory.getInstance("RSA").generatePrivate(new PKCS8EncodedKeySpec(decodes)); Signature signature = Signature.getInstance("MD5withRSA"); signature.initSign(privateKey); signature.update(msg.getBytes()); byte[] result = signature.sign(); return result ; &#125; /** * 验签 * @param msg 消息 * @param digest 消息摘要 * @param rsaPublicKey 公钥 * @return * @throws NoSuchAlgorithmException * @throws InvalidKeySpecException * @throws InvalidKeyException * @throws SignatureException * @throws UnsupportedEncodingException */ public static boolean verifySignature(String msg, byte[] digest,String rsaPublicKey) throws NoSuchAlgorithmException, InvalidKeySpecException, InvalidKeyException, SignatureException, UnsupportedEncodingException &#123; byte[] decodes = Base64.decodeBase64(rsaPublicKey); PublicKey publicKey = KeyFactory.getInstance("RSA").generatePublic(new X509EncodedKeySpec(decodes)); Signature signature = Signature.getInstance("MD5withRSA"); signature.initVerify(publicKey); signature.update(msg.getBytes()); boolean bool = signature.verify(digest ); return bool; &#125;&#125;]]></content>
      <categories>
        <category>安全</category>
      </categories>
      <tags>
        <tag>网络安全 RSA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[activiti初体验(八) 监听器]]></title>
    <url>%2Factiviti%E5%88%9D%E4%BD%93%E9%AA%8C-%E5%85%AB-%E7%9B%91%E5%90%AC%E5%99%A8%2F</url>
    <content type="text"><![CDATA[监听器是activiti中经常使用的，一般用在启动或者关闭，以及流程流转的时候。流程引擎的启动与监听之前的配置文件中，有这么个配置：12345678910111213141516171819202122232425/** * 用于监听流程引擎的启动与关闭 * * @author wsylp * */@Service("myProcessEngineLifecycleListener")public class MyProcessEngineLifecycleListener implements ProcessEngineLifecycleListener &#123; private static final Logger LOGGER = LoggerFactory.getLogger(ActivitiServiceImpl.class); @Override public void onProcessEngineBuilt(ProcessEngine processEngine) &#123; LOGGER.debug("processEngine:onProcessEngineBuilt&#123;&#125;开始启动", processEngine); LOGGER.info("processEngine:onProcessEngineBuilt:&#123;&#125;开始启动" + processEngine); &#125; @Override public void onProcessEngineClosed(ProcessEngine processEngine) &#123; LOGGER.debug("processEngine:onProcessEngineClosed&#123;&#125;结束流程", processEngine); LOGGER.info("processEngine:onProcessEngineBuilt:&#123;&#125;结束流程" + processEngine); &#125;&#125;此时我们进行查询任务的单元测试，进行观察日志12345678910111213141516171819202122232425262728293031323334[09:15:38:575] [DEBUG] - wsylp.service.impl.MyProcessEngineLifecycleListener.onProcessEngineBuilt(MyProcessEngineLifecycleListener.java:22) - processEngine:onProcessEngineBuiltorg.activiti.engine.impl.ProcessEngineImpl@4417af13开始启动 [09:15:38:575] [INFO] - wsylp.service.impl.MyProcessEngineLifecycleListener.onProcessEngineBuilt(MyProcessEngineLifecycleListener.java:23) - processEngine:onProcessEngineBuilt:&#123;&#125;开始启动org.activiti.engine.impl.ProcessEngineImpl@4417af13[09:15:38:576] [INFO] - wsylp.log.MyLog.logAfter(MyLog.java:29) - @AfterReturning：org.activiti.engine.ProcessEngineLifecycleListener.onProcessEngineBuilt end.[09:15:38:656] [INFO] - wsylp.log.MyLog.logBegin(MyLog.java:22) - @Before：wsylp.service.ActivitiService.getTasks begin.[09:15:38:657] [DEBUG] - org.activiti.engine.impl.interceptor.LogInterceptor.execute(LogInterceptor.java:33) - [09:15:38:658] [DEBUG] - org.activiti.engine.impl.interceptor.LogInterceptor.execute(LogInterceptor.java:34) - --- starting TaskQueryImpl --------------------------------------------------------[09:15:38:658] [DEBUG] - org.activiti.spring.SpringTransactionInterceptor.execute(SpringTransactionInterceptor.java:40) - Running command with propagation REQUIRED[09:15:38:718] [DEBUG] - org.apache.ibatis.logging.jdbc.BaseJdbcLogger.debug(BaseJdbcLogger.java:159) - ==&gt; Preparing: select distinct RES.* from ACT_RU_TASK RES order by RES.ID_ asc LIMIT ? OFFSET ? [09:15:38:720] [DEBUG] - org.apache.ibatis.logging.jdbc.BaseJdbcLogger.debug(BaseJdbcLogger.java:159) - ==&gt; Parameters: 2147483647(Integer), 0(Integer)[09:15:38:756] [DEBUG] - org.apache.ibatis.logging.jdbc.BaseJdbcLogger.debug(BaseJdbcLogger.java:159) - &lt;== Total: 3[09:15:38:756] [DEBUG] - org.activiti.engine.impl.db.DbSqlSession.flush(DbSqlSession.java:611) - flush summary: 0 insert, 0 update, 0 delete.[09:15:38:757] [DEBUG] - org.activiti.engine.impl.db.DbSqlSession.flush(DbSqlSession.java:612) - now executing flush...[09:15:38:763] [DEBUG] - org.activiti.engine.impl.interceptor.LogInterceptor.execute(LogInterceptor.java:40) - --- TaskQueryImpl finished --------------------------------------------------------[09:15:38:763] [DEBUG] - org.activiti.engine.impl.interceptor.LogInterceptor.execute(LogInterceptor.java:41) - [09:15:38:764] [INFO] - wsylp.service.impl.ActivitiServiceImpl.getTasks(ActivitiServiceImpl.java:166) - 任务处理人【zjl】,任务id【22504】,任务名称【总经理[审批]】,任务流程定义id【sequenceFlow:1:7504】, 流程定义key【zjlsp】,任务拥有者【null】 [09:15:38:764] [INFO] - wsylp.service.impl.ActivitiServiceImpl.getTasks(ActivitiServiceImpl.java:166) - 任务处理人【zjl】,任务id【30004】,任务名称【总经理[审批]】,任务流程定义id【sequenceFlow:1:7504】, 流程定义key【zjlsp】,任务拥有者【null】 [09:15:38:765] [INFO] - wsylp.service.impl.ActivitiServiceImpl.getTasks(ActivitiServiceImpl.java:166) - 任务处理人【gy】,任务id【35014】,任务名称【普通[处理]】,任务流程定义id【gateway:1:32504】, 流程定义key【generalApprove】,任务拥有者【null】 [09:15:38:765] [INFO] - wsylp.log.MyLog.logAfter(MyLog.java:29) - @AfterReturning：wsylp.service.ActivitiService.getTasks end.[09:15:38:778] [DEBUG] - org.activiti.engine.impl.interceptor.LogInterceptor.execute(LogInterceptor.java:33) - [09:15:38:779] [DEBUG] - org.activiti.engine.impl.interceptor.LogInterceptor.execute(LogInterceptor.java:34) - --- starting SchemaOperationProcessEngineClose --------------------------------------------------------[09:15:38:779] [DEBUG] - org.activiti.spring.SpringTransactionInterceptor.execute(SpringTransactionInterceptor.java:40) - Running command with propagation NOT_SUPPORTED[09:15:38:779] [DEBUG] - org.activiti.engine.impl.db.DbSqlSession.flush(DbSqlSession.java:611) - flush summary: 0 insert, 0 update, 0 delete.[09:15:38:779] [DEBUG] - org.activiti.engine.impl.db.DbSqlSession.flush(DbSqlSession.java:612) - now executing flush...[09:15:38:780] [DEBUG] - org.activiti.engine.impl.interceptor.LogInterceptor.execute(LogInterceptor.java:40) - --- SchemaOperationProcessEngineClose finished --------------------------------------------------------[09:15:38:780] [DEBUG] - org.activiti.engine.impl.interceptor.LogInterceptor.execute(LogInterceptor.java:41) - [09:15:38:780] [INFO] - wsylp.log.MyLog.logBegin(MyLog.java:22) - @Before：org.activiti.engine.ProcessEngineLifecycleListener.onProcessEngineClosed begin.[***09:15:38:781] [DEBUG] - wsylp.service.impl.MyProcessEngineLifecycleListener.onProcessEngineClosed(MyProcessEngineLifecycleListener.java:28) - processEngine:onProcessEngineClosedorg.activiti.engine.impl.ProcessEngineImpl@4417af13结束流程[09:15:38:781] [INFO] - wsylp.service.impl.MyProcessEngineLifecycleListener.onProcessEngineClosed(MyProcessEngineLifecycleListener.java:29) - processEngine:onProcessEngineBuilt:&#123;&#125;结束流程***org.activiti.engine.impl.ProcessEngineImpl@4417af13[09:15:38:781] [INFO] - wsylp.log.MyLog.logAfter(MyLog.java:29) - @AfterReturning：org.activiti.engine.ProcessEngineLifecycleListener.onProcessEngineClosed end.从上面的日志中可以看到开始于结束的日志，表示流程正常启动与关闭。开始与结束事件监听器正常的开启流程需要进行设置变量，指定代理人等信息，或者发送短信提醒，都可以使用事件监听器。 日志1[09:38:36:461] [INFO] - wsylp.service.impl.ActivitiListener.notify(ActivitiListener.java:35) - start=========也可以使用spring管理，写入表达式，其中表达式为spring管理的bean的id任务监听器任务监听与开始的事件监听差不多123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package wsylp.service.impl;import org.activiti.engine.delegate.DelegateTask;import org.activiti.engine.delegate.Expression;import org.activiti.engine.delegate.TaskListener;import org.slf4j.Logger;import org.slf4j.LoggerFactory;/** * 节点监听器，任务监听器，连线监听器 * * @author wsylp * */public class MyTaskListener implements TaskListener &#123; private static final Logger LOGGER = LoggerFactory.getLogger(ActivitiServiceImpl.class); private static final long serialVersionUID = 6200534335483960408L; private Expression arg; public Expression getArg() &#123; return arg; &#125; public void setArg(Expression arg) &#123; this.arg = arg; &#125; @Override public void notify(DelegateTask delegateTask) &#123; // 实现TaskListener中的方法 String eventName = delegateTask.getEventName(); LOGGER.info("任务监听器:&#123;&#125;", arg.getValue(delegateTask)); if ("create".endsWith(eventName)) &#123; LOGGER.info("create========="); &#125; else if ("assignment".endsWith(eventName)) &#123; LOGGER.info("assignment========"); &#125; else if ("complete".endsWith(eventName)) &#123; LOGGER.info("complete==========="); &#125; else if ("delete".endsWith(eventName)) &#123; LOGGER.info("delete============="); &#125; &#125;&#125;日志12[10:36:53:622] [INFO] - wsylp.service.impl.MyTaskListener.notify(MyTaskListener.java:35) - 任务监听器:张飒[10:36:53:626] [INFO] - wsylp.service.impl.MyTaskListener.notify(MyTaskListener.java:41) - complete===========github代码地址：https://github.com/wsylp/gms.git]]></content>
      <categories>
        <category>activiti</category>
      </categories>
      <tags>
        <tag>activiti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[activiti初体验(七) 委派,转办,会签,挂起,激活]]></title>
    <url>%2Factiviti%E5%88%9D%E4%BD%93%E9%AA%8C-%E4%B8%83-%E5%A7%94%E6%B4%BE-%E8%BD%AC%E5%8A%9E-%E4%BC%9A%E7%AD%BE-%E6%8C%82%E8%B5%B7-%E6%BF%80%E6%B4%BB%2F</url>
    <content type="text"><![CDATA[其中委派与转办的流程图与正常的没有啥区别，这里直接上代码。任务委派任务委派只是任务人将当前的任务交给接收人进行审批，完成任务后又重新回到任务人身上。委派人查询任务与完成任务与正常的有区别。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273/** * 指定代办人 */ @Test public void delegateTask() &#123; String taskId = "2511"; String loginName = "0003"; activitiService.delegateTask(taskId, loginName); &#125; /** * 正在运行的任务表中被委派人办理任务后任务会回到委派人 ，历史任务表中也一样,只是多了一个人进行审批 */ @Test public void resolveTask() &#123; String taskId = "2511"; Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); activitiService.resolveTask(taskId ,map); &#125; @Test public void getTaskByOwner() &#123; String processDefinitionKey = "delegateTask"; String owner = "0003"; activitiService.getTaskByOwner(processDefinitionKey, owner); &#125;/** * 根据任务拥有者查询任务 * * @param processDefinitionKey * @param owner * @return */ boolean getTaskByOwner(String processDefinitionKey, String owner); /** * 委派人完成任务 * * @param taskId * @param map * @return */ boolean resolveTask(String taskId, Map&lt;String, Object&gt; map);@Override public boolean delegateTask(String taskId, String loginName) &#123; taskService.delegateTask(taskId, loginName); return true; &#125; @Override public boolean getTaskByOwner(String processDefinitionKey, String owner) &#123; TaskQuery taskQuery = taskService.createTaskQuery(); // 任务列表 List&lt;Task&gt; list = taskQuery.processDefinitionKey(processDefinitionKey).taskOwner(owner).list();// 指定办理人 for (Task task : list) &#123; LOGGER.info("任务处理人【&#123;&#125;】", task.getAssignee()); LOGGER.info("流程名称【&#123;&#125;】", task.getName()); LOGGER.info("任务id【&#123;&#125;】", task.getId()); LOGGER.info("流程定义id【&#123;&#125;】", task.getProcessDefinitionId()); LOGGER.info("执行对象id【&#123;&#125;】", task.getExecutionId()); LOGGER.info("任务拥有者【&#123;&#125;】", task.getOwner()); &#125; return true; &#125; @Override public boolean resolveTask(String taskId, Map&lt;String, Object&gt; map) &#123; taskService.resolveTask(taskId, map); return true; &#125;任务转办任务转办是把任务交给别人进行处理123456789101112131415/** * 任务转办,将任务交给其他人处理 */ @Test public void turnTask() &#123; String taskId = "7511"; String assignee = "0003"; activitiService.trunTask(taskId,assignee); &#125;@Override public boolean trunTask(String taskId, String assignee) &#123; taskService.setAssignee(taskId, assignee); return true; &#125;任务会签会签：当任务有多人审批，但只要部分人审批就可以通过，类似于投票，十个人中五个人投票通过即可通过，那么久需要使用会签 1234567891011121314151617181920212223@Test public void startActiviti() &#123; String processDefinitionKey = "counterSign"; String orgCode = "070067801"; String[] assigneeList = &#123;"0001","0002","0003"&#125;; // 设置变量 HashMap&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put("createLoginName", "0003"); map.put("orgCode", orgCode); //必须是List map.put("assigneeList", Arrays.asList(assigneeList)); //map.put("signCount", 0); activitiService.startActivitiAndFinsh(processDefinitionKey, map); &#125; @Test public void getValaier() &#123; String taskId = "35044"; Map&lt;String, Object&gt; variable = activitiService.getVariableByTaskId(taskId , false); System.out.println("nrOfInstances 实例总数："+variable.get("nrOfInstances")); System.out.println("nrOfActiveInstances 当前还没有完成的实例个数："+variable.get("nrOfActiveInstances")); System.out.println("nrOfCompletedInstances 当前完成的实例个数数：："+variable.get("nrOfCompletedInstances")); &#125;挂起激活12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667/** * 挂起流程实例 * * @param processInstanceId * @return */ boolean suspendProcessInstanceById(String processInstanceId); /** * 删除流程实例 * * @param processInstanceId * @param reason * @return */ boolean deleteProcessInstance(String processInstanceId, String reason); /** * 激活流程实例（激活挂起的流程实例） * * @param processInstanceId * @return */ boolean activateProcessInstanceById(String processInstanceId); /** * 挂起流程定义 * * @param processDefineKey * @param cascade * @return */ boolean suspendProcessDefineKey(String processDefineKey, boolean cascade); /** * 激活流程定义 * * @param processDefineKey * @param cascade * @return */ boolean activateProcessDefinitionByKey(String processDefineKey, boolean cascade);@Override public boolean suspendProcessInstanceById(String processInstanceId) &#123; runtimeService.suspendProcessInstanceById(processInstanceId); return true; &#125; @Override public boolean activateProcessInstanceById(String processInstanceId) &#123; runtimeService.activateProcessInstanceById(processInstanceId); return true; &#125; @Override public boolean suspendProcessDefineKey(String processDefineKey, boolean cascade) &#123; repositoryService.suspendProcessDefinitionByKey(processDefineKey,cascade,new Date()); return true; &#125; @Override public boolean activateProcessDefinitionByKey(String processDefineKey,boolean cascade)&#123; repositoryService.activateProcessDefinitionByKey(processDefineKey,cascade,new Date()); return true; &#125;github地址：https://github.com/wsylp/gms.git]]></content>
      <categories>
        <category>activiti</category>
      </categories>
      <tags>
        <tag>activiti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[activiti初体验(六) 排他网关]]></title>
    <url>%2Factiviti%E5%88%9D%E4%BD%93%E9%AA%8C-%E5%85%AD-%E6%8E%92%E4%BB%96%E7%BD%91%E5%85%B3%2F</url>
    <content type="text"><![CDATA[有时候需要进行判断走哪一个分支，而且像上一篇，如果存的删除不正确就会出现异常，此时的排他网关可以设置默认值。流程图与定义 核心代码上面两篇已经讲述了基本操作这里仅仅进行主要代码1234567@Test public void getTaskByloginName() &#123; String loginName = "0004"; String processDefinitionKey = "gateway"; // 任务处理人【0003】流程名称【采购申请】任务id【10006】流程定义id【buyBill:2:2504】 activitiService.getTaskByLoginName(processDefinitionKey, loginName); &#125;日志12345[21:21:15:453] [INFO] - wsylp.service.impl.ActivitiServiceImpl.getTaskByLoginName(ActivitiServiceImpl.java:185) - 任务处理人【gy】[21:21:15:453] [INFO] - wsylp.service.impl.ActivitiServiceImpl.getTaskByLoginName(ActivitiServiceImpl.java:186) - 流程名称【普通[处理]】[21:21:15:453] [INFO] - wsylp.service.impl.ActivitiServiceImpl.getTaskByLoginName(ActivitiServiceImpl.java:187) - 任务id【35014】[21:21:15:453] [INFO] - wsylp.service.impl.ActivitiServiceImpl.getTaskByLoginName(ActivitiServiceImpl.java:188) - 流程定义id【gateway:1:32504】[21:21:15:453] [INFO] - wsylp.service.impl.ActivitiServiceImpl.getTaskByLoginName(ActivitiServiceImpl.java:189) - 执行对象id【35001】github地址：https://github.com/wsylp/gms.git]]></content>
      <categories>
        <category>activiti</category>
      </categories>
      <tags>
        <tag>activiti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[activiti初体验(五) 变量设置与获取]]></title>
    <url>%2Factiviti%E5%88%9D%E4%BD%93%E9%AA%8C-%E4%BA%94-%E5%8F%98%E9%87%8F%E8%AE%BE%E7%BD%AE%E4%B8%8E%E8%8E%B7%E5%8F%96%2F</url>
    <content type="text"><![CDATA[变量设置与获取流程图以及属性 发布流程并开始12345678910111213141516171819202122232425/** * setValiable 与 setLocalValiable作用域不同 */ @Test public void deploeyFlow() &#123; String folderPath = "study/activiti/diagrams/sequenceFlow"; HashMap&lt;String, String&gt; map = new HashMap&lt;&gt;(); map.put("name", "连线流程");// 名称 map.put("id", "sequenceFlow");// id map.put("category", "办公流程");// 类别 activitiService.devlopActiviti(folderPath, map); &#125; @Test public void startActiviti() &#123; String processDefinitionKey = "sequenceFlow"; String orgCode = "070067801"; // 设置变量 HashMap&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put("createLoginName", "0003"); map.put("orgCode", orgCode); activitiService.startActiviti(processDefinitionKey, map); &#125;此时没有完成第一个任务。设置变量并获取变量1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@Test public void setVariable() &#123; // String excutionId = "25001"; String taskId = "10008"; HashMap&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put("message", "重要"); boolean isLocal = true; // activitiService.setVariableByExcutionId(excutionId, isLocal, map); activitiService.setVariableByTaskId(taskId, isLocal, map); &#125; @Test public void getVariable() &#123; // String excutionId = "10001"; String taskId = "10008"; Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); boolean isLocal = false; //map = activitiService.getVariableByExcutionId(excutionId, isLocal ); map = activitiService.getVariableByTaskId(taskId, isLocal); LOGGER.info("message【&#123;&#125;】",(String)map.get("message")); //SequenceFlow sequenceFlow = activitiService.getVariableByTaskId(taskId, "sequenceFlow", SequenceFlow.class); // LOGGER.info("创建时间【&#123;&#125;】", sequenceFlow.getDate()); &#125; @Override public boolean setVariableByTaskId(String taskId, boolean isLocal, HashMap&lt;String, Object&gt; map) &#123; /* * taskService.setVariable(taskId, variableName, value); * * 设置本执行对象的变量，该作用域只在当前的executionId中 taskService.setVariableLocal(taskId, * variableName, value); 可以设置对个变量，放在map中 */ if (isLocal) &#123; taskService.setVariablesLocal(taskId, map); &#125; else &#123; taskService.setVariables(taskId, map); &#125; return true; &#125; @Override public Map&lt;String, Object&gt; getVariableByTaskId(String taskId, boolean isLocal) &#123; Map&lt;String, Object&gt; variablesMap = new HashMap&lt;String, Object&gt;(); if (isLocal) &#123; variablesMap = taskService.getVariablesLocal(taskId); &#125; else &#123; variablesMap = taskService.getVariables(taskId); &#125; return variablesMap; &#125;日志12[20:39:24:795] [INFO] - wsylp.log.MyLog.logAfter(MyLog.java:29) - @AfterReturning：wsylp.service.ActivitiService.getVariableByTaskId end.[20:39:24:795] [INFO] - serviceTest.ActivitiVariableTest.getVariable(ActivitiVariableTest.java:172) - message【重要】设置变量为对象如果变量为对象需要实现序列化接口1234567891011121314151617181920212223242526272829303132public class SequenceFlow implements Serializable &#123; private static final long serialVersionUID = -1164661902871465047L; private String message;//信息（重要，不重要） private String createLoginName;// 申请人 private Date date;// 申请日期 public String getMessage() &#123; return message; &#125; public void setMessage(String message) &#123; this.message = message; &#125; public String getCreateLoginName() &#123; return createLoginName; &#125; public void setCreateLoginName(String createLoginName) &#123; this.createLoginName = createLoginName; &#125; public Date getDate() &#123; return date; &#125; public void setDate(Date date) &#123; this.date = date; &#125;&#125;设置变量12345678910111213141516171819202122232425262728293031323334353637/** * 设置流程变量值 */ @Test public void setVariablesByBean() &#123; String taskId = "10008"; /** * 支持的变量类型 * * &lt;br&gt; * 简单类型：String boolean Integer double date &lt;br&gt; * 自定义对象bean */ // 传递的是一个自定义的bean对象 SequenceFlow sequenceFlow = new SequenceFlow(); sequenceFlow.setCreateLoginName("0003"); sequenceFlow.setDate(new Date()); sequenceFlow.setMessage("重要"); activitiService.setVariableByTaskId(taskId, "sequenceFlow", sequenceFlow); &#125; @Test public void getVariable() &#123; // String excutionId = "10001"; String taskId = "10008"; Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); boolean isLocal = false; //map = activitiService.getVariableByExcutionId(excutionId, isLocal ); // map = activitiService.getVariableByTaskId(taskId, isLocal); //LOGGER.info("message【&#123;&#125;】",(String)map.get("message")); SequenceFlow sequenceFlow = activitiService.getVariableByTaskId(taskId, "sequenceFlow", SequenceFlow.class); LOGGER.info("创建时间【&#123;&#125;】", sequenceFlow.getDate()); &#125;日志12[20:45:47:841] [INFO] - wsylp.log.MyLog.logAfter(MyLog.java:29) - @AfterReturning：wsylp.service.ActivitiService.getVariableByTaskId end.[20:45:47:841] [INFO] - serviceTest.ActivitiVariableTest.getVariable(ActivitiVariableTest.java:175) - 创建时间【2018-06-17T20:45:24.240+0800】由于此时串的message为重要，那么下一个审批人为总经理完成任务并查询由于变量设置在sequenceFlow上，尽量设置变量为全局的。或者设置在执行对象上。1[20:53:50:698] [INFO] - wsylp.service.impl.ActivitiServiceImpl.finshTask(ActivitiServiceImpl.java:148) - 完成任务【10008】github地址：https://github.com/wsylp/gms.git]]></content>
      <categories>
        <category>activiti</category>
      </categories>
      <tags>
        <tag>activiti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[activiti初体验(四) 基本操作]]></title>
    <url>%2Factiviti%E5%88%9D%E4%BD%93%E9%AA%8C-%E5%9B%9B-%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[流程图展示流程图流程图的常用元素很简单，开启，结束为必要的。一个完生的流程图如下所示：左边为开始（startEvent），右边为结束(endEvent)，中间为活动(任务Task)，箭头的线 (SequenceFlow)开发之前我们需要给eclipse安装activiti插件，个人建议使用eclipse，感觉idea对流程图的插件支持不是很好。安装插件以及画流程图这里不再陈述，大家可以自己百度。由于设计开发中activiti提供的用户相关的表很难满足我们项目的需要，一般使用项目本身的角色信息表。而且在开发中审批人甚少指定为某一个人，一般为角色。在之前的工作中使用的为分离式的流程引擎，配置角色生产与测试经常要维护两个表，不方便，这里提供了自己的一个实现逻辑。简单配置配置流程点击空白处—-》eclipse窗口会出现属性的配置：配置id(流程图的id)与name（流程图的名称）配置人点击请假审批的task，填写id与name（当前活动的id与name），再点击Main config，再assiness框中填写任务代理人，图片中的表达式为获取该流程中的变量，变量的属性为：createLoginName 设置审批【副总】的审批人，此时使用的为角色，查询待办时，是根据登录人查询出角色再次进行查询待办任务的。流程发布1234567891011121314151617181920212223 @Test public void deplomentActiviti() &#123; String folderPath = "study/activiti/diagrams/leaveBill"; HashMap&lt;String, String&gt; map = new HashMap&lt;&gt;(); map.put("name", "请假流程");// 名称 map.put("id", "leaveBill");// id map.put("category", "办公流程");// 类别 activitiService.devlopActiviti(folderPath, map); &#125;@Override public boolean devlopActiviti(String folderPath, HashMap&lt;String, String&gt; map) &#123; Deployment deploy = repositoryService.createDeployment()// 创建一个部署构建器 .addClasspathResource(folderPath + File.separator + map.get("id") + ".bpmn")// 从类路径一次只能添加一个文件 .addClasspathResource(folderPath + File.separator + map.get("id") + ".png")// 流程图片 .name(map.get("name")).category(map.get("category")).deploy(); LOGGER.info("流程名称【 &#123;&#125;】", deploy.getName()); LOGGER.info("流程id【&#123;&#125;】", deploy.getId()); LOGGER.info("流程类别【&#123;&#125;】", deploy.getCategory()); return true; &#125;日志123[18:18:11:735] [INFO] - wsylp.service.impl.ActivitiServiceImpl.devlopActiviti(ActivitiServiceImpl.java:95) - 流程名称【 请假流程】[18:18:11:735] [INFO] - wsylp.service.impl.ActivitiServiceImpl.devlopActiviti(ActivitiServiceImpl.java:96) - 流程id【1】[18:18:11:735] [INFO] - wsylp.service.impl.ActivitiServiceImpl.devlopActiviti(ActivitiServiceImpl.java:97) - 流程类别【办公流程】数据库 开启流程由于第一个工作项审批人Assignee为“#{createLoginName}”,在进行开启任务的时候需要设置createLoginName参数：123456789101112131415161718192021222324252627@Test public void startActiviti() &#123; String processDefinitionKey = "leaveBill"; String orgCode = "070067801"; // 设置变量 HashMap&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put("createLoginName", "0003"); map.put("orgCode", orgCode); activitiService.startActivitiAndFinsh(processDefinitionKey, map); &#125; @Override public boolean startActivitiAndFinsh(String processDefinitionKey, HashMap&lt;String, Object&gt; map) &#123; // 取得流程实例 ProcessInstance processInstance = runtimeService.startProcessInstanceByKey(processDefinitionKey, map); LOGGER.info("流程(流程执行对象实例)id【&#123;&#125;】", processInstance.getId());// execution对象 LOGGER.info("流程实例id:【&#123;&#125;】", processInstance.getProcessInstanceId());// processInstance对象 LOGGER.info("流程定义id【&#123;&#125;】", processInstance.getProcessDefinitionId());// 默认为最新的id LOGGER.info("流程实例id【&#123;&#125;】", processInstance.getSuperExecutionId()); List&lt;Task&gt; tasks = this.getTaskByDeploymentId(processInstance.getDeploymentId(), processDefinitionKey, processInstance.getId(), (String) map.get("createLoginName")); for (Task task : tasks) &#123; this.finshTask(task.getId()); &#125; return true; &#125;上面代码中：processInstance.getId()也就是executionId的id(该流程的id)日志123456[19:27:55:914] [INFO] - wsylp.service.impl.ActivitiServiceImpl.startActivitiAndFinsh(ActivitiServiceImpl.java:132) - 流程(流程执行对象实例)id【2501】[19:27:55:914] [INFO] - wsylp.service.impl.ActivitiServiceImpl.startActivitiAndFinsh(ActivitiServiceImpl.java:133) - 流程实例id:【2501】[19:27:55:914] [INFO] - wsylp.service.impl.ActivitiServiceImpl.startActivitiAndFinsh(ActivitiServiceImpl.java:134) - 流程定义id【leaveBill:1:4】[19:27:55:914] [INFO] - wsylp.service.impl.ActivitiServiceImpl.startActivitiAndFinsh(ActivitiServiceImpl.java:135) - 流程实例id【null】[19:29:33:040] [DEBUG] - org.activiti.engine.impl.interceptor.LogInterceptor.execute(LogInterceptor.java:33) -查询任务查询任务的方法有很多，这里只是用几个简单的：12345678910111213141516171819202122232425262728293031323334353637383940414243444546 @Override public boolean getTasks() &#123; TaskQuery taskQuery = taskService.createTaskQuery(); // 任务列表 List&lt;Task&gt; list = taskQuery.list(); for (Task task : list) &#123; LOGGER.info("任务处理人【&#123;&#125;】,任务id【&#123;&#125;】,任务名称【&#123;&#125;】,任务流程定义id【&#123;&#125;】, 流程定义key【&#123;&#125;】,任务拥有者【&#123;&#125;】 ", task.getAssignee(), task.getId(), task.getName(), task.getProcessDefinitionId(), task.getTaskDefinitionKey(), task.getOwner()); &#125; return true; &#125; @Override public List&lt;Task&gt; getTaskByDeploymentId(String deploymentId, String processDefinitionKey, String executionId, String loginName) &#123; List&lt;Task&gt; list = taskService.createTaskQuery().processDefinitionKey(processDefinitionKey) .deploymentId(deploymentId).taskAssignee(loginName).executionId(executionId).list(); // 获取当前人的 return list; &#125;@Override public boolean getTaskByLoginName(String processDefinitionKey, String loginName) &#123; TaskQuery taskQuery = taskService.createTaskQuery(); // 查询登录人所在角色，在根据角色进行查询 List&lt;Role&gt; roleList = userService.getRolesByLoginName(loginName); for (Role role : roleList) &#123; // 任务列表 List&lt;Task&gt; list = taskQuery.processDefinitionKey(processDefinitionKey).taskAssignee(role.getRoleCode()) // . taskCandidateUser(assignee) .list();// 组任务的办理人查询 for (Task task : list) &#123; LOGGER.info("任务处理人【&#123;&#125;】", task.getAssignee()); LOGGER.info("流程名称【&#123;&#125;】", task.getName()); LOGGER.info("任务id【&#123;&#125;】", task.getId()); LOGGER.info("流程定义id【&#123;&#125;】", task.getProcessDefinitionId()); LOGGER.info("执行对象id【&#123;&#125;】", task.getExecutionId()); &#125; &#125; return true; &#125;我们调用查询所有的任务getTasks进行查看，结果如下：1234@Test public void getTasks() &#123; activitiService.getTasks(); &#125;日志1wsylp.service.impl.ActivitiServiceImpl.getTasks(ActivitiServiceImpl.java:166) - 任务处理人【fzjl】,任务id【2513】,任务名称【审批[副总]】,任务流程定义id【leaveBill:1:4】, 流程定义key【fzsp】,任务拥有者【null】此时根据登录号进行调用，查看该用户是否能查到任务123456789[19:47:33:515] [DEBUG] - org.activiti.engine.impl.interceptor.LogInterceptor.execute(LogInterceptor.java:40) - --- TaskQueryImpl finished --------------------------------------------------------[19:47:33:515] [DEBUG] - org.activiti.engine.impl.interceptor.LogInterceptor.execute(LogInterceptor.java:41) - [19:47:33:515] [INFO] - wsylp.service.impl.ActivitiServiceImpl.getTaskByLoginName(ActivitiServiceImpl.java:185) - 任务处理人【fzjl】[19:47:33:515] [INFO] - wsylp.service.impl.ActivitiServiceImpl.getTaskByLoginName(ActivitiServiceImpl.java:186) - 流程名称【审批[副总]】[19:47:33:515] [INFO] - wsylp.service.impl.ActivitiServiceImpl.getTaskByLoginName(ActivitiServiceImpl.java:187) - 任务id【2513】[19:47:33:515] [INFO] - wsylp.service.impl.ActivitiServiceImpl.getTaskByLoginName(ActivitiServiceImpl.java:188) - 流程定义id【leaveBill:1:4】[19:47:33:515] [INFO] - wsylp.service.impl.ActivitiServiceImpl.getTaskByLoginName(ActivitiServiceImpl.java:189) - 执行对象id【2501】[19:47:33:515] [INFO] - wsylp.log.MyLog.logAfter(MyLog.java:29) - @AfterReturning：wsylp.service.ActivitiService.getTaskByLoginName end.与上文的结果一致数据库信息：完成任务1234567891011@Test public void finshTask() &#123; String taskId = "2513"; activitiService.finshTask(taskId); &#125; @Override public boolean finshTask(String taskId) &#123; taskService.complete(taskId); LOGGER.info("完成任务【&#123;&#125;】", taskId); return true; &#125;日志1[19:52:19:571] [INFO] - wsylp.service.impl.ActivitiServiceImpl.finshTask(ActivitiServiceImpl.java:148) - 完成任务【2513】查询流程信息1234567891011121314151617181920212223242526272829@Test public void getProcessDefin() &#123; String processDefinitionKey = "leaveBill"; activitiService.getProcessDefin(processDefinitionKey); &#125;@Override public boolean getProcessDefin(String processDefinitionKey) &#123; List&lt;ProcessDefinition&gt; list = repositoryService.createProcessDefinitionQuery() // .processDefinitionId(processDefinitionId)//流程定义id // BuyBill:1:10004 组成，proDefiKey(流程定义的key) + version(版本) + 自动生成的id .processDefinitionKey(processDefinitionKey)// 流程定义的key // .processDefinitionName(processDefinitionName)//流程定义名称 // .processDefinitionVersion(processDefinitionVersion)//流程定义版本 // .latestVersion()//最新版本 // .orderByProcessDefinitionName().desc()//安装版本降序排序 // .count()//统计结果 // .listPage(firstResult, maxResults)//分页查询 .list(); // 遍历结果 for (ProcessDefinition processDefinition : list) &#123; LOGGER.info("流程定义id【&#123;&#125;】", processDefinition.getId()); LOGGER.info("流程定义的key【&#123;&#125;】", processDefinition.getKey()); LOGGER.info("流程部署id【&#123;&#125;】", processDefinition.getDeploymentId()); LOGGER.info("流程定义的版本【&#123;&#125;】", processDefinition.getVersion()); LOGGER.info("流程资源名称【&#123;&#125;】", processDefinition.getResourceName()); &#125; return true; &#125;日志12345[19:56:53:960] [INFO] - wsylp.service.impl.ActivitiServiceImpl.getProcessDefin(ActivitiServiceImpl.java:221) - 流程定义id【leaveBill:1:4】[19:56:53:960] [INFO] - wsylp.service.impl.ActivitiServiceImpl.getProcessDefin(ActivitiServiceImpl.java:222) - 流程定义的key【leaveBill】[19:56:53:960] [INFO] - wsylp.service.impl.ActivitiServiceImpl.getProcessDefin(ActivitiServiceImpl.java:223) - 流程部署id【1】[19:56:53:960] [INFO] - wsylp.service.impl.ActivitiServiceImpl.getProcessDefin(ActivitiServiceImpl.java:224) - 流程定义的版本【1】[19:56:53:960] [INFO] - wsylp.service.impl.ActivitiServiceImpl.getProcessDefin(ActivitiServiceImpl.java:225) - 流程资源名称【study/activiti/diagrams/leaveBill\leaveBill.bpmn】流程图123456789101112131415161718192021222324252627282930313233@Test public void getProcessImage() &#123; String deploymentId = &quot;1&quot;; activitiService.getProcessImage(deploymentId); &#125; @Override public boolean getProcessImage(String deploymentId) &#123; List&lt;String&gt; resourceNames = repositoryService.getDeploymentResourceNames(deploymentId); for (String resourceName : resourceNames) &#123; if (resourceName.endsWith(&quot;.png&quot;)) &#123; LOGGER.info(&quot;流程资源名称【&#123;&#125;】&quot;, resourceName); /** * 读取资源 * * @params deploymentId 部署id * @params resourceName 资源文件名 */ try &#123; InputStream resourceAsStream = repositoryService.getResourceAsStream(deploymentId, resourceName); // 把流写入到文件中 String pathName = &quot;E:/&quot; + resourceName; File file = new File(pathName); FileUtils.copyInputStreamToFile(resourceAsStream, file); LOGGER.info(&quot;输出完成&quot;); &#125; catch (Exception e) &#123; LOGGER.error(e.getMessage()); &#125; &#125; &#125; return true; &#125;日志1[19:59:51:558] [INFO] - wsylp.service.impl.ActivitiServiceImpl.getProcessImage(ActivitiServiceImpl.java:235) - 流程资源名称【study/activiti/diagrams/leaveBill\leaveBill.png】流程状态123456789101112131415161718@Test public void getProcessInstanceStateByProcessInstanceId() &#123; String processInstanceId = "2501"; activitiService.getProcessInstanceStateByProcessInstanceId(processInstanceId); &#125;@Override public void getProcessInstanceStateByProcessInstanceId(String processInstanceId) &#123; ProcessInstance pi = runtimeService.createProcessInstanceQuery().processInstanceId(processInstanceId) .singleResult();// 返回数据结果，要么单行，要么是空，其他情况报错; if (pi != null) &#123; LOGGER.info("该流程实例【&#123;&#125;】正在运行.....", processInstanceId); LOGGER.info("当前活动的任务【&#123;&#125;】,名称为", pi.getActivityId()); &#125; else &#123; LOGGER.info("该任务已经结束。。。"); &#125; &#125;日志12 [20:05:13:657] [INFO] - wsylp.service.impl.ActivitiServiceImpl.getProcessInstanceStateByProcessInstanceId(ActivitiServiceImpl.java:344) - 该流程实例【2501】正在运行.....[20:05:13:657] [INFO] - wsylp.service.impl.ActivitiServiceImpl.getProcessInstanceStateByProcessInstanceId(ActivitiServiceImpl.java:345) - 当前活动的任务【zglsp】,名称为历史流程实例12345678910111213141516 @Test public void getHistoryProcinst() &#123; activitiService.getHistoryProcinst(); &#125;@Override public void getHistoryProcinst() &#123; List&lt;HistoricProcessInstance&gt; list = historyService.createHistoricProcessInstanceQuery().list(); if (list != null &amp;&amp; list.size() &gt; 0) &#123; for (HistoricProcessInstance m : list) &#123; LOGGER.info("历史的流程实例【&#123;&#125;】", m.getId()); LOGGER.info("历史流程定义id【&#123;&#125;】", m.getProcessDefinitionId()); LOGGER.info("历史流程实例开始时间&#123;&#125;----结束时间:&#123;&#125;---&gt;", m.getStartTime(), m.getEndTime()); &#125; &#125; &#125;日志123 [20:08:24:169] [INFO] - wsylp.service.impl.ActivitiServiceImpl.getHistoryProcinst(ActivitiServiceImpl.java:357) - 历史的流程实例【2501】[20:08:24:169] [INFO] - wsylp.service.impl.ActivitiServiceImpl.getHistoryProcinst(ActivitiServiceImpl.java:358) - 历史流程定义id【leaveBill:1:4】[20:08:24:169] [INFO] - wsylp.service.impl.ActivitiServiceImpl.getHistoryProcinst(ActivitiServiceImpl.java:359) - 历史流程实例开始时间2018-06-17T19:27:55.742+0800----结束时间:null---&gt;查询历史任务1234567891011121314151617181920@Test public void getHistoryTaskByProcessInstanceId() &#123; String processInstanceId = "2501"; activitiService.getHistoryTaskByProcessInstanceId(processInstanceId); &#125; @Override public void getHistoryTaskByProcessInstanceId(String processInstanceId) &#123; List&lt;HistoricTaskInstance&gt; list = historyService.createHistoricTaskInstanceQuery() .processInstanceId(processInstanceId).list(); if (list != null &amp;&amp; list.size() &gt; 0) &#123; for (HistoricTaskInstance m : list) &#123; LOGGER.info("历史的流程任务【&#123;&#125;】", m.getId()); LOGGER.info("历史流程定义id【&#123;&#125;】", m.getProcessDefinitionId()); LOGGER.info("历史任务名称【&#123;&#125;】", m.getName()); LOGGER.info("历史任务实例处理人【&#123;&#125;】", m.getAssignee()); &#125; &#125; &#125;日志12345678910111213[20:11:51:095] [INFO] - wsylp.service.impl.ActivitiServiceImpl.getHistoryTaskByProcessInstanceId(ActivitiServiceImpl.java:372) - 历史的流程任务【2510】[20:11:51:095] [INFO] - wsylp.service.impl.ActivitiServiceImpl.getHistoryTaskByProcessInstanceId(ActivitiServiceImpl.java:373) - 历史流程定义id【leaveBill:1:4】[20:11:51:095] [INFO] - wsylp.service.impl.ActivitiServiceImpl.getHistoryTaskByProcessInstanceId(ActivitiServiceImpl.java:374) - 历史任务名称【请假申请】[20:11:51:095] [INFO] - wsylp.service.impl.ActivitiServiceImpl.getHistoryTaskByProcessInstanceId(ActivitiServiceImpl.java:375) - 历史任务实例处理人【0003】[20:11:51:095] [INFO] - wsylp.service.impl.ActivitiServiceImpl.getHistoryTaskByProcessInstanceId(ActivitiServiceImpl.java:372) - 历史的流程任务【2513】[20:11:51:095] [INFO] - wsylp.service.impl.ActivitiServiceImpl.getHistoryTaskByProcessInstanceId(ActivitiServiceImpl.java:373) - 历史流程定义id【leaveBill:1:4】[20:11:51:095] [INFO] - wsylp.service.impl.ActivitiServiceImpl.getHistoryTaskByProcessInstanceId(ActivitiServiceImpl.java:374) - 历史任务名称【审批[副总]】[20:11:51:095] [INFO] - wsylp.service.impl.ActivitiServiceImpl.getHistoryTaskByProcessInstanceId(ActivitiServiceImpl.java:375) - 历史任务实例处理人【fzjl】[20:11:51:095] [INFO] - wsylp.service.impl.ActivitiServiceImpl.getHistoryTaskByProcessInstanceId(ActivitiServiceImpl.java:372) - 历史的流程任务【5002】[20:11:51:095] [INFO] - wsylp.service.impl.ActivitiServiceImpl.getHistoryTaskByProcessInstanceId(ActivitiServiceImpl.java:373) - 历史流程定义id【leaveBill:1:4】[20:11:51:095] [INFO] - wsylp.service.impl.ActivitiServiceImpl.getHistoryTaskByProcessInstanceId(ActivitiServiceImpl.java:374) - 历史任务名称【审批[总经理]】[20:11:51:095] [INFO] - wsylp.service.impl.ActivitiServiceImpl.getHistoryTaskByProcessInstanceId(ActivitiServiceImpl.java:375) - 历史任务实例处理人【zjl】删除流程定义删除一般选择级联删除，否则如果路ice好难过定义已经启动就会报错123456789101112@Test public void deleteDeploment() &#123; String deploymentId = "1"; boolean cascade = true; activitiService.deleteDeployment(deploymentId, cascade); // activitiService.deleteDeployment(deploymentId); &#125; @Override public boolean deleteDeployment(String deploymentId, boolean cascade) &#123; repositoryService.deleteDeployment(deploymentId, cascade); return true; &#125;github地址：https://github.com/wsylp/gms.git]]></content>
      <categories>
        <category>activiti</category>
      </categories>
      <tags>
        <tag>activiti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[activiti初体验(三) 创建数据库]]></title>
    <url>%2Factiviti%E5%88%9D%E4%BD%93%E9%AA%8C-%E4%B8%89-%E5%88%9B%E5%BB%BA%E6%95%B0%E6%8D%AE%E5%BA%93%2F</url>
    <content type="text"><![CDATA[创建数据库数据库activiti创建数据库有三种方式，但是在实际开中，一般都是默认配置。而且为了操作方便，一般activiti数据库与项目数据库都会进行分开管理。123456789101112131415161718192021222324252627@Override public boolean createtableByXml() &#123; /** * 创建数据库的三种方式 * 1：指定xml * 2： 默认xml（activiti.cfg.xml） * 3:不需要xml public void createTable()&#123; ProcessEngineConfiguration configuration = ProcessEngineConfiguration.createStandaloneProcessEngineConfiguration(); configuration.setJdbcDriver("com.mysql.jdbc.Driver"); configuration.setJdbcUrl("jdbc:mysql://192.168.2.163:3306/activiti?createDatabaseIfNotExist=true&amp;useUnicode=true&amp;characterEncoding=utf-8&amp;zeroDateTimeBehavior=convertToNull"); configuration.setJdbcUsername("root"); configuration.setJdbcPassword("root"); configuration.setDatabaseSchema(ProcessEngineConfiguration.DB_SCHEMA_UPDATE_TRUE); ProcessEngine processEngine = configuration.buildProcessEngine(); &#125; */ ProcessEngineConfiguration engineConfiguration = ProcessEngineConfiguration //1:指定xml .createProcessEngineConfigurationFromResource("gms/spring-activiti.xml"); //2:默认xml // .createProcessEngineConfigurationFromResourceDefault(); engineConfiguration.buildProcessEngine(); LOGGER.info("创建成功"); return true; &#125;jdbc.properties123456789101112driverClass=com.mysql.jdbc.DriverjdbcUrl=jdbc:mysql://192.168.2.163:3306/gmsdb?useUnicode=true&amp;characterEncoding=utf-8&amp;zeroDateTimeBehavior=convertToNulljdbcUrlActi=jdbc:mysql://192.168.2.163:3306/activiti?createDatabaseIfNotExist=true&amp;useUnicode=true&amp;characterEncoding=utf-8&amp;zeroDateTimeBehavior=convertToNullusername=rootpassword=rootinitialSize=0maxActive=20maxIdle=20minIdle=1maxWait=60000github地址：https://github.com/wsylp/gms.git]]></content>
      <categories>
        <category>activiti</category>
      </categories>
      <tags>
        <tag>activiti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[activiti初体验(二) 数据库与配置文件]]></title>
    <url>%2Factiviti%E5%88%9D%E4%BD%93%E9%AA%8C-%E4%BA%8C-%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[数据库与配置文件activit jar包123456789101112&lt;!-- activiti jar --&gt; &lt;dependency&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-engine&lt;/artifactId&gt; &lt;version&gt;$&#123;activiti.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- activiti 与 Spring 集成 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-spring&lt;/artifactId&gt; &lt;version&gt;$&#123;activiti.version&#125;&lt;/version&gt; &lt;/dependency&gt;spring-activitici.xml1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"&gt; &lt;!-- 配置数据源 --&gt; &lt;bean id="dataSource_act" class="org.apache.commons.dbcp.BasicDataSource" destroy-method="close"&gt; &lt;property name="driverClassName" value="$&#123;driverClass&#125;" /&gt; &lt;property name="url" value="$&#123;jdbcUrlActi&#125;" /&gt; &lt;property name="username" value="$&#123;username&#125;" /&gt; &lt;property name="password" value="$&#123;password&#125;" /&gt; &lt;/bean&gt; &lt;!-- 事务管理 --&gt; &lt;bean id="transactionManager_act" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;property name="dataSource" ref="dataSource_act" /&gt; &lt;/bean&gt; &lt;bean id="processEngineConfiguration" class="org.activiti.spring.SpringProcessEngineConfiguration"&gt; &lt;property name="dataSource" ref="dataSource_act" /&gt; &lt;property name="transactionManager" ref="transactionManager_act" /&gt; &lt;property name="databaseSchemaUpdate" value="true" /&gt; &lt;property name="jobExecutorActivate" value="false" /&gt; &lt;!-- Activit默认提供了4中历史级别： none: 不保存任何历史记录，可以提高系统性能； --&gt; &lt;!-- activity：保存所有的流程实例、任务、活动信息； audit：也是Activiti的默认级别，保存所有的流程实例、任务、活动、表单属性； --&gt; &lt;!-- full： 最完整的历史记录，除了包含audit级别的信息之外还能保存详细，例如：流程变量 --&gt; &lt;property name="history" value="full" /&gt; &lt;property name="databaseType" value="mysql" /&gt; &lt;property name="dbIdentityUsed" value="false" /&gt; &lt;!-- 不检测历史表是否存在,应对Activiti database problem: Tables missing for component(s) history, identity --&gt; &lt;property name="dbHistoryUsed" value="true" /&gt; &lt;!-- 发布时是否包括流程图片png --&gt; &lt;property name="createDiagramOnDeploy" value="false" /&gt; &lt;!-- 避免发布的图片和xml遇到中文时乱码 --&gt; &lt;property name="activityFontName" value="宋体" /&gt; &lt;property name="labelFontName" value="宋体" /&gt; &lt;!-- 解析xml流程文件所使用的字符集，默认为utf8，依据数据库来 --&gt; &lt;property name="xmlEncoding" value="utf8" /&gt; &lt;!-- &lt;property name="deploymentResources"&gt; 自动部署 &lt;list&gt; &lt;value&gt;classpath*:/study/activiti/diagrams/autoDeploy/*&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; --&gt; &lt;property name="processEngineLifecycleListener" ref="myProcessEngineLifecycleListener" /&gt; &lt;/bean&gt; &lt;bean id="processEngine" class="org.activiti.spring.ProcessEngineFactoryBean"&gt; &lt;property name="processEngineConfiguration" ref="processEngineConfiguration" /&gt; &lt;/bean&gt; &lt;bean id="repositoryService" factory-bean="processEngine" factory-method="getRepositoryService" /&gt; &lt;bean id="runtimeService" factory-bean="processEngine" factory-method="getRuntimeService" /&gt; &lt;bean id="taskService" factory-bean="processEngine" factory-method="getTaskService" /&gt; &lt;bean id="historyService" factory-bean="processEngine" factory-method="getHistoryService" /&gt; &lt;bean id="managementService" factory-bean="processEngine" factory-method="getManagementService" /&gt; &lt;!--自定发布资源文件处理，这里进行处理只有改动的流程引擎才会进行再次发布。 --&gt; &lt;!-- &lt;bean id="activitiDeployer" class="wsylp.plugins.WorkflowDeployer"&gt; &lt;property name="deploymentResources" value="classpath*:diagrams/autoDeploy" /&gt; &lt;/bean&gt; --&gt;&lt;/beans&gt;Acitiviti引擎配置日志本人使用的为log4j2版本12&lt;!-- activiti --&gt;&lt;logger name="org.activiti" level="debug" /&gt;]]></content>
      <categories>
        <category>activiti</category>
      </categories>
      <tags>
        <tag>activiti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[activiti初体验(一) 简介]]></title>
    <url>%2Factiviti%E5%88%9D%E4%BD%93%E9%AA%8C-%E4%B8%80-%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[初识activiti工作流（workflow）工作流总是以任务（Task）的形式驱动人处理业务或者驱动业务系统自动完成作业。–我们不必关注他人的工作进度，只要关心自己的待办任务即可。activiti活动activity的复数activities化简的方式标示活动的集合。来诠释activiti与工作流的母的与设计 。Tom Bayen(jbpm的创始人)自2010年离开jBoss加入alfresco公司后的又一力作。 第一版2010年5月发布。Activiti是一个针对企业用户、开发人员、系统管理员的轻量级工作流业务管理平台。其核心是使用Java开发的快速、稳定的BPMN2.0l流程引擎。BPMBPM：(Business Process Management)，业务流程管理，一套达成企业各种业务环节整合的全面管理模式。BPM是为了实现一定的经营目的而执行的一系列逻辑相关的集合。业务流程的输出是为了满足市场需要的产品或服务。企业流程管理一般分为生产流程层、运作层、计划层、战略层。BPM最早是由工作流与企业应用集成逐步融合发展起来的。当时为了满足无纸化办公需求进行设计的。现在BPM是一种企业集成技术，作为面向服务系统框架SOA（Service-Oriented Archirecture）、企业应用集成EAI（Enterprise Application Integration 、企业服务总线ESB（Enteprise Service Bus）的补充。工作流的生命周期定义：收集业务需求并转化为流程定义。一般由开发人员加工转化为计算机可以识别的流程定义。发布：将资源打包发布。执行：具体的流程引擎按照事先定义的流程处理线路以任务驱动的方式执行业务流程。监控：依赖执行阶段。跟具执行（Task）结果进行处理相应的操作。优化：一个完整的流程已经结束，进行优化、设计、改进等。BPMN（Business Process Modeling Noattion）业务流程建模标注，由BPM标准组织发布的。BPMN 1.0规范与2014年5月发布。BPMN 2.0规范与2011年发布。BPMN定义了业务流程图，是基于流程图技术，同时对创建业务流程操作的图形化模型进行裁剪。Activiti的特点1：数据持久化–mybaties2：引擎service接口3：流程设计器-插件4：原生支持Spring5：分离运行时与历史数据Activiti架构与组件Activiti Engine：核心模块，提供针对BOMN 2.0规范的解析、执行、创建、管理（任务、流程），查询历史记录并根据结果生成报表。Activiti Modeler ：模型设计器。Activiti Designer：功能和Activiti Modeler 类似。Activiti Exploer：用来管理仓库、用户、组、启动流程、任务办理等。Activiti REST：提供Restful风格的服务。github地址：https://github.com/wsylp/gms.git]]></content>
      <categories>
        <category>activiti</category>
      </categories>
      <tags>
        <tag>activiti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Web Service探索]]></title>
    <url>%2FWeb-Service%E6%8E%A2%E7%B4%A2%2F</url>
    <content type="text"><![CDATA[Web Service探索概念Web Service也称作XMl Web Service.XML是Web Service的基础.是应用程序组件,是独立的并可以自我描述的,它是使用的开放协议进行通信,可通过使用UDDI来发现,可以被其他应用程序使用.如何工作通过SOAP在Web上提供的软件服务，使用WSDL文件进行说明，并通过UDDI进行注册。web service三要素SOAP、WSDL(WebServicesDescriptionLanguage)、UDDI(UniversalDescriptionDiscovery andIntegration);soap用来描述传递信息的格式,WSDL 用来描述如何访问具体的接口， uddi用来管理，分发，查询webService 。XML：(Extensible Markup Language)扩展型可标记语言。面向短期的临时数据处理、面向万维网络，是Soap的基础。Soap：(Simple Object Access Protocol)简单对象存取协议。是XML Web Service 的通信协议。当用户通过UDDI找到你的WSDL描述文档后，他通过可以SOAP调用你建立的Web服务中的一个或多个操作。SOAP是XML文档形式的调用方法的规范，它可以支持不同的底层接口，像HTTP(S)或者SMTP. SOAP 可以和现存的许多因特网协议和格式结合使用，包括超文本传输协议（HTTP），简单邮件传输协议（SMTP），多用途网际邮件扩充协议（MIME）。它还支持从消息系统到远程过程调用（RPC）等大量的应用程序。SOAP使用基于XML的数据结构和超文本传输协议(HTTP)的组合定义了一个标准的方法来使用Internet上各种不同操作环境中的分布式对象。WSDL：(Web Services Description Language) WSDL 文件是一个 XML 文档，用于说明一组 SOAP 消息以及如何交换这些消息。大多数情况下由软件自动生成和使用。UDDI (Universal Description, Discovery, and Integration) 是一个主要针对Web服务供应商和使用者的新项目。在用户能够调用Web服务之前，必须确定这个服务内包含哪些商务方法，找到被调用的接口定义，还要在服务端来编制软件，UDDI是一种根据描述文档来引导系统查找相应服务的机制。UDDI利用SOAP消息机制（标准的XML/HTTP）来发布，编辑，浏览以及查找注册信息。它采用XML格式来封装各种不同类型的数据，并且发送到注册中心或者由注册中心来返回需要的数据。webservice现在应用的非常广泛,概念的东西这里就不在赘述了,闲话少说,我喜欢用代码来进行学习,现在开始我们的第一步.使用java进行发布这里定义了一个接口与一个实现类，用来进行发布。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849**接口**/** * 使用java发布接口 * Created by wsylp on 2017/10/17. */@WebServicepublic interface JavaPublish &#123; void publish(String name);&#125;**实现**/** * 实现接口 * Created by wsylp on 2017/10/17. */@WebService( serviceName = "JavaPublish", portName = "JavaPublishPort", endpointInterface = "wsylp.ws.jdkPub.JavaPublish")public class JavaPublishImpl implements JavaPublish &#123; @Override public void publish(String name) &#123; System.out.println("我们使用java进行发布:" + name); &#125;&#125;@WebService用来定义该类是一个webservice**服务端**这里简单的使用java main方法进行发布上面的接口与实现import javax.xml.ws.Endpoint;/** * 用来发布WebService的服务端 * Created by wsylp on 2017/10/17. */public class Server &#123; public static void main(String[] args) &#123; //ws的服务地址,可以在浏览器中直接输入该地址,http://localhost/ismg/wsylp/javaPub/javaPub?wsdl String adress = "http://localhost/ismg/wsylp/javaPub/javaPub"; JavaPublish javaPublish = new JavaPublishImpl(); Endpoint.publish(adress,javaPublish); System.out.println("webservice 已经发布....."); &#125;&#125;我们运行Server的main方法就可以输入地址,进行查看,这个就是wsdl的xml文件,中间有方法名,参数等,大家可以进行仔细看下.使用wsimport命令我们进行调用的时候，可以使用java 自带的wsimport将wsdl大包为jar包，依赖后就可以进行调用。简单说明下wsimport(在java bin目录下)的命令wsimport wsdlAdress 默认为当前路径下进行解-d 表示输出的目录，目录必须事先存在，否则导出失败。-keep表示导出webservice的class文件时是否也导出源代码java文件。-verbose表示详细信息。例如:wsimport -d folder wsdladresswsimport -d folder -keep wsdladresswsimport -d folder -keep -verbose wsdlAdress123456现在我们使用命令进行打包:wsimport -d webservice -keep -verbose http://localhost/ismg/wsylp/javaPub/javaPub?wsdl现在进行打包:jar -cvf javaPub.jar wsylp/* : 将webservice目录下的所有文件压缩为jar文件等价于jar -cvf javaPub.jar * -c wsylp客户端调用引用jar进行测试123456789101112131415161718import wsylp.ws.jdkpub.JavaPublish;import wsylp.ws.jdkpub.JavaPublish_Service;/** * 测试引用的jar,进行webservice测试 * @author wsylp * */public class Client &#123; public static void main(String[] args) &#123; JavaPublish_Service ws = new JavaPublish_Service(); JavaPublish jp = ws.getJavaPublishPort(); jp.publish("哈哈"); &#125;&#125;结果:12webservice 已经发布.....我们使用java进行发布:哈哈如果你不想进行打包,你也可以进行这样操作123456789101112131415161718192021222324import java.net.URL;import javax.xml.namespace.QName;import javax.xml.ws.Service;import wsylp.ws.jdkpub.JavaPublish;public class DyClient &#123; public static void main(String[] args) &#123; try &#123; URL wsdl = new URL("http://localhost/ismg/wsylp/javaPub/javaPub?wsdl"); QName serviceName = new QName("http://jdkPub.ws.wsylp/", "JavaPublish"); QName portName = new QName("http://jdkPub.ws.wsylp/", "JavaPublishPort"); Service service = Service.create(wsdl, serviceName); JavaPublish jp = service.getPort(portName, JavaPublish.class); jp.publish("哈哈"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125;使用CXF框架简单介绍下CXF(引用百度百科)CXF：Apache CXF = Celtix + XFire，开始叫 Apache CeltiXfire，后来更名为 Apache CXF 。CXF 继承了 Celtix 和 XFire 两大开源项目的精华，提供了对 JAX-WS 全面的支持，并且提供了多种 Binding 、DataBinding、Transport 以及各种 Format 的支持，并且可以根据实际项目的需要，采用代码优先（Code First）或者 WSDL 优先（WSDL First）来轻松地实现 Web Services 的发布和使用。Apache CXF 是一个开源的 Services 框架，CXF 帮助您利用 Frontend 编程 API 来构建和开发 Services ，像 JAX-WS 。这些 Services 可以支持多种协议，比如：SOAP、XML/HTTP、RESTful HTTP 或者 CORBA ，并且可以在多种传输协议上运行，比如：HTTP、JMS 或者 JBI，CXF 大大简化了 Services 的创建，同时它继承了 XFire 传统，一样可以天然地和 Spring 进行无缝集成。在项目中我们不可能频繁的打包,在者使用java发布的方式的确比较繁琐,目前用的最多的就是CXF了.在这里我使用ssm框架与CXf进行整合:首先我说下使用的jar包:注意:本人使用的是gradle进行依赖的.1234compile group: 'org.apache.cxf', name: 'apache-cxf', version: '3.2.0', ext: 'pom'compile group: 'org.apache.cxf', name: 'cxf-rt-frontend-jaxws', version: '3.2.0'compile group: 'org.apache.cxf', name: 'cxf-rt-transports-http-jetty', version: '3.2.0'compile group: 'org.apache.cxf', name: 'cxf-rt-transports-http', version: '3.2.0'java代码接口123456789101112131415package wsylp.ws.spring_cxf;import javax.jws.WebMethod;import javax.jws.WebService;/** * Created by wsylp on 2017/10/19. */@WebServicepublic interface SpringCxfService &#123; @WebMethod void useSpringCxfService(String name);&#125;实现接口1234567891011121314151617package wsylp.ws.spring_cxf;import javax.jws.WebService;import org.springframework.stereotype.Component;/** - Created by wsylp on 2017/10/19. */@WebService@Componentpublic class SpringCxfServiceImpl implements SpringCxfService &#123; @Override public void useSpringCxfService(String name) &#123; System.out.println("使用spring与cxf进行使用wenservice:" + name); &#125;&#125;配置文件在这里我将CXF的配置文件进行单独编写(spring-cxf.xml)一定要在context中加载配置文件，不然后报错。在web.xml进行配置1234567891011121314&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring-m*.xml,classpath*:spring-cxf.xml&lt;/param-value&gt; &lt;/context-param&gt;&lt;servlet&gt; &lt;servlet-name&gt;CXFServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.apache.cxf.transport.servlet.CXFServlet&lt;/servlet-class&gt; &lt;load-on-startup&gt;2&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;CXFServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/ws/*&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;spring-cxf.xml配置这里采用的简单的配置,还有另外两种方式123456789101112131415&lt;jaxws:endpoint id="springCxfService" implementor="#springCxfServiceImpl" address="/mywebservice" &gt; &lt;/jaxws:endpoint&gt;&lt;!-- &lt;jaxws:server id="springCxfService" address="/mywebservice"&gt; &lt;jaxws:serviceBean&gt; &lt;ref bean="springCxfServiceImpl"/&gt; &lt;/jaxws:serviceBean&gt; &lt;/jaxws:server&gt;--&gt; &lt;!--simple方式进行发布--&gt; &lt;!-- &lt;simple:server id="springCxfService" serviceClass="#springCxfService" address="/mywebservice"&gt; &lt;simple:serviceBean&gt; &lt;ref bean="#springCxfServiceImpl"/&gt; &lt;/simple:serviceBean&gt; &lt;/simple:server&gt;--&gt;启动tomcat-我们可以输入项目http://localhost:8080/ismg/ws进行查看输入http://localhost:8080/ismg/ws/mywebservice?wsdl12345&lt;wsdl:definitions name="SpringCxfServiceImplService" targetNamespace="http://spring_cxf.ws.wsylp/"&gt;&lt;wsdl:types&gt;&lt;xs:schema elementFormDefault="unqualified" targetNamespace="http://spring_cxf.ws.wsylp/" version="1.0"&gt;&lt;xs:element name="useSpringCxfService" type="tns:useSpringCxfService"/&gt;&lt;xs:element name="useSpringCxfServiceResponse" type="tns:useSpringCxfServiceResponse"/&gt;&lt;xs:complexType name="useSpringCxfService"&gt;&lt;xs:sequence&gt;&lt;xs:element minOccurs="0" name="arg0" type="xs:string"/&gt;&lt;/xs:sequence&gt;&lt;/xs:complexType&gt;&lt;xs:complexType name="useSpringCxfServiceResponse"&gt;&lt;xs:sequence/&gt;&lt;/xs:complexType&gt;&lt;/xs:schema&gt;&lt;/wsdl:types&gt;&lt;wsdl:message name="useSpringCxfService"&gt;&lt;wsdl:part element="tns:useSpringCxfService" name="parameters"&gt; &lt;/wsdl:part&gt;&lt;/wsdl:message&gt;&lt;wsdl:message name="useSpringCxfServiceResponse"&gt;&lt;wsdl:part element="tns:useSpringCxfServiceResponse" name="parameters"&gt; &lt;/wsdl:part&gt;&lt;/wsdl:message&gt;&lt;wsdl:portType name="SpringCxfService"&gt;&lt;wsdl:operation name="useSpringCxfService"&gt;&lt;wsdl:input message="tns:useSpringCxfService" name="useSpringCxfService"&gt; &lt;/wsdl:input&gt;&lt;wsdl:output message="tns:useSpringCxfServiceResponse" name="useSpringCxfServiceResponse"&gt; &lt;/wsdl:output&gt;&lt;/wsdl:operation&gt;&lt;/wsdl:portType&gt;&lt;wsdl:binding name="SpringCxfServiceImplServiceSoapBinding" type="tns:SpringCxfService"&gt;&lt;soap:binding style="document" transport="http://schemas.xmlsoap.org/soap/http"/&gt;&lt;wsdl:operation name="useSpringCxfService"&gt;&lt;soap:operation soapAction="" style="document"/&gt;&lt;wsdl:input name="useSpringCxfService"&gt;&lt;soap:body use="literal"/&gt;&lt;/wsdl:input&gt;&lt;wsdl:output name="useSpringCxfServiceResponse"&gt;&lt;soap:body use="literal"/&gt;&lt;/wsdl:output&gt;&lt;/wsdl:operation&gt;&lt;/wsdl:binding&gt;&lt;wsdl:service name="SpringCxfServiceImplService"&gt;&lt;wsdl:port binding="tns:SpringCxfServiceImplServiceSoapBinding" name="SpringCxfServiceImplPort"&gt;&lt;soap:address location="http://localhost:8080/ismg/ws/mywebservice"/&gt;&lt;/wsdl:port&gt;&lt;/wsdl:service&gt;&lt;/wsdl:definitions&gt;调用webservice这里首先我们先测试一下,使用单元测试123456789101112@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = &#123;"classpath*:spring-*.xml"&#125;)public class WsTest &#123; @Autowired private SpringCxfService springCxfService; @Test public void testWs() &#123; springCxfService.useSpringCxfService("我在测试....."); &#125;&#125;测试结果12[21:53:01:290] [DEBUG] - org.apache.ibatis.logging.LogFactory.setImplementation(LogFactory.java:135) - Logging initialized using 'class org.apache.ibatis.logging.log4j2.Log4j2Impl' adapter.使用spring与cxf进行使用wenservice:我在测试.....在实际的项目中我们可以采取生成客户端的方式在eclipse中选中项目,new-&gt;other-&gt;搜索client-&gt;选中webservice client生成文件如下12345SpringCxfService.javaSpringCxfServiceImplService.javaSpringCxfServiceImplServiceLocator.javaSpringCxfServiceImplServiceSoapBindingStub.javaSpringCxfServiceProxy.java将生成的客户端当做service进行使用即可.REST与CXFREST是继SOAP之后有一种广泛使用的Web服务，但是REST没有WSDL,。rest，即REST（RepresentationalStateTransfer表述性状态转移）是一种针对网络应用的设计和开发方式，可以降低开发的复杂性，提高系统的可伸缩性。现如今在三种主流的Web服务实现方案中，因为REST模式的Web服务与复杂的SOAP和XML-RPC对比来讲明显的更加简洁，越来越多的web服务开始采用REST风格设计和实现。例如，Amazon.com提供接近REST风格的Web服务进行图书查找；雅虎提供的Web服务也是REST风格的。 (来自搜狗百科)REST 本质上是使用 URL 来访问资源的一种方式。请求方式：GET（查）、POST（增）、PUT（改）、DELETE（删）、HEAD、OPTIONS；GET用来获取资源，POST用来新建资源（也可以用于更新资源），PUT用来更新资源，DELETE用来删除资源。接口以及实现类用来发布的接口以及实现接口123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566package wsylp.ws.rest;import java.util.List;import java.util.Map;import javax.jws.WebService;import javax.ws.rs.Consumes;import javax.ws.rs.DELETE;import javax.ws.rs.FormParam;import javax.ws.rs.GET;import javax.ws.rs.POST;import javax.ws.rs.PUT;import javax.ws.rs.Path;import javax.ws.rs.PathParam;import javax.ws.rs.Produces;import javax.ws.rs.core.MediaType;import wsylp.po.User;/** * rest方式进行webservice * Created by wsylp on 2017/10/22. * * * 请求方式注解，包括：@GET、@POST、@PUT、@DELETE * 请求路径注解，包括：@Path，其中包括一个路径参数 * 数据格式注解，包括：@Consumes（输入）、@Produces（输出），可使用 MediaType 常量 * 相关参数注解，包括：@PathParam（路径参数）、@FormParam（表单参数），此外还有 @QueryParam（请求参数） * GET用来获取资源， * POST用来新建资源（也可以用于更新资源）， * PUT用来更新资源， * DELETE用来删除资源。 */public interface UserWebservice &#123; @GET @Path("/user") @Produces(MediaType.APPLICATION_JSON) List&lt;User&gt; getUser(); @GET @Path("/user/&#123;id&#125;") @Produces(MediaType.APPLICATION_JSON) User getUserById(@PathParam("id") long id); @POST @Path("/user") @Consumes(MediaType.APPLICATION_FORM_URLENCODED) @Produces(MediaType.APPLICATION_JSON) User updateUserByLoginName(@FormParam("loginName") String name); @POST @Path("/user") @Consumes(MediaType.APPLICATION_JSON) @Produces(MediaType.APPLICATION_JSON) User createUser(User user); @PUT @Path("/user/&#123;id&#125;") @Consumes(MediaType.APPLICATION_JSON) @Produces(MediaType.APPLICATION_JSON) User updateUserById(@PathParam("id") long id, Map&lt;String, Object&gt; fieldMap); @DELETE @Path("/user/&#123;id&#125;") @Produces(MediaType.APPLICATION_JSON) User deleteUserById(@PathParam("id") long id);&#125;实现（这里没有写实现方法的内部处理）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package wsylp.ws.rest;import java.util.List;import java.util.Map;import javax.jws.WebService;import javax.ws.rs.Consumes;import javax.ws.rs.DELETE;import javax.ws.rs.FormParam;import javax.ws.rs.GET;import javax.ws.rs.POST;import javax.ws.rs.PUT;import javax.ws.rs.Path;import javax.ws.rs.PathParam;import javax.ws.rs.Produces;import javax.ws.rs.core.MediaType;import org.springframework.stereotype.Component;import org.springframework.stereotype.Service;import wsylp.po.User;@Componentpublic class UserWebserviceImpl implements UserWebservice &#123; @Override public List&lt;User&gt; getUser() &#123; return null; &#125; @Override public User getUserById(long id) &#123; return null; &#125; @Override public User updateUserByLoginName(String name) &#123; return null; &#125; @Override public User createUser(User user) &#123; return null; &#125; @Override public User updateUserById(long id, Map&lt;String, Object&gt; fieldMap) &#123; return null; &#125; @Override public User deleteUserById(long id) &#123; return null; &#125;&#125;配置web.xml123456789101112131415&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;!-- ,classpath*:spring-cxf-rest.xml--&gt; &lt;param-value&gt;classpath:spring-m*.xml,classpath*:spring-cxf-rest.xml&lt;/param-value&gt; &lt;/context-param&gt;&lt;servlet&gt; &lt;servlet-name&gt;CXFServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.apache.cxf.transport.servlet.CXFServlet&lt;/servlet-class&gt; &lt;load-on-startup&gt;2&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;CXFServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/ws/*&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;配置spring-cxf-rest.xml123456789&lt;bean id="jsonProvider" class="com.fasterxml.jackson.jaxrs.json.JacksonJsonProvider"/&gt; &lt;jaxrs:server address="/rest"&gt; &lt;jaxrs:serviceBeans&gt; &lt;ref bean="userWebserviceImpl"/&gt; &lt;/jaxrs:serviceBeans&gt; &lt;jaxrs:providers&gt; &lt;ref bean="jsonProvider"/&gt; &lt;/jaxrs:providers&gt; &lt;/jaxrs:server&gt;启动tomcat并调用12345678910$(function() &#123; $.ajax(&#123; type: 'get', url: 'http://localhost:8080/ismg/ws/rest/user', dataType: 'json', success: function(data) &#123; console.log(data); &#125; &#125;); &#125;);由于没有写内部的代码，这里进行调用打断点的时候可以看到进入方法。后话实际的开发当中webservice都是给别的项目进行调用的，不在本项目中使用，因此一般会跨域。这部分没有测试（具体结果不清楚）使用 JSONP 解决 AJAX 跨域问题JSONP 的全称是 JSON with Padding，实际上是在需要返回的 JSON 数据外，用一个 JS 函数进行封装。可以这样来理解，服务器返回一个 JS 函数，参数是一个 JSON 数据，例如：callback({您的 JSON 数据})，虽然 AJAX 不能跨域访问，但 JS 脚本是可以跨域执行的，因此客户端将执行这个 callback 函数，并获取其中的 JSON 数据。配置文件在上面已经介绍过了，下面直接进行使用：spring-cxf-rest.xml12345678910111213141516171819202122&lt;bean id="jsonProvider" class="com.fasterxml.jackson.jaxrs.json.JacksonJsonProvider"/&gt; &lt;!--jsonp使用--&gt; &lt;bean id="jsonpInInterceptor" class="org.apache.cxf.jaxrs.provider.jsonp.JsonpInInterceptor"/&gt; &lt;bean id="jsonpPreStreamInterceptor" class="org.apache.cxf.jaxrs.provider.jsonp.JsonpPreStreamInterceptor"/&gt; &lt;bean id="jsonpPostStreamInterceptor" class="org.apache.cxf.jaxrs.provider.jsonp.JsonpPostStreamInterceptor"/&gt;&lt;jaxrs:server address="/rest"&gt; &lt;jaxrs:serviceBeans&gt; &lt;ref bean="userWebserviceImpl"/&gt; &lt;/jaxrs:serviceBeans&gt; &lt;jaxrs:providers&gt; &lt;ref bean="jsonProvider"/&gt; &lt;ref bean="jsonpPreStreamInterceptor"/&gt; &lt;/jaxrs:providers&gt; &lt;jaxrs:inInterceptors&gt; &lt;ref bean="jsonpInInterceptor"/&gt; &lt;/jaxrs:inInterceptors&gt; &lt;jaxrs:outInterceptors&gt; &lt;ref bean="jsonpPostStreamInterceptor"/&gt; &lt;/jaxrs:outInterceptors&gt; &lt;/jaxrs:server&gt;使用 CORS 解决 AJAX 跨域问题在 IE8 中使用 jQuery 发送 AJAX 请求时，需要配置 $.support.cors = true，才能开启 CORS 特性123456789101112&lt;!--使用 CORS 解决 AJAX 跨域问题--&gt; &lt;jaxrs:server address="/rest"&gt; &lt;jaxrs:serviceBeans&gt; &lt;ref bean="userWebserviceImpl"/&gt; &lt;/jaxrs:serviceBeans&gt; &lt;jaxrs:providers&gt; &lt;bean class="com.fasterxml.jackson.jaxrs.json.JacksonJsonProvider"/&gt; &lt;bean class="org.apache.cxf.rs.security.cors.CrossOriginResourceSharingFilter"&gt; &lt;property name="allowOrigins" value="http://localhost"/&gt; &lt;/bean&gt; &lt;/jaxrs:providers&gt; &lt;/jaxrs:server&gt;本文参考了这里写链接内容]]></content>
      <categories>
        <category>Web Service</category>
      </categories>
      <tags>
        <tag>Web Service</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java IO流]]></title>
    <url>%2FJava-IO%E6%B5%81%2F</url>
    <content type="text"><![CDATA[IO流IO流IO流主要用来读写文件,而且很难理解.不过早实际的项目操作中也就简单的运用就能满足我们的需求.先看看IO流的一些类字节流字节流主要来对二进制进行操作的,它是以字节的来处理的.(简单的说使用记事本无法打开的,打开或者乱码的)OutputStreram:输出流,也就是写入文件中.简单使用:向文件中写入”hello World”123456//字节输出流.写数据File file = new File("f:\\demo\\io.txt");//创建字节流输出对象FileOutputStream fos = new FileOutputStream(file); String content = "hello world"; //写数据 fos.write(content.getBytes()); //关闭资源 fos.close();inputStream输入流(从文件中读取数据)从文件中读取数据:一次读取一个字符## 标题 ##1234567891011//从文件中读取文件中的内容File file = new File("f:\\demo\\io.txt");//创建字节流输入对象FileInputStream fis = new FileInputStream(file);int by = 0;## 标题 ##while ((by = fis.read()) != -1) &#123;System.out.print((char)by);&#125;## 标题 ##//关闭资源fis.close();一次读取字符数组123456789//一次性读取整个数组byte[] bys = new byte[1024];int len = 0;while((len = fis.read(bys)) != -1)&#123;System.out.println(new String(bys,0,len));&#125;//关闭资源fis.close();字符缓冲流定义数组读取的速度相对比读取一个字节的速度快的多,可知存在缓冲区的话速率会更快,这就是字符缓冲流.写入数据12345678//字符缓冲输出流,写入文件File file = new File("f:\\demo\\bos.txt");BufferedOutputStream bos = new BufferedOutputStream(new FileOutputStream(file));// 写数据bos.write("hello".getBytes());// 释放资源bos.close();从文件中读取数据1234567891011//从文件中读取文件内容File file = new File("f:\\demo\\bos.txt");BufferedInputStream bis = new BufferedInputStream(new FileInputStream(file));byte[] bys = new byte[1024];int len = 0;while ((len = bis.read(bys)) != -1) &#123;System.out.print(new String(bys, 0, len));&#125;// 释放资源bis.close();字符流的对比这里我们做一个实验,判断字节流读取的速率将IO流.bmp文件进行复制结果如下:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778private static void testCopyFile() throws IOException &#123; /** * 四中复制方式 * &lt;ul&gt; * &lt;li&gt;基本字节流一次读写一个字节:共耗时：8890毫秒&lt;/li&gt; * &lt;li&gt;基本字节流一次读写一个字节数组:共耗时：17毫秒&lt;/li&gt; * &lt;li&gt;高效字节流一次读写一个字节:共耗时：95毫秒&lt;/li&gt; * &lt;li&gt;高效字节流一次读写一个字节数组:共耗时：5毫秒&lt;/li&gt; * &lt;/ul&gt; */ long start = System.currentTimeMillis(); // method1("f:\\demo\\IO流.bmp", "IO流1.bmp"); // method2("f:\\demo\\IO流.bmp", "IO流2.bmp"); // method3("f:\\demo\\IO流.bmp", "IO流3.bmp"); method4("f:\\demo\\IO流.bmp", "IO流4.bmp"); long end = System.currentTimeMillis(); System.out.println("共耗时：" + (end - start) + "毫秒");&#125;// 高效字节流一次读写一个字节数组：public static void method4(String srcString, String destString) throws IOException &#123; BufferedInputStream bis = new BufferedInputStream(new FileInputStream(srcString)); BufferedOutputStream bos = new BufferedOutputStream(new FileOutputStream(destString)); byte[] bys = new byte[1024]; int len = 0; while ((len = bis.read(bys)) != -1) &#123; bos.write(bys, 0, len); &#125; bos.close(); bis.close();&#125;// 高效字节流一次读写一个字节：public static void method3(String srcString, String destString) throws IOException &#123; BufferedInputStream bis = new BufferedInputStream(new FileInputStream(srcString)); BufferedOutputStream bos = new BufferedOutputStream(new FileOutputStream(destString)); int by = 0; while ((by = bis.read()) != -1) &#123; bos.write(by); &#125; bos.close(); bis.close();&#125;// 基本字节流一次读写一个字节数组public static void method2(String srcString, String destString) throws IOException &#123; FileInputStream fis = new FileInputStream(srcString); FileOutputStream fos = new FileOutputStream(destString); byte[] bys = new byte[1024]; int len = 0; while ((len = fis.read(bys)) != -1) &#123; fos.write(bys, 0, len); &#125; fos.close(); fis.close();&#125;// 基本字节流一次读写一个字节public static void method1(String srcString, String destString) throws IOException &#123; FileInputStream fis = new FileInputStream(srcString); FileOutputStream fos = new FileOutputStream(destString); int by = 0; while ((by = fis.read()) != -1) &#123; fos.write(by); &#125; fos.close(); fis.close();&#125;字符流字符流 = 字节流 + 编码表字节输出流(写入文件中)OutputStreamWriter方法方法:OutputStreamWriter(OutputStream out):根据默认编码把字节流的数据转换为字符流OutputStreamWriter(OutputStream out,String charsetName):根据指定编码把字节流数据转换为字符流public void write(int c);一次写一个字符public void write(char[] chuf):写一个字符数组public void write(char[] chuf,int off,int len):写一个字符数组的一部分public void write(String str):写一个字符串public void write(String str,int off,int len) :写一个数组的一部分close()与flush()的区别:close()关闭流对象关闭后无法继续写入内容,flush()刷新流,还可以写入文件中.简单看下文件的读写12345OutputStreamWriter osw = new OutputStreamWriter(new FileOutputStream(&quot;F://demo//io.txt&quot;),&quot;UTF-8&quot;);osw.write(&quot;今天是周五&quot;);osw.write(&quot;今天是周六&quot;);osw.flush();osw.close();InputStreamReader方法:int read()：一次读取一个字符;int read(char[] chs):一次读取一个字符数组;12345678910111213141516InputStreamReader isr = new InputStreamReader(new FileInputStream("F://demo//io.txt"),"utf-8");//一次读取一个字符int ch = 0;while ((ch = isr.read()) != -1) &#123; System.out.print((char)ch);&#125;//关闭流释放资源isr.close();//一次读取一个字符数组char[] chs = new char[1024]; int len = 0; while((len = isr.read(chs))!= -1)&#123; System.out.print(new String(chs,0,len)); &#125;拷贝文件代码123456789101112131415161718/** * 边读编写 */ InputStreamReader isr = new InputStreamReader(new FileInputStream("f://demo/io.txt")); OutputStreamWriter osw = new OutputStreamWriter(new FileOutputStream("f://demo//ioC.txt")); //一次读取字符数组 int len = 0; char[] ch = new char[1024]; while((len = isr.read(ch)) != -1) &#123; String content = new String(ch,0,len); osw.write(content); osw.flush(); &#125; isr.close(); osw.close();一般拷贝文件都是使用本地默认的编码,可以不指定编码.下面我们尝试用子类来进行拷贝文件直接上代码,代码如下1234567891011121314public static void main(String[] args) throws IOException &#123; FileReader fr = new FileReader("f://demo//io.txt"); FileWriter fw = new FileWriter("f://demo//ioC2.txt"); int len = 0; char[] ch = new char[1024]; while((len = fr.read(ch)) != -1) &#123; String content = new String(ch,0,len); fw.write(content); fw.flush(); &#125; fr.close(); fw.close();&#125;缓冲流字符流为了增加读写效率增加了缓冲流.BufferedWriter:字符缓冲输出流BufferedReader:字符缓冲输入流BufferedWrite:字节缓冲输出流,将文本写入字符输出流,缓冲各个字符,从而提供单个字符、数组和字符串的 高效写入。BufferedReader:字符缓冲输入流,从字符输入流中读取文本，缓冲各个字符，从而实现字符、数组和行的高效读取。备注:缓冲区大小可以指定,一般情况下默认大小就能满足我们的需求两者的使用如下:1234567891011121314151617181920BufferedReader br = new BufferedReader(new FileReader("f://demo//io.txt"));BufferedWriter bw = new BufferedWriter(new FileWriter("f://demo//ioC4.txt"));//一次读取一个字符数组char[] chs = new char[1024];int len = 0;while ((len = br.read(chs)) != -1) &#123; bw.write(chs, 0, len); bw.flush();&#125;//一次读取一行String con = null;while ((con = br.readLine()) != null) &#123; bw.write(con); bw.flush();&#125;bw.close();br.close();下面有一些示例可以参考下:拷贝文本文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134/** * 拷贝文件 * 采用字符流 * Created by wsylp on 2017/7/1. */public class CopyFileDemo &#123; public static void main(String[] args) throws IOException &#123; String src = "f://demo//io.txt"; String target1 = "f://demo//ioCopy1.txt"; String target2 = "f://demo//ioCopy2.txt"; String target3 = "f://demo//ioCopy3.txt"; String target4 = "f://demo//ioCopy4.txt"; String target5 = "f://demo//ioCopy5.txt"; //一次读写一个字符 copyFile1(src, target1); //一次读写一个字符数组 copyFile2(src, target2); //字符缓冲流读取一个字符 copyFile3(src, target3); //字符缓冲流读取一个字符数组 copyFile4(src, target4); //字符缓冲流读取一行字符串 copyFile5(src, target5); &#125; /** * 字符缓冲流读取一行字符串 * * @param src 源文件 * @param target 目标文件 */ private static void copyFile5(String src, String target) throws IOException &#123; BufferedReader br = new BufferedReader(new FileReader(src)); BufferedWriter bw = new BufferedWriter(new FileWriter(target)); String line = null; while ((line = br.readLine()) != null) &#123; bw.write(line); bw.flush(); &#125; bw.close(); br.close(); &#125; /** * 字符缓冲流读取一个字符数组 * * @param src 源文件 * @param target 目标文件 */ private static void copyFile4(String src, String target) throws IOException &#123; BufferedReader br = new BufferedReader(new FileReader(src)); BufferedWriter bw = new BufferedWriter(new FileWriter(target)); char[] ch = new char[1024]; int len = 0; while ((len = br.read(ch)) != -1) &#123; bw.write(ch, 0, len); bw.flush(); &#125; bw.close(); br.close(); &#125; /** * 字符缓冲流读取一个字符 * * @param src 源文件 * @param target 目标文件 */ private static void copyFile3(String src, String target) throws IOException &#123; BufferedReader br = new BufferedReader(new FileReader(src)); BufferedWriter bw = new BufferedWriter(new FileWriter(target)); int ch = 0; while ((ch = br.read()) != -1) &#123; bw.write(ch); bw.flush(); &#125; bw.close(); br.close(); &#125; /** * 一次读写一个字符数组 * * @param src 源文件 * @param target 目标文件 */ private static void copyFile2(String src, String target) throws IOException &#123; FileReader fr = new FileReader(src); FileWriter fw = new FileWriter(target); char[] ch = new char[1024]; int len = 0; while ((len = fr.read(ch)) != -1) &#123; fw.write(ch, 0, len); fw.flush(); &#125; fw.close(); fr.close(); &#125; /** * 一次读写一个字符 * * @param src 源文件 * @param target 目标文件 */ private static void copyFile1(String src, String target) throws IOException &#123; FileReader fr = new FileReader(src); FileWriter fw = new FileWriter(target); int len = 0; while ((len = fr.read()) != -1) &#123; fw.write(len); fw.flush(); &#125; fw.close(); fr.close(); &#125;&#125;拷贝照片12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697/** * 复制照片文件需要字节流 * * Created by wsylp on 2017/7/1. */public class CopyImgDemo &#123; public static void main(String[] args) throws IOException &#123; String src = "f://demo//io.bmp"; String target1 = "f://demo//io1.bmp"; String target2 = "f://demo//io2.bmp"; String target3 = "f://demo//io3.bmp"; String target4 = "f://demo//io4.bmp"; copyImg1(src,target1); copyImg2(src,target2); copyImg3(src,target3); copyImg4(src,target4); &#125; /** * 缓冲流,一次读取一个字节数组 * @param src 源地址 * @param target 目标地址 */ private static void copyImg4(String src, String target) throws IOException &#123; BufferedInputStream bis = new BufferedInputStream(new FileInputStream(src)); BufferedOutputStream bos = new BufferedOutputStream(new FileOutputStream(target)); byte[] by = new byte[1024]; int len = 0; while((len = bis.read(by)) != -1)&#123; bos.write(by,0,len); bos.flush(); &#125; bis.close(); bos.close(); &#125; /** * 缓冲流,一次读取一个字节 * @param src 源地址 * @param target 目标地址 */ private static void copyImg3(String src, String target) throws IOException&#123; BufferedInputStream bis = new BufferedInputStream(new FileInputStream(src)); BufferedOutputStream bos = new BufferedOutputStream(new FileOutputStream(target)); int ch = 0; while((ch = bis.read()) != -1) &#123; bos.write(ch); bos.flush(); &#125; bos.close(); bis.close(); &#125; /** * 一次读取一个字节数组 * @param src 源地址 * @param target 目标地址 */ private static void copyImg2(String src, String target) throws IOException &#123; FileInputStream fis = new FileInputStream(src); FileOutputStream fos = new FileOutputStream(target); byte[] by = new byte[1024]; int len = 0; while((len = fis.read(by))!= -1) &#123; fos.write(by,0,len); &#125; fos.close(); fis.close(); &#125; /** * 缓冲流,一次读取一个字节 * @param src 源地址 * @param target 目标地址 */ private static void copyImg1(String src, String target) throws IOException&#123; FileInputStream fis = new FileInputStream(src); FileOutputStream fos = new FileOutputStream(target); int len = 0; while((len = fis.read())!= -1) &#123; fos.write(len); &#125; fos.close(); fis.close(); &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java IO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java File解析]]></title>
    <url>%2FJava-File%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[java File解析创建文件File.createNewFile();仅仅创建文件.1234567//在f盘下面创建a.txtFile file2 = new File("F:\\demo\\a.txt");file2.createNewFile();//该方法会报IO异常 系统找不到指定的路径File file3 = new File("F:\\demo\\a\\a.txt");file3.createNewFile();File.mkdir();创建文件夹,如果已经创建就不在进行创建;注意:当用该方法创建文件时,只能创建一个文件,如果两个文件的话,父文件不存在还是无法创建.1234567891011//这种方式无法进行创建文件 File file2 = new File("F:\\demo\\a\\a.txt"); file2.mkdir(); //如果demo文件夹不存在,还是无法创建 File file3 = new File("F:\\demo\\a"); file3.mkdir(); //当demo存在时才会进行创建 File file4 = new File("F:\\demo\\a"); file4.mkdir();3.File.mkdirs();创建文件夹,如果父文件不存在,父文件也会创建出来.//创建文件夹File file2 = new File(“F:\demo\a\a.txt”);file2.mkdirs();删除文件注意事项:删除文件后无法在回收站中找到.如果删除文件夹,文件夹下面不能有文件或者文件夹File.delete();文件重命名注意:如果文件路径相同,则相当于重命名,如果文件路径不相同,则是相当于改名并剪切.File.renameTo();将a.txt重命名为b.txt1234File file = new File("F:\\demo\\a\\a.txt"); File fileNew = new File("F:\\demo\\a\\b.txt"); file.renameTo(fileNew);将b.txt剪切到demo文件夹下改名为c.txt12File fileAfter = new File("F:\\demo\\c.txt");fileNew.renameTo(fileAfter);判断功能public boolean isDirectory()：是否是目录public boolean isFile()：是否是文件夹public boolean exists()：是否存在public boolean canRead()：是否可读public boolean canWrite()：是否可写public boolean isHidden()：是否隐藏获取文件路径大小等方法public String getAbsolutePath()：获取绝对路径public String getPath():获取相对路径public String getName():获取名称public long length():获取长度。字节数public long lastModified():获取最后一次的修改时间，毫秒值指定文件夹下的文件获取public String[] list():获取指定目录下的所有文件或者文件夹的名称数组public File[] listFiles():获取指定目录下的所有文件或者文件夹的File数组遍历demo下的文件,仅仅是当前目录下的文件1234567//获取demo下的文件File file = new File("F:\\demo");File[] files = file.listFiles(); for (File o: files ) &#123; System.out.println("文件名字:"+o.getName()); System.out.println("文件路径"+o.getAbsolutePath()); &#125;根据需求查找文件1File[] listFiles(FileFilter filter)123456789101112131415161718192021//文件名过滤器//过滤后缀名为 .txt的文件File file = new File("F:\\demo");FileFilter fileFilter = new FileFilter() &#123; @Override public boolean accept(File pathname) &#123; String fileName = pathname.getName().toLowerCase(); if (fileName.endsWith(".txt")) &#123; return true; &#125; else &#123; return false; &#125; &#125;&#125;;File[] files = file.listFiles(fileFilter);for (File o: files ) &#123; System.out.println(o.getName());&#125;File[] listFiles(FilenameFilter filter);1234567891011121314//过滤demo文件夹中后缀名为 .txt的文件File file = new File("f:\\demo");FilenameFilter fileFilter = new FilenameFilter() &#123; @Override public boolean accept(File dir, String name) &#123; if (dir.getAbsoluteFile().toString().equals("f:\\demo") &amp;&amp; name.endsWith(".txt")) &#123; return true; &#125; else &#123; return false; &#125; &#125;&#125;;​]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java File</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络安全之MD5_SHA1]]></title>
    <url>%2F%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E4%B9%8BMD5_SHA1%2F</url>
    <content type="text"><![CDATA[java File解析MD5首先,我们简单介绍一下MD5（Message Digest Algorithm MD5）。发展历史​ 从1989年的MD2-&gt;1990年MD4-&gt;1991年MD5应用一致性校验数字签名安全访问认证一致性验证：unix下有些文件会有一个.md5的文件，它就是对文件的一个签名，用来保证这个文件是否被篡改过。由于不同的内容经过MD5后会产生不同的结果，所以可以保证文件的一致性。利用MD5算法来进行文件的校验被大量应用到软件下载、论坛数据库、系统文件安全等方面。数字签名：对消息进行加密，消息内容被修改后，重新获取的MD5值就会不一致，如果有第三发进行认证的话，这样就会对文件的消息来源进行保证，防止文件的作者“抵赖”。安全访问认证：在系统的开发中会经常用到密码的保存。当用户登录时对密码进行MD5加密，然后与数据库的密码进行比对，一致即可完成登录。但是现在通过跑字典的方式可以将MD5加密后的内容还原为加密前的内容。算法原理MD5是输入不定长度信息，输出固定的128-bits的算法。经过程序流程，生成四个32位数据，最后连在一起成为一个128-bits散列。基本方式为，求余、取余、调整长度、与链接变量进行循环运算，得到结果。处理原文首先计算出原文长度(bit)对512求余，如果不等于448，进行填充原文使得原文对515的求余满足等于448。填充的方式是第一位填充1，其余位填0.填完后，信息的长度为512*N+448。之后，用剩余的位置（512-448=64位）记录原文的真正长度，把长度的二进制值补在最后。这样处理后的信息长度就是512*（N+1）。设置初始值MD5的哈希结果长度为128位，按每32位分成一组工4组。这4组的结果是由4个初始值A、B、C、D经过不断演变得到的。MD5的官方实现中，A、B、C、D的初始值如下（16进制）1234A=0x01234567B=0x89ABCDEFC=0xFEDCBA98D=0x76543210循环加工我们先看下面的这张图图中，A、B、C、D就是哈希值的四个分组。每一次循环都会让旧的ABCD产生新的ABCD。循环的次数是由处理后的原文长度决定的。假设处理后的原文长度为M主循环次数=M/512每个主循环中包含512/32 * 4 = 64次子循环。上图为单词子循环的流程。每次操作对a、b、c和d中的其中三个作一次非线性函数运算，然后将所得结果加上第四个变量，文本的一个子分组和一个常数。再将所得结果向左环移一个不定的数，并加上a、b、c或d中之一。最后用该结果取代a、b、c或d中之一。现在对图中的元素进行解释绿色F图中绿色F，代表非线性函数。MD5所用到的函数有四种：1234F(X, Y, Z) =(X&amp;Y) | ((~X) &amp; Z)G(X, Y, Z) =(X&amp;Z) | (Y &amp; (~Z))H(X, Y, Z) =X^Y^ZI(X, Y, Z)=Y^(X|(~Z))在主循环下面64次子循环中，F、G、H、I 交替使用，第一个16次使用F，第二个16次使用G，第三个16次使用H，第四个16次使用I。红色田字红色的田字代表相加的意思MiMi是第一步处理后的原文。在第一步中，处理后的原文长度为512的整数倍。把原文的没512位在分成16等份，命名为M0~M15，每份长度为32。在64次子循环中，每16次循环，都会交替用到M1~M16之一。Ki一个常量，在64次子循环中，每一次用到的常量都是不同的。黄色的&lt;&lt;1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768第一轮： FF(a,b,c,d,M0,7,0xd76aa478） s[0]=7, K[0] = 0xd76aa478 FF(a,b,c,d,M1,12,0xe8c7b756） s[1]=12, K[1] = 0xe8c7b756 FF(a,b,c,d,M2,17,0x242070db) FF(a,b,c,d,M3,22,0xc1bdceee) FF(a,b,c,d,M4,7,0xf57c0faf) FF(a,b,c,d,M5,12,0x4787c62a) FF(a,b,c,d,M6,17,0xa8304613） FF(a,b,c,d,M7,22,0xfd469501） FF(a,b,c,d,M8,7,0x698098d8） FF(a,b,c,d,M9,12,0x8b44f7af) FF(a,b,c,d,M10,17,0xffff5bb1） FF(a,b,c,d,M11,22,0x895cd7be) FF(a,b,c,d,M12,7,0x6b901122） FF(a,b,c,d,M13,12,0xfd987193） FF(a,b,c,d,M14,17, 0xa679438e) FF(a,b,c,d,M15,22,0x49b40821）第二轮： GG(a,b,c,d,M1,5,0xf61e2562） GG(a,b,c,d,M6,9,0xc040b340） GG(a,b,c,d,M11,14,0x265e5a51） GG(a,b,c,d,M0,20,0xe9b6c7aa) GG(a,b,c,d,M5,5,0xd62f105d) GG(a,b,c,d,M10,9,0x02441453） GG(a,b,c,d,M15,14,0xd8a1e681） GG(a,b,c,d,M4,20,0xe7d3fbc8） GG(a,b,c,d,M9,5,0x21e1cde6） GG(a,b,c,d,M14,9,0xc33707d6） GG(a,b,c,d,M3,14,0xf4d50d87） GG(a,b,c,d,M8,20,0x455a14ed) GG(a,b,c,d,M13,5,0xa9e3e905） GG(a,b,c,d,M2,9,0xfcefa3f8） GG(a,b,c,d,M7,14,0x676f02d9） GG(a,b,c,d,M12,20,0x8d2a4c8a)第三轮： HH(a,b,c,d,M5,4,0xfffa3942） HH(a,b,c,d,M8,11,0x8771f681） HH(a,b,c,d,M11,16,0x6d9d6122） HH(a,b,c,d,M14,23,0xfde5380c) HH(a,b,c,d,M1,4,0xa4beea44） HH(a,b,c,d,M4,11,0x4bdecfa9） HH(a,b,c,d,M7,16,0xf6bb4b60） HH(a,b,c,d,M10,23,0xbebfbc70） HH(a,b,c,d,M13,4,0x289b7ec6） HH(a,b,c,d,M0,11,0xeaa127fa) HH(a,b,c,d,M3,16,0xd4ef3085） HH(a,b,c,d,M6,23,0x04881d05） HH(a,b,c,d,M9,4,0xd9d4d039） HH(a,b,c,d,M12,11,0xe6db99e5） HH(a,b,c,d,M15,16,0x1fa27cf8） HH(a,b,c,d,M2,23,0xc4ac5665）第四轮： Ⅱ（a,b,c,d,M0,6,0xf4292244） Ⅱ（a,b,c,d,M7,10,0x432aff97） Ⅱ（a,b,c,d,M14,15,0xab9423a7） Ⅱ（a,b,c,d,M5,21,0xfc93a039） Ⅱ（a,b,c,d,M12,6,0x655b59c3） Ⅱ（a,b,c,d,M3,10,0x8f0ccc92） Ⅱ（a,b,c,d,M10,15,0xffeff47d) Ⅱ（a,b,c,d,M1,21,0x85845dd1） Ⅱ（a,b,c,d,M8,6,0x6fa87e4f) Ⅱ（a,b,c,d,M15,10,0xfe2ce6e0) Ⅱ（a,b,c,d,M6,15,0xa3014314） Ⅱ（a,b,c,d,M13,21,0x4e0811a1） Ⅱ（a,b,c,d,M4,6,0xf7537e82） Ⅱ（a,b,c,d,M11,10,0xbd3af235） Ⅱ（a,b,c,d,M2,15,0x2ad7d2bb) Ⅱ（a,b,c,d,M9,21,0xeb86d391）拼接结果循环加工最终产生的A，B，C，D四个值拼接在一起，转换成字符串即可java实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166package top.wsylp.demo;/** * @Description: * @Author: wsylp * @Date: 2019/6/13 6:29 */public class MD5&#123; /* *四个链接变量 */ private final int A=0x67452301; private final int B=0xefcdab89; private final int C=0x98badcfe; private final int D=0x10325476; /* *ABCD的临时变量 */ private int Atemp,Btemp,Ctemp,Dtemp; /* *常量ti *公式:floor(abs(sin(i+1))×(2pow32) */ private final int K[]=&#123; 0xd76aa478,0xe8c7b756,0x242070db,0xc1bdceee, 0xf57c0faf,0x4787c62a,0xa8304613,0xfd469501,0x698098d8, 0x8b44f7af,0xffff5bb1,0x895cd7be,0x6b901122,0xfd987193, 0xa679438e,0x49b40821,0xf61e2562,0xc040b340,0x265e5a51, 0xe9b6c7aa,0xd62f105d,0x02441453,0xd8a1e681,0xe7d3fbc8, 0x21e1cde6,0xc33707d6,0xf4d50d87,0x455a14ed,0xa9e3e905, 0xfcefa3f8,0x676f02d9,0x8d2a4c8a,0xfffa3942,0x8771f681, 0x6d9d6122,0xfde5380c,0xa4beea44,0x4bdecfa9,0xf6bb4b60, 0xbebfbc70,0x289b7ec6,0xeaa127fa,0xd4ef3085,0x04881d05, 0xd9d4d039,0xe6db99e5,0x1fa27cf8,0xc4ac5665,0xf4292244, 0x432aff97,0xab9423a7,0xfc93a039,0x655b59c3,0x8f0ccc92, 0xffeff47d,0x85845dd1,0x6fa87e4f,0xfe2ce6e0,0xa3014314, 0x4e0811a1,0xf7537e82,0xbd3af235,0x2ad7d2bb,0xeb86d391&#125;; /* *向左位移数,计算方法未知 */ private final int s[]=&#123;7,12,17,22,7,12,17,22,7,12,17,22,7, 12,17,22,5,9,14,20,5,9,14,20,5,9,14,20,5,9,14,20, 4,11,16,23,4,11,16,23,4,11,16,23,4,11,16,23,6,10, 15,21,6,10,15,21,6,10,15,21,6,10,15,21&#125;; /* *初始化函数 */ private void init()&#123; Atemp=A; Btemp=B; Ctemp=C; Dtemp=D; &#125; /* *移动一定位数 */ private int shift(int a,int s)&#123; return(a&lt;&lt;s)|(a&gt;&gt;&gt;(32-s));//右移的时候，高位一定要补零，而不是补充符号位 &#125; /* *主循环 */ private void MainLoop(int M[])&#123; int F,g; int a=Atemp; int b=Btemp; int c=Ctemp; int d=Dtemp; for(int i = 0; i &lt; 64; i ++)&#123; if(i&lt;16)&#123; F=(b&amp;c)|((~b)&amp;d); g=i; &#125;else if(i&lt;32)&#123; F=(d&amp;b)|((~d)&amp;c); g=(5*i+1)%16; &#125;else if(i&lt;48)&#123; F=b^c^d; g=(3*i+5)%16; &#125;else&#123; F=c^(b|(~d)); g=(7*i)%16; &#125; int tmp=d; d=c; c=b; b=b+shift(a+F+K[i]+M[g],s[i]); a=tmp; &#125; Atemp=a+Atemp; Btemp=b+Btemp; Ctemp=c+Ctemp; Dtemp=d+Dtemp; &#125; /* *填充函数 *处理后应满足bits≡448(mod512),字节就是bytes≡56（mode64) *填充方式为先加一个0,其它位补零 *最后加上64位的原来长度 */ private int[] add(String str)&#123; int num=((str.length()+8)/64)+1;//以512位，64个字节为一组 int strByte[]=new int[num*16];//64/4=16，所以有16个整数 for(int i=0;i&lt;num*16;i++)&#123;//全部初始化0 strByte[i]=0; &#125; int i; for(i=0;i&lt;str.length();i++)&#123; strByte[i&gt;&gt;2]|=str.charAt(i)&lt;&lt;((i%4)*8);//一个整数存储四个字节，小端序 &#125; strByte[i&gt;&gt;2]|=0x80&lt;&lt;((i%4)*8);//尾部添加1 /* *添加原长度，长度指位的长度，所以要乘8，然后是小端序，所以放在倒数第二个,这里长度只用了32位 */ strByte[num*16-2]=str.length()*8; return strByte; &#125; /* *调用函数 */ public String getMD5(String source)&#123; init(); int strByte[]=add(source); for(int i=0;i&lt;strByte.length/16;i++)&#123; int num[]=new int[16]; for(int j=0;j&lt;16;j++)&#123; num[j]=strByte[i*16+j]; &#125; MainLoop(num); &#125; return changeHex(Atemp)+changeHex(Btemp)+changeHex(Ctemp)+changeHex(Dtemp); &#125; /* *整数变成16进制字符串 */ private String changeHex(int a)&#123; String str=""; for(int i=0;i&lt;4;i++)&#123; str+=String.format("%2s", Integer.toHexString(((a&gt;&gt;i*8)%(1&lt;&lt;8))&amp;0xff)).replace(' ', '0'); &#125; return str; &#125; /* *单例 */ private static MD5 instance; public static MD5 getInstance()&#123; if(instance==null)&#123; instance=new MD5(); &#125; return instance; &#125; private MD5()&#123;&#125;; public static void main(String[] args)&#123; String str=MD5.getInstance().getMD5("a"); System.out.println(str); &#125;&#125;MD5使用很简单:12345678910111213141516171819202122232425262728293031package top.wsylp.demo;import java.security.MessageDigest;import java.security.NoSuchAlgorithmException;/** * @Description: * @Author: wsylp * @Date: 2019/6/14 22:47 */public class MD5Util &#123; public static void MD5Encrypt(String data) throws NoSuchAlgorithmException &#123; StringBuffer ensryptStr = new StringBuffer(); MessageDigest digest = MessageDigest.getInstance("MD5"); digest.update(data.getBytes()); byte[] cipher = digest.digest(); for (byte b : cipher) &#123; //转换为16进制 String hexStr = Integer.toHexString(b &amp; 0xff); ensryptStr.append(hexStr.length() == 1 ? "0" + hexStr : hexStr); &#125; System.out.println(ensryptStr.toString()); &#125; public static void main(String[] args) throws NoSuchAlgorithmException &#123; MD5Encrypt("a"); &#125;&#125;SHA1SHA算法，即安全散列算法（Secure Hash Algorithm）是一种与MD5同源的数据加密算法，该算法经过加密专家多年来的发展和改进已日益完善，现在已成为公认的最安全的散列算法之一，并被广泛使用。概述SHA算法能计算出一个数位信息所对应到的，长度固定的字串，又称信息摘要。而且如果输入信息有任何的不同，输出的对应摘要不同的机率非常高。因此SHA算法也是FIPS所认证的五种安全杂凑算法之一。原因有两点：一是由信息摘要反推原输入信息，从计算理论上来说是极为困难的；二是，想要找到两组不同的输入信息发生信息摘要碰撞的几率，从计算理论上来说是非常小的。任何对输入信息的变动，都有很高的几率导致的信息摘要大相径庭。SHA实际上是一系列算法的统称，分别包括：SHA-1、SHA-224、SHA-256、SHA-384以及SHA-512。后面4中统称为SHA-2，事实上SHA-224是SHA-256的缩减版，SHA-384是SHA-512的缩减版。各中SHA算法的数据比较如下表，其中的长度单位均为位:类别SHA-1SHA-224SHA-256SHA-384SHA-512消息摘要长度160224256384512消息长度小于(2的64幂）位小于(2的64幂）位小于(2的64幂）位小于(2的128幂）位小于(2的128幂）位分组长度51251251210241024计算字长度3232326464计算步骤数8064648080SHA-1在许多安全协定中广为使用，包括TLS和SSL、PGP、SSH、S/MIME和IPsec，曾被视为是MD5的后继者。SHA1主要适用于数字签名标准（Digital Signature Standard DSS）里面定义的数字签名算法（Digital Signature Algorithm DSA）。对于长度小于264位的消息，SHA1会产生一个160位的消息摘要。基本原理我们分析SHA-1的算法原理。SHA-1是一种数字加密算法，该算法的思想是接受一段明文，然后以一种不可逆的方式将它转换为一段密文，将不定长读的信息加密为固定长度的散列值，也称之为信息摘要或信息认证过程。SHA-1算法输入报文的最大长度不超过264位，产生的输出是一个160位的报文摘要。输入是按512 位的分组进行处理的。SHA-1是不可逆的、防冲突，并具有良好的雪崩效应。对输入信息进行处理​ 对信息处理的方式与MD5的有些类似，对输入信息按512位进行分组并进行填充。填充后的长度与512进行相除，得到的余数为448位。填充的内容是什么？现在报文的后面加一个1，在加多个0，直到长度满足对512取余的模为448。至于为什么是448位？与MD5类似，会在后面补充64的长度信息。在上面的报表中，消息长度小于2的64幂，是因为长度信息的位数为64位。信息分组处理对输入信息进行填充后，长度为512的倍数，然后按照512的长度进行分组，可以得到一定数量的明文分组，这里用A、B、C 、 D等明文分组。对于每一个明文分组，都要重复反复的处理，这些与MD5都是相同的。而对于每个512位的明文分组，SHA1将其再分成16份更小的明文分组，称为子明文分组，每个子明文分组为32位，我们且使用M[t]（t= 0, 1,……15）来表示这16个子明文分组。然后需要将这16个子明文分组扩充到80个子明文分组，我们将其记为W[t]（t= 0, 1,……79），扩充的具体方法是：当0≤t≤15时，Wt = Mt；当16≤t≤79时，Wt = ( Wt-3 ⊕ Wt-8⊕ Wt-14⊕ Wt-16) &lt;&lt;&lt; 1，从而得到80个子明文分组。初始化缓存所谓初始化缓存就是为链接变量赋初值。前面我们实现MD5算法时，说过由于摘要是128位，以32位为计算单位，所以需要4个链接变量。同样SHA-1采用160位的信息摘要，也以32位为计算长度，就需要5个链接变量。我们记为A、B、C、D、E。其初始赋值分别为：A = 0x67452301、B = 0xEFCDAB89、Ｃ = 0x98BADCFE、Ｄ = 0x10325476、Ｅ = 0xC3D2E1F0。如果我们对比前面说过的MD5算法就会发现，前４个链接变量的初始值是一样的，因为它们本来就是同源的。计算信息摘要A）、将A左移5为与 函数的结果求和，再与对应的子明文分组、E以及计算常数求和后的结果赋予H0。（B）、将A的值赋予H1。（C）、将B左移30位，并赋予H2。（D）、将C的值赋予H3。（E）、将D的值赋予H4。（F）、最后将H0、H1、H2、H3、H4的值分别赋予A、B、C、D这个过程表示如下：123456789101112public static void sha1Encrypt(String str) throws NoSuchAlgorithmException &#123; MessageDigest messageDigest = MessageDigest.getInstance("SHA1"); messageDigest.update(str.getBytes()); byte[] cipher = messageDigest.digest(); String a = ""; for (byte b : cipher) &#123; String hex = Integer.toHexString(b &amp; 0xff); a += (hex.length() == 1 ? "0" + hex : hex); &#125; System.out.println(a); &#125;参考内容：信息摘要算法之二：SHA1算法分析及实现百度百科​]]></content>
      <categories>
        <category>安全</category>
      </categories>
      <tags>
        <tag>网络安全 加密 MD5 SHA1</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络安全知识之对称加密]]></title>
    <url>%2F%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E7%9F%A5%E8%AF%86%E4%B9%8B%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86%2F</url>
    <content type="text"><![CDATA[对称加密DES加密讲解DES加密之前我们先来了解一下什么是对称加密.对称加密:采用单钥密码系统的加密方法，同一个密钥可以同时用作信息的加密和解密，这种加密方法称为对称加密，也称为单密钥加密。对称加密的使用率比较高,相对于非对称加密来说,它是可逆的,只要知道密钥就可以解析出明文.由于数据传输容易暴露信息,一般都会进行加密来处理,防止信息暴露.不过对于DES加密,密钥只有56位,破解还是很简单的,不过基本的应用中可以进行使用.DES加密算法:把输入的64位数据块按位重新组合，并把输出分为L0、R0两部分，每部分各长32位，其置换规则为将输入的第58位换到第一位,第50位换到第2位……依此类推,最后一位是原来的第7位。L0、R0则是换位输出后的两部分，L0是输出的左32位，R0是右32位,例:设置换前的输入值为D1D2D3……D64,则经过初始置换后的结果为:L0=D58D50……D8;R0=D57D49……D7。经过16次迭代运算后,得到L16、R16,将此作为输入，进行逆置换，逆置换正好是初始置换的逆运算，由此即得到密文输出。代码实现:1234567891011121314151617181920212223242526272829303132333435363738public static void main(java.lang.String[] args) throws Exception &#123; //DES代表的为DES加密,密钥生成器 KeyGenerator keyGen = KeyGenerator.getInstance("DES"); //初始化56位密钥生成器 keyGen.init(56); //采用KeyGenerator规则生成密钥 SecretKey secretKey = keyGen.generateKey(); //生成为密钥数组 byte[] key = secretKey.getEncoded(); /** * 1:取得密钥 * 2:实例化Cipher * 3:ENCRYPT_MODE模式进行加密 */ //取得密钥 SecretKey secretKey1 = new SecretKeySpec(key, "DES"); //实例化Cipher完成加密或解密工作类 Cipher cipher = Cipher.getInstance("DES"); ////对Cipher.ENCRYPT_MODE模式加密 cipher.init(Cipher.ENCRYPT_MODE, secretKey1); byte[] cipherByte = cipher.doFinal("张三".getBytes());//加密数据 /** * 1:取得密钥 * 2:实例化Cipher * 3:Cipher.DECRYPT_MODE模式进行解密 */ //恢复密钥 SecretKey secretKey2 = new SecretKeySpec(key, "DES"); //Cipher完成加密或解密工作类 Cipher cipher2 = Cipher.getInstance("DES"); //对Cipher初始化，Cipher.DECRYPT_MODE为解密模式 cipher.init(Cipher.DECRYPT_MODE, secretKey2); //将数据解密出来 byte[] cipherByte2 = cipher.doFinal(cipherByte); System.out.println(new String(cipherByte2)); &#125;DES加密算法:3DES加密:在DES的基础上进行了三重DES加密的算法.该方法使用两个密钥，执行三次DES算法，加密的过程是加密-解密-加密，解密的过程是解密-加密-解密.3DES加密与DES加密类似,只是取得实例化不一样12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/** * 3DES加密 * Created by wsylp on 2017/6/29. */public class DES3Util &#123; //生成密钥 public static byte[] initkey() throws NoSuchAlgorithmException &#123; //生成3des密钥 KeyGenerator keyGen = KeyGenerator.getInstance("DESede"); //密钥长度默认为168,可以指定为112 keyGen.init(168); //采用KeyGenerator规则生成密钥 SecretKey secretKey = keyGen.generateKey(); //生成为密钥数组 byte[] key = secretKey.getEncoded(); return key; &#125; public static byte[] enectry(byte[] data, byte[] key) throws NoSuchAlgorithmException, NoSuchPaddingException, InvalidKeyException, BadPaddingException, IllegalBlockSizeException &#123; /** * 1:取得密钥 * 2:实例化Cipher * 3:ENCRYPT_MODE模式进行加密 */ //取得密钥 SecretKey secretKey1 = new SecretKeySpec(key, "DESede"); //实例化Cipher完成加密或解密工作类 Cipher cipher = Cipher.getInstance("DESede"); ////对Cipher.ENCRYPT_MODE模式加密 cipher.init(Cipher.ENCRYPT_MODE, secretKey1); //加密数据 byte[] cipherByte = cipher.doFinal(data); return cipherByte; &#125; public static byte[] decrypt(byte[] data, byte[] key) throws NoSuchPaddingException, NoSuchAlgorithmException, InvalidKeyException, BadPaddingException, IllegalBlockSizeException &#123; /** * 1:取得密钥 * 2:实例化Cipher * 3:Cipher.DECRYPT_MODE模式进行解密 */ //恢复密钥 SecretKey secretKey = new SecretKeySpec(key, "DESede"); //Cipher完成加密或解密工作类 Cipher cipher = Cipher.getInstance("DES"); //对Cipher初始化，Cipher.DECRYPT_MODE为解密模式 cipher.init(Cipher.DECRYPT_MODE, secretKey); //将数据解密出来 byte[] cipherByte2 = cipher.doFinal(data); return cipherByte2; &#125;&#125;AES加密AES:为高级加密标准(Advanced Encryption Standard).该算法为比利时密码学家Joan Daemen和Vincent Rijmen所设计，因此也称为Rijndael加密.AES加密用的比较多,能够防御针对DES加密的攻击.12345678910111213141516171819202122232425262728293031323334353637public static void main(String[] args) &#123; String loginName = "admin"; String password = "123456"; String bankCode = "070667999"; Date date = new Date(); long a = date.getTime(); byte[] key = AESUtils.initKey(128); byte[] keys = Base64.encodeBase64(key); String key64 = new String(keys); System.out.println("key64:" + key64); String data = "loginName=admin;password=123456;bankCode=070667999;" + a; System.out.println("加密的数据为" + data); byte[] ebStr = AESUtils.encrypt(data.getBytes(), key); byte[] b = Base64.encodeBase64(ebStr); String c = new String(b); System.out.println(c); //解密 byte[] d = Base64.decodeBase64(c.getBytes()); byte[] f = Base64.decodeBase64(keys); byte[] g = AESUtils.decrypt(d, f); String h = new String(g); System.out.println("最终结果:" + h); for (int i = 0; i &lt; 10; i++) &#123; byte[] key1 = AESUtils.initKey(128); byte[] keys1 = Base64.encodeBase64(key1); String key641 = new String(keys1); System.out.println("key64:" + key641); &#125;&#125;三种对称加密的比较Base64Base64不是一种加密方式,而是一种编码方式.base64可以用于在http传递信息,不能用肉眼看到,没有密钥,可以进行解码.注意:java自带的Base64无法放在url中,因为base64编码后的+等特殊符号会在接手时变为空格(url将+认为空格),例如:http:*?id=’1B2F+3D4g’在传输时候中间的+号就会变为空格,这个时候我们可以使用appach的包来进行对url加密.gradle下:compile “commons-codec:commons-codec:1.9”闲话少说,直接看代码:12345678910111213141516171819202122232425262728293031323334/** * Created by wsylp on 2017/7/1. */public class Base64Util &#123; /** * 正常编码 * * @param data 数据 * @return 加密后的字节数组 */ public static byte[] encode(byte[] data)&#123; byte[] bys = Base64.encodeBase64(data); return bys; &#125; /** * 对url进行编码 * @param data 数据 * @return 加密后的字符串 */ public static String encodeUrl(byte[] data)&#123; String da = Base64.encodeBase64URLSafeString(data); return new String(da); &#125; /** * 对64位base64解码 * @param str 数据 * @return 解码后字符串 */ public static String decodeUrl(byte[] str)&#123; byte[] da = Base64.decodeBase64(str); return new String(da); &#125;]]></content>
      <categories>
        <category>安全</category>
      </categories>
      <tags>
        <tag>网络安全</tag>
      </tags>
  </entry>
</search>
